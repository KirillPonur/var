Исторические сведения
Возникновение теории вероятностей как науки относят к средним векам,
когда появилась возможность и возникла необходимость изучения математическими методами азартных игр (таких как орлянка, кости, рулетка). Самые
ранние работы учёных в области теории вероятностей относятся к XVII веку. Первоначально её основные понятия не имели строго математического
описания. Задачи, из которых позже выросла теория вероятностей представляли набор некоторых эмпирических фактов о свойствах реальных событий,
которые формулировались с помощью наглядных описаний. Исследуя прогнозирование выигрыша при бросании костей в письмах друг другу, Блез
Паскаль и Пьер Ферма открыли первые вероятностные закономерности. Решением тех же задач занимался и Христиан Гюйгенс. При этом с перепиской
Паскаля и Ферма он знаком не был и методику решения изобрёл самостоятельно. Его статья, в которой он ввёл основные понятия теории вероятностей (понятие вероятности как величину шанса; математическое ожидание
для дискретных случаев в виде цены шанса). В своей статье он использует
(не сформулированные ещё в явном виде) теоремы сложения и умножения
вероятностей. Статья была опубликована в печатном виде на двадцать лет
раньше (1657 г.) издания писем Паскаля и Ферма (1679 г.).
Важный вклад в теорию вероятностей внёс Якоб Бернулли, он дал доказательство закона больших чисел в простейшем случае независимых испытаний. В первой половине XIX века теория вероятностей начинает применяться к анализу ошибок наблюдений; Лаплас и Пуассон доказали первые
предельные теоремы. Во второй половине XIX века основной вклад внесли
русские учёные П. Л. Чебышёв, А. А. Марков и А. М. Ляпунов. В это время были доказаны закон больших чисел, центральная предельная теорема,
а также разработана теория цепей Маркова. Современный вид теория вероятностей получила благодаря аксиоматике, предложенной Андреем Николаевичем Колмогоровым. В результате теория вероятностей приобрела строгий
математический вид и окончательно стала восприниматься как один из разделов математики.
Википедия,
Статья "Теория вероятностей".

1

Глава 1. СОБЫТИЯ И ИХ ВЕРОЯТНОСТИ
§1. Элементы комбинаторики. Схемы шансов
В этом параграфе мы подсчитываем число элементарных событий или,
проще говоря, исходов, шансев, которые могут возникать в результате эксперимента. Например, при подбрасывание монеты могут произойти 2 исхода,
при подбрасывание игрального кубика могут произойти 6 исходов, при извлечение карты из колоды в 54 листа могут произойти 53 исхода. Такие подсчёты
изучают в разделе математики, называемом комбинаторикой.
Пусть A и B -- два непересекающихся конечных множества с числом
элементов m и n соответственно. Очевидны следующие две леммы.
Лемма 1.1 (о сумме). Число шансов выбрать один элемент либо из A
либо из B, т.е. из объединения A ∪ B, равно m + n.
Лемма 1.2 (о произведении). Число шансов выбрать пару элементов,
один из A, а другой из B, равно mn, т.е. числу элементов в декартовом
произведении A × B.
Непосредственным обобщением предыдущей леммы является следующая
теорема.
Теорема 1.3. Пусть A1 , A2 , \ldots , Ak -- конечные непересекающиеся множества, имеющие n1 , n2 , \ldots , nk элементов соответственно. Выберем из
каждого множества по одному элементу. Тогда общее число способов, которыми можно осуществить такой выбор, равно n1 n2 \ldots nk .
Доказательство. Ясно, что число способов такого выбора равно числу точек (элементов) в декартовом произведении A1 × A2 × \ldots × Ak , т.е. равно
n1 n 2 \ldots n k .

1.1. Эксперименты выбора шариков
Рассмотрим ящик, содержащий n одинаковых шариков, на которых написаны
числа 1, 2, \ldots , n. Эксперимент состоит в том, что из ящика, не глядя, по
одному вынимают k шариков, где k \leq n. Обозначим через
(n1 , n2 , \ldots , nk )
упорядоченный набор чисел, где n1 -- номер 1-го вынутого шарика, n2 --
номер 2-го шарика, \ldots , nk -- номер k-го шарика.
Например, из 5 занумерованных шариков выбрали 3 шарика и получился
набор (4, 2, 1).
2

Сколько имеется различных способов вынуть из ящика k шариков? На
этот вопрос нельзя дать однозначный ответ, потому что такой эксперимент
определён неоднозначно.
Во-первых, не определено, возвращают ли извлеченный шарик обратно в
ящик. Во-вторых, не определено, какие наборы номеров считать различными
и какие наборы считать одинаковыми.
Рассмотрим следующие возможные условия проведения эксперимента.
1. Эксперимент с возвращением. Каждый извлечённый шарик возвращается в ящик.
В этом случае в наборе могут появляться одинаковые номера. Например, при выборе трёх шариков из ящика, содержащего пять шариков
с номерами 1, 2, 3, 4 и 5, могут появиться наборы (3, 3, 5), (1, 2, 4)
и (4, 2, 1).
2. Эксперимент без возвращений. Извлечённые шарики в ящик не возвращаются.
В этом случае в наборе не могут встречаться одинаковые номера. В
рассмотренном выше примере набор (3, 3, 5) не может появиться, а
наборы (1, 2, 4) и (4, 2, 1) могут.
Опишем теперь, какие наборы номеров мы будем считать различными.
Существуют ровно две возможности.
1. Эксперимент с учётом порядка. Два набора номеров считаются различными, если они отличаются либо составом, либо порядком.
В рассмотренном выше примере все наборы (3, 3, 5), (1, 2, 4) и (4, 2, 1)
считаются различными.
2. Эксперимент без учёта порядка. Два набора номеров считаются различными, если они отличаются только составом.
В рассмотренном выше примере наборы (1, 2, 4) и (4, 2, 1) доставляют
одно и тот же элементарное событие, а набор (3, 3, 5) -- другое.
Подсчитаем теперь, сколько получится различных исходов для каждого
из четырёх экспериментов. Заметим, что в литературе такие эксперименты
часто называют схемами выбора или схемами шансов. Схема шансов -- это
условия (с возвратом или без, какие наборы различны и т.д.), при которых
проводится эксперимент.
3

1.2. Схема шансов без возвращения и с учётом порядка
Теорема 1.4. В эксперименте без возвращения и с учётом порядка число
способов выбрать k элементов из n-элементного множества равно
n!
Akn = n(n − 1) \ldots (n − k + 1) =
.
(n − k)!
Число Akn называется числом размещений k элементов на n местах. Читается: "A из n по k."
Доказательство. При выборе первого шарика имеется n возможностей. При
выборе второго шарика остаётся n − 1 возможностей, и т.д. При выборе последнего k-го шарика остаётся n − k + 1 возможностей. По теор. 1.3 общее
число наборов равно n(n − 1) \ldots (n − k + 1), что и требовалось доказать.
Следствие 1.5. Число перестановок из n элементов равно n!.
Доказательство. Очевидно, что перестановка есть результат выбора по схеме без возвращения и с учётом порядка всех n элементов из n, т.е. общее
число перестановок равно Ann = n!.

1.3. Схема шансов без возвращения и без учёта порядка
Теорема 1.6. В эксперименте без возвращения и без учёта порядка число
способов извлечь k из n-элементного множества равно
Cnk

Akn
n!
=
=
.
k!
k!(n − k)!

Число Cnk называется числом сочетаний k элементов из n элементов.
Читается: "C из n по k."
Доказательство. По след. 1.5 из k элементов можно образовать k! упорядоченных наборов. Поэтому количество сочетаний (неупорядоченных наборов)
в k! раз меньше, чем число размещений. Поделив Akn на k!, получим требуемый результат.

1.4. Схема шансов с возвращением и с учётом порядка
Теорема 1.7. В эксперименте с возвращением и с учётом порядка число
способов извлечь k элементов из n-элементного множества равно nk .
Доказательство. При выборе каждого из k шариков имеется n возможностей. По теор. 1.3 общее число наборов равно n \cdot n \cdot ... \cdot n = nk .
4

1.5. Схема шансов с возвращением и без учёта порядка
Замечание 1.8. Рассмотрим для примера ящик с двумя шариками 1 и 2,
из которого мы вынимаем последовательно два шарика. Без учёта порядка
имеется 3 исхода: {1, 1}, {1, 2} = {2, 1}, {2, 2}.
Теорема 1.9. В эксперименте с возвращением и без учёта порядка число
k
способов извлечь k элементов из n-элементного множества равно Cn+k−1
.
Доказательство. Т.к. порядок появления шариков не учитывается, то мы
учитываем лишь только то, сколько раз в наборе появится i-й шарик для
каждого i = 1, 2, \ldots , n. Обозначим через ki число появлений i-го шарика в
наборе. Во-первых, 0 \leq ki \leq k, а во-вторых,
k1 + k2 + \ldots + kn = k.
Поставим каждому исходу в соответствие набор чисел (k1 , k2 , \ldots , kn ).
Легко видеть, что это соответствие является взаимно однозначным. Такое соответствие можно рассматривать как способ нумерации наборов. (Например,
исходам из замеч. 1.8 ставятся в соответствие следующие номера: {1, 1} ↔
(2, 0), {1, 2} ↔ (1, 1) и {2, 2} ↔ (0, 2).)
Рассмотрим теперь другой эксперимент. Пусть теперь имеется n урн с
номерами i = 1, 2, \ldots , n, в которых размещаются k неразличимых шариков.
Сколько существует способов разложить шарики по урнам? Нас интересует
только количество шариков в i-й урне для каждого i. Обозначим через ki
число шариков в i-й урне. Ясно, что 0 \leq ki \leq k, и что числа ki и в этом
эксперименте тоже удовлетворяют уравнению
k1 + k2 + \ldots + kn = k.
Исходы этого эксперимента тоже взаимно однозначно описываются наборами
чисел (k1 , k2 , \ldots , kn ). Т.о., исходы в эксперименте с урнами и исходы предыдущего эксперимента с ящиком занумерованы одним и тем же набором чисел,
поэтому число исходов в обоих экспериментах одно и то же и равно числу
решений этого уравнения. Вычислим это число для эксперимента с урнами.
Изобразим расположение шариков в урнах с помощью схематичного рисунка. Вертикальными линиями обозначим перегородки между урнами, а
кружками -- шарики, находящиеся в них. Например,
 
    
 • •  • • •  •   • •  • .
На рисунке показаны 9 шариков, рассыпанные по 7 урнам: 1-я и 6-я урны
содержат по 2 шарика, 2-я урна содержит 3 шарика, 3-я и 5-я урны -- пустые
и, наконец, 4-я и 7-я урны содержат по одному шарику.
5

Меняя местами шарики и стенки, можно получить все возможные расположения шариков в урнах. Другими словами, все расположения можно
получить, расставляя k шариков и n − 1 стенок на n − 1 + k местах. Число
n − 1 + k получается следующим образом. Число стенок у n урн равно n + 1,
и т.к. две крайние стенки двигать нельзя, то число стенок, которые можно
двигать равно n − 1. Поэтому шарики могут занимать k мест, а стенки урн
-- оставшиеся n − 1 место. По теор. 1.6 число способов расставить k шариков
на n − 1 + k местах и затем расставить стенки на оставшихся n − 1 местах
k
равно Cn+k−1
. Что и требовалось доказать.

§2. События, операции над ними
и σ-алгебры событий
Теория вероятностей, как и любая современная математическая теория,
начинается с аксиоматических (неопределяемых) понятий. Такими являются
следующие понятия.
1) Понятие: эксперимент = опыт = испытание. Считается, что все три
слова означают одно и то же, т.е. являются синонимами.
2) Понятие: произойти = возникнуть = появиться.
3) Понятие: элементарное событие = элементарный исход = результат
= шанс.
При этом считается, что в результате опыта происходит одно и только
одно элементарное событие.
Определение 2.1. Множество всех элементарных событий данного эксперимента называется пространством элементарных событий, или часто
короче пространством.
Будем обозначать его через \Omega. Ясно, что пространство элементарных событий не пусто, \Omega ̸= ∅.
Как множество пространство \Omega может быть либо конечным1 , либо счётным2 , либо несчётным3 множеством.
Определение 2.2. Конечные и счётные пространства элементарных событий называется дискретным.
Примеры. 1) Эксперимент: подбрасывание монеты. Элементарные события: o -- выпадение орла, p -- выпадение решётки. Пространство \Omega = {o, p}
1

Конечное множество -- множество, количество элементов которого конечно, то есть, существует неотрицательное целое число n, равное количеству элементов этого множества. В противном случае множество
называется бесконечным.
2
Cчётное множество есть бесконечное множество, элементы которого можно пронумеровать натуральными числами. Более формально: множество \Omega является счётным, если существует биекция \Omega ↔ N, где N
обозначает множество всех натуральных чисел.
3
Множество, не являющееся конечным или счетным, называется несчетным.

6

является конечным множеством.
2) Эксперимент: одновременное подбрасывание двух монет одного достоинства. Пространство элементарных событий \Omega = {(o, o), (o, p), (p, p)} является конечным множеством.
3) Эксперимент: подбрасывание одной монеты до выпадения первого орла. Пространство элементарных событий \Omega = {o, po, ppo, pppo, ppppo, pppppo,
\ldots } -- счётное множество.
4) Эксперимент: на стол \Omega = I 2 = I × I садится мыльный пузырь и лопается, оставляя под собой точку (x, y). Элементарное событие: появление на
плоскости точки (x, y). Пространство элементарных событий \Omega -- несчётное
множество.
Определение 2.3. Если пространство \Omega содержит только одно элементарное событие, то эксперимент называется с детерминированным (определённым) исходом; в противном случае эксперимент называется со случайным
исходом.
Определение 2.4. Любое подмножество A ⊂ \Omega пространства элементарных событий называется случайным событием или просто событием. Считается, что событие A произошло, если произошло любое элементарное событие \Omega, содержащееся в A, см. рис. 1.
Определение 2.5. 1) Событие \Omega называется достоверным.
2) Событие ∅ ⊂ \Omega называется невозможным.
Каждое элементарное событие \Omega \in \Omega можно рассматривать как одноэлементное подмножество достоверного события \Omega, т.е. {\Omega} ⊂ \Omega. Для изображения событий можно использовать диаграммы Венна4 .
Пусть A и B -- события, они показаны на рис. 1.

Рис. 1: События в достоверном событии \Omega.
Определение 2.6. 1) Событие A ∪ B называется объединением событий
и состоит в том, что произошло хотя бы одно из событий A или B.
2) Событие A \cap B называется пересечением событий A и B и состоит в
том, что произошли оба события A и B.
4

Джон Венн (John Venn, 1834 – 1923), английский логик.

7

3) Событие A r B называется разностью событий A и B и состоит в том,
что событие A произошло, а B -- нет.
4) Событие A = \Omega r A называется противоположным событию A и состоит в том, что событие A не произошло. Ясно, что A = A (событие, противоположное к противоположному, является исходным событием).
Т.к. ∅ = \Omega r ∅ = \Omega и \Omega = \Omega r \Omega = ∅, то невозможное событие ∅ и
достоверное событие \Omega являются взаимно противоположными (друг другу).
5) Говорят, что событие A влечёт событие B, и пишут A ⊂ B, если при
наступлении события A происходит и событие B.
Определение 2.7. 1) События A и B называются несовместными, если
A \cap B является невозможным событием, т.е. A \cap B = ∅.
2) События A1 , \ldots , An называются попарно несовместными, если для любых 1 \leq i < j \leq n события Ai и Aj несовместны.
Определение 2.8. Рассмотрим множество A, элементами которого являются события пространства \Omega (не обязательно все!). Множество A называется
алгеброй событий, если достоверное событие \Omega и любые события A, B \in A
удовлетворяют аксиомам.
Акс. A1.
\Omega \in A.
Акс. A2.
A ∪ B \in A.
Акс. A3.
A \cap B \in A.
Акс. A4.
A r B \in A.
Из аксиомы A1 следует, что алгебра событий не может быть пустой; она
всегда содержит достоверное событие \Omega. А т.к. \Omega r \Omega = ∅, то из аксиомы A4 следует, что ∅ \in A, т.е. любая алгебра событий A содержит вместе с
достоверным и невозможное событие.
Примеры. 1) Для любого пространства элементарных событий \Omega набор
из двух множеств A0 = {∅, \Omega} удовлетворяет аксиомам A1 – A4, поэтому
A0 = {∅, \Omega} является алгеброй событий. Алгебра событий A0 называется
тривиальной. Это самая маленькая алгебра событий.
2) В этом примере эксперимент -- подбрасывание игральной кости. Пространство элементарных событий есть \Omega = {1, 2, 3, 4, 5, 6}. Пусть событие
A = {1, 3, 5} -- выпадение нечётного числа очков, а событие B = {2, 4, 6}
-- выпадение чётного числа очков. Множество событий A1 = {∅, \Omega, A, B}
удовлетворяет аксиомам A1 – A4, поэтому является алгеброй событий.
3) Для любого пространства элементарных событий \Omega множество P(\Omega) =
{множество всех подмножеств \Omega} удовлетворяет аксиомам A1 – A4, поэтому
является алгеброй событий. Эта алгебра событий является самой большой
на \Omega. Для \Omega = {1, 2, 3, 4, 5, 6} эта алгебра событий содержит 64 события.
4) Задайте ещё какую-нибудь алгебру событий на \Omega = {1, 2, 3, 4, 5, 6}.
Сколько различных алгебр событий можно задать на этом пространстве эле8

ментарных событий?
Замечание 2.9. Из аксиомы A1 – A4 следует, что если к конечному набору событий из любой алгебры событий применить операции объединения,
пересечения и вычитания конечное число раз, то полученное событие тоже
содержится в этой алгебре.
Замечание 2.10. Если пространство элементарных событий конечно,
\Omega = {\Omega_1 , \Omega2 , \ldots , \Omegan }, то любая его алгебра событий тоже конечна. Это следует из того, что множество P(\Omega) всех возможных событий, содержащихся
в \Omega, тоже конечно и содержит 2n событий.
Определение 2.11. Алгебра событий A называется σ-алгеброй, если для
любого счётного набора событий A1 , A2 , \ldots \in A выполнена пятая аксиома.
∞
∪
Акс. A5.
An \in A.
n=1

Замечание 2.12. Из аксиом A1 – A4 не следует, что объединение несчётного количества событий является событием из σ-алгебры. Рассмотрение
несчётных объединений событий приводит к построению т.н. неизмеримых
событий, вероятность наступления которых не существует. Первый пример
такого неизмеримого события построил Витали5 . При построении неизмеримого множества Витали используется аксиома теории множеств -- аксиома
выбора.
Аксиома выбора. Для любого произвольного набора непустых непересекающихся множеств можно составить множество, выбрав в него по
одному элементу из каждого множества этого набора.
Теорема Витали 2.13. (Построение неизмеримого множества.) Существуют множества, длина которых не может быть выражена никаким
числом.
Доказательство. Для доказательства нам понадобятся лишь следующие очевидные свойства длины:
длина дуги остается неизменной при повороте окружности вокруг
центра;
длина дуги, которая представляет собой объединение счетного количества попарно непересекающихся дуг, равна сумме длин этих
дуг.
Рассмотрим стандартную (единичного радиуса) окружность S 1 . Она эквивалентна отрезку [0, 2\pi), т.е. её длина равна 2\pi. На этой окружности центральный угол в радианах равен длине дуги на которую он опирается.
5

Джузеппе Витали (Giuseppe Vitali, 26.08.1875 -- 29.02.1932, Italy) -- итальянский математик.

9

Для любого рационального числа pq , где q ̸= 0, рассмотрим дугу длины 2\pip
q .
Если отложить её на окружности S 1 последовательно q раз, то полученная
дуга замкнётся, т.е. начало 1-ой дуги совпадёт с концом q-ой.
Для любого иррационального числа α рассмотрим дугу длины 2\piα. Ясно,
что если отложить эту дугу n раз на окружности S 1 , то начало и конец
дуги 2\piαn не совпадут ни при каком целом n. Это означает, что множество
A0 = {\ldots , −2\piαn, \ldots , −4\piα, −2\piα, 0, 2\piα, 4\piα, \ldots , 2\piαn, \ldots }
является счётным. Заметим, что для любого целого n поворот на угол 2\piαn
переводит множество A0 в себя.
Если взять произвольную точку (угол) φ \in [0, 2\pi) на окружности, такую
чтобы φ \in
/ A0 , то множество
Aφ = {\ldots , φ − 2\piα n, \ldots , φ − 4\piα, φ − 2\piα, φ, φ + 2\piα, φ + 4\piα, \ldots , φ + 2\piα n, \ldots }

тоже является счётным, и для любого целого n поворот множества Aφ на угол
2\pinα тоже переводит его в себя. Заметим, что т.к. φ \in
/ A0 , то множества A0
и Aφ не пересекаются: если бы они имели общую точку, то при n = ±1, ±2, \ldots
все остальные их точки получились бы прибавлением дуг 2\piα n, и тогда бы
множества A0 и Aφ совпадали. Заметим, что для любого целого n поворот на
угол 2\piαn переводит множество Aφ в себя.
Если теперь выбрать угол ψ \in [0, 2\pi), такой чтобы ψ \in
/ A0 и ψ \in
/ Aφ , то
множество
Aψ = {\ldots , ψ − 2\piα n, \ldots , ψ − 4\piα, ψ − 2\piα, ψ, ψ + 2\piα, ψ + 4\piα, \ldots , ψ + 2\piα n, \ldots }

тоже является счётным, и для любого целого n поворот множества Aψ на
угол 2\piα n тоже переводит его в себя. Заметим, что т.к. ψ \in
/ A0 и ψ \in
/ Aφ , то
множество Aψ не пересекается ни с A0 и ни с Aφ . Заметим, что для любого
целого n поворот на угол 2\piαn переводит множество Aψ в себя.
Процесс построения таких непересекающихся множеств можно продолжить неограниченно6 пока не будут исчерпаны (выбраны) все точки окруж6

В математике различают два типа бесконечности: потенциальная и актуальная бесконечности.
Потенциальная бесконечность означает, что процесс построения какого-либо объекта может быть продолжен неограниченно. В нашем случае процесс построения множеств Aφ , Aχ , Aψ , \ldots может быть продолжен неограниченно (если не принимать во внимание, какое время может быть потрачено на это построение). Другой пример потенциальной бесконечности возникает при построении натурального ряда.
Если мы выпишем все натуральные числа от 1 до n, то ничто не мешает нам написать число n + 1, и т.д.
Потенциальная бесконечность есть бесконечный процесс построения объектов, у которого нет последнего
шага. Например, в доказательстве по методу математической индукции.
Под актуальной бесконечностью понимается бесконечная совокупность, построение которой завершено, и все ее элементы наличествуют одновременно. Например, мы будем иметь дело с актуальной
бесконечностью, если перечислим весь натуральный ряд полностью и имеем его в законченном виде
N = {1, 2, \ldots , n, \ldots }. Актуальная бесконечность представляет собой весьма сильную идеализацию. В
самом деле, она допускает не только возможность построения последующего объекта, если построен
предыдущий, но и постулирует, что все возможные объекты уже построены и существуют одновременно.
В нашем случае актуальная бесконечность означает, что процесс построения множеств A0 , Aφ , Aψ , \ldots
закончен, и мы имеем это множество множеств {A0 , Aφ , Aψ , \ldots } налицо.

10

ности S 1 . В каждом таком множестве содержится счетное число точек, и все
точки в одном множестве получаются друг из друга поворотами на угол 2\piα.
Разные множества не пересекаются. Таким образом, окружность S 1 является
объединением непересекающихся множеств A0 , Aφ , Aψ , \ldots т.е.
∪

1

S =

Aλ .

λ\in{0,φ, ψ, ... }

Объединение счётного набора счётных множеств есть счётное множество.
А т.к. окружность S 1 состоит из несчетного множества точек, то набор построенных множеств A0 , Aφ , Aψ , \ldots является несчётным. Другими словами
множество индексов {0, φ, ψ, \ldots , } -- несчётное.
Выберем из каждого множества A0 , Aφ , Aψ , \ldots ровно по одной точке и
по аксиоме выбора составим из этих точек множество B0 . Построенное множество B0 называется множеством Витали. Для каждого n = ±1, ±2, \ldots
обозначим через Bn множество, которое получается в результате поворота
множества B0 на угол 2\pinα. Ясно, что все множества Bn , n \in Z, имеют одну
и ту же длину. Т.к. все точки множества Aλ , где λ \in {0, φ, ψ, \ldots }, можно получить, поворачивая одну из них на углы 2\pinα, и т.к. в множестве B0
собраны по одной точке из каждого множества Aλ , то объединение всех Bn
составляет окружность S 1 , т.е.
1

S =

∞
∪

Bn .

n=−∞

Оставшуюся часть доказательства проведём методом от противного. Предположим, что длина множества Витали B0 существует, и обозначим её через \mu(B0 ). Тогда все множества Bn имеют одну и ту же длину, т.к. получены
из B0 поворотом на угол кратный 2\piα. Т.к. множества Bn не пересекаются,
то сумма их длин равна длине окружности S 1 . Поэтому
( ∞
)
∞
∞
∪
∑
∑
1
2\pi = \mu(S ) = \mu
Bn =
\mu (Bn ) =
\mu (B0 ) =
n=−∞

{
=

n=−∞

n=−∞

∞, если \mu (B0 ) > 0
.
0, если \mu (B0 ) = 0

Полученное противоречие означает, что длины у множества Витали B0
нет вообще никакой (ни нулевой, ни конечной, ни бесконечной). Такие множества и соответствующие им события называются неизмеримыми.
11

Замечание 2.14. 1) В предыдущем примере было доказано существование неизмеримого множества (множества Витали) и предъявлена конструкция его построения. Меняя иррациональное число α, можно получить несчётное количество неизмеримых множеств на окружности S 1 = [0, 2\pi). Если
аксиому выбора не признавать, то неизвестно можно ли вообще построить
неизмеримые множества. Можно доказать, что аксиома A5 не допускает появление неизмеримых событий.
2) Если \Omega -- несчётное множество (отрезок, площадка, объёмное тело),
то множество P(\Omega) всех подмножеств множества \Omega не является σ-алгеброй,
потому что оно содержит неизмеримые события.
Замечание 2.15. Все конечные и счётные алгебры событий являются
σ-алгебрами.
Лемма 2.16. Если {A1 , A2 , \ldots } есть счётный набор событий из
∞
\cap
σ-алгебры A, то
An \in A.
n=1

Доказательство. Пусть A1 , A2 , \ldots \in A, Тогда из аксиомы A4 следует, что
∞
∪
A1 , A2 , \ldots \in A, а из аксиомы A4 следует, что
An \in A. Тогда по аксиоме 4
n=1

дополнение к этому множеству тоже принадлежит A, т.е.
формулам двойственности де Моргана

∞
∪

An =

n=1

∞
\cap

∞
∪

An \in A. По

n=1

An , поэтому

n=1

∞
\cap

An \in A.

n=1

Следствие 2.17. Лемма 2.16 и аксиома A5 эквивалентны.

§3. Вероятность и её свойства
Определение 3.1. Пусть \Omega -- пространство элементарных событий, и
A -- его σ-алгебра событий. Вероятностью называется функция множества
P : A \to R, удовлетворяющая следующим аксиомам:
Акс. P1 (неотрицательность вероятности). Для любого события A \in A
выполнено неравенство P(A) ≥ 0.
Акс. P2 (нормированность вероятности). P(\Omega) = 1.
Акс. P3 (счётная аддитивность вероятности как функции множества).
Для любого счётного набора попарно несовместных событий A1 , A2 , \ldots \in A
имеет место равенство
(∞ )
∞
∪
∑
P
An =
P (An ) .
n=1

n=1

12

В частности, эта аксиома справедлива и для конечного набора попарно несовместных событий.
Акс. P4 (непрерывность вероятности). Для любой убывающей последовательности событий A1 ⊃ A2 ⊃ \ldots ⊃ An ⊃ \ldots из σ-алгебры A такой, что
∞
\cap
An = ∅, выполняется равенство
n=1

lim P(An ) = 0.

n\to∞

Определение 3.2. Тройка (\Omega, A, P) называется вероятностным пространством.
Докажем теперь основные свойства вероятности пп. 3.3 – 3.12.
Лемма 3.3. Если событие A влечёт событие B, т.е. A ⊆ B, то
P(B r A) = P(B) − P(A), см. рис. 2.
Доказательство. Т.к. B = A∪(B rA), и события A и B rA несовместны, то
по аксиоме P3 имеем P(B) = P(A)+P(BrA), что и требовалось доказать.

Рис. 2: Если A ⊆ B, то P(B r A) = P(B) − P(A).
Следствие 3.4. Если A ⊆ B, то P(A) \leq P(B).
Лемма 3.5. P(∅) = 0.
Доказательство. P(∅) = P(\Omega r \Omega) = P(\Omega) − P(\Omega) = 1 − 1 = 0.
Лемма 3.6. Для любого события A \in A выполнено неравенство
0 \leq P(A) \leq 1.
Доказательство. Т.к. ∅ ⊆ A ⊆ \Omega, то из след. 3.4 следует утверждение
леммы.
Лемма 3.7. Для любого события A \in A имеем P(A) = 1 − P(A).
Доказательство. P(A) = P(\Omega r A) = P(\Omega) − P(A) = 1 − P(A).
13

Лемма 3.8. Для любых событий A, B \in A выполнено равенство
P(A ∪ B) = P(A) + P(B) − P(A \cap B), см. рис. 1.
Доказательство. Т.к. A ∪ B = A ∪ (B r (A \cap B)), и события A и
B r (A \cap B) несовместны, то применяя сначала Акс. P3, а затем лемму 3.3
получим P(A ∪ B) = P(A) + P(B r (A \cap B)) = P(A) + P(B) − P(A \cap B).
Следствие 3.9. Для любых событий A, B \in A выполнено неравенство
P(A ∪ B) \leq P(A) + P(B).
Следствие 3.10. Если события A и B несовместны, т.е. A \cap B = ∅,
то P(A ∪ B) = P(A) + P(B).
Доказательство. По лемме 3.8 имеем P(A ∪ B) = P(A) + P(B) − P(A \cap B) =
P(A) + P(B) − P(∅) = P(A) + P(B).
Следствие 3.11. P(A1 ∪ \ldots ∪ An ) \leq

n
∑

P (Ai ) .

i=1

Теорема 3.12. P(A1 ∪ A2 ∪ \ldots ∪ An ) =
+

∑

n
∑

P(Ai ) −

i=1

∑

P(Ai \cap Aj )+

1\leqi<j\leqn

P(Ai \cap Aj \cap Am ) − \ldots + (−1)n−1 P(A1 \cap A2 \cap \ldots \cap An ).

1\leqi<j<m\leqn

Доказательство. Применяя метод математической индукции и лемму 3.8
получим требуемый результат.

§4. Способы задания и подсчёта вероятности
4.1. Экспериментальное нахождение вероятности
В этом пункте описан способ экспериментального определения вероятности
наступления так называемых массовых событий.
Определение 4.1. Событие A называется массовым, если опыт (эксперимент, испытание), при котором событие A может произойти, можно повторить неограниченное число раз при одних и тех же условиях.
Методами теории вероятностей изучают (в основном) эксперименты, которые порождают массовые события. Всюду до конца лекций будут рассматриваться только массовые события.
Примеры 4.2. 1) Опыт: однократное подбрасывание ломаного гроша.
События выпадение орла O и выпадение решки P являются массовыми событиями. Заметим, что пространство элементарных событий \Omega = {O, P }
состоит из конечного числа элементарных исходов.
14

2) Опыт: подбрасывание ломаного гроша до появления первого орла. События P , OP , OOP , \ldots, O \ldots OP , \ldots являются массовым. Заметим, что в
этом примере пространство \Omega = {P, OP, OOP, \ldots , O \ldots OP, \ldots} состоит из
счётного количества элементарных исходов: положение кольца однозначно
определяется положением его центра.
3) Опыт: бросание обручального кольца на клетчатую скатерть (диаметр
кольца меньше стороны клетки). Событие A: кольцо падает внутрь какойнибудь клетки, не пересекая её границы. Это событие является массовым.
Заметим, что в этом примере пространство состоит из несчётного количества
элементарных исходов.
Типичность этих трёх примеров состоит в том, что в теории вероятностей встречаются три типа пространств элементарных событий: конечные,
счётные и несчётные.
Определение 4.3. Если в результате n испытаний массовое событие A
произошло \mu(A) раз, то число \mu(A)
называется относительной частотой
n
появления события A.
Для каждого примера 4.2 можно провести n опытов, сосчитать число \mu(A)
появлений этого события и подсчитать относительную частоту \mu(A)
n .
Массовые события обладают свойством "статистической устойчивости," а
именно: при увеличении числа экспериментов относительная частота \mu(A)
n
появления события A имеет тенденцию стабилизироваться, стремясь к
некоторому числу P(A).
Определение 4.4. Число P(A) = lim \mu(A)
называется статистической
n\to∞ n
вероятностью события A и находится при больших n по приближённой формуле P(A) ≃ \mu(A)
n .

4.2. Вероятность на конечном пространстве.
Пусть задано конечное пространство \Omega = {\Omega_1 , \Omega2 , \ldots , \Omegan }, состоящее из
n элементарных событий (исходов), и заданы вероятности наступления этих
событий P(\Omega_1 ) = p1 , P(\Omega2 ) = p2 , \ldots , P(\Omegan ) = pn так, что p1 + p2 + \ldots + pn = 1.
Обозначим через \Omega переменную величину, принимающую значения из \Omega.
Определение 4.5. Такое соответствие записывает в виде таблицы
\Omega \Omega_1 \Omega2 \ldots \Omegan
,
P(ξ) p1 p2 \ldots pn
которая называется рядом распределения случайных исходов или законом
распределения. Если n = 2, то ряд называется схемой Бернулли. Если n ≥ 3,
то ряд называется схемой независимых испытаний с несколькими исходами.
15

Рад распределения задаёт функцию в виде таблицы, которая каждому
элементарному исходу ставит в соответствие вероятность его наступления.
Потребуем теперь выполнение акс. P3.
Лемма-определение 4.6. (Формула вероятности на конечном пространстве.) Если вероятность, определяемая рядом распределения из опред. 4.5,
подчиняется акс. P3, то вероятность события A = {\Omegai1 , \Omegai2 , \ldots , \Omegaik } ⊂ \Omega
вычисляется по формуле
P (A) = pi1 + pi2 + \ldots + pik ,
которая называется формулой вероятности на конечном пространстве.
(
)
k
k
)
∪
P3 ∑ (
Доказательство. P (A) = P (\Omegai1 , \Omegai2 , \ldots , \Omegaik ) = P
{\Omegaij } =
P \Omegaij =
j=1

=

k
∑

j=1

pij = pi1 + pi2 + \ldots + pik .

j=1

Пример 4.7. Простейший ряд распределения имеет эксперимент с детерминированным исходом, \Omega = {\Omega} (см. опред. 2.3):
ξ \Omega
.
P 1
Этот тривиальный случай удовлетворяет всем аксиомам и определениям, однако никакого значения в теории вероятностей не имеет. Придётся с этим
мириться.
Определение 4.8. Путь в результате опыта могут возникнуть только
два события: «успех», который обозначается единицей -- 1 и наступает c
вероятностью p, и «неудача», которая обозначается нулём -- 0 и наступает c
вероятностью q = 1−p; \Omega = {0, 1}. Такой опыт называется схемой Бернулли7
и имеет ряд распределения
ξ
0
1
.
P q =1−p p
Схема Бернулли является первым нетривиальным примером вероятности на
конечном пространстве.
Схема Бернулли имеет простую интерпретацию. Рассмотрим ломаный
грош с вероятностями выпадения орла p и решки q = 1 − p. Обозначим
появление орла через 1, а его не выпадение через 0, получим схему Бернулли.
7

Якоб Бернулли (Jakob Bernoulli, 1654 -- 1705), швейцарский математик.

16

Геометрическая интерпретация 4.9 (схемы независимых испытаний
с несколькими исходами). Рассмотрим произвольный выпуклый многогранника с n гранями, на которых написаны символы \Omega_1 , \Omega2 , \ldots , \Omegan ; при этом
многогранник должен быть таким, чтобы перпендикуляр, опущенный из его
центра тяжести на любую грань, пересекал эту грань в её внутренней точке (чтобы многогранник, падая на эту грань, не перекатывался на другую).
Пусть вероятности выпадения многогранника гранью вниз равны соответственно p1 , p2 , \ldots , pn , где естественно p1 +p2 +\ldots+pn = 1. Легко видеть, что
вероятность pi пропорциональна телесному углу αi с вершиной C в центре
тяжести многогранника, опирающегося на грань \Omegai ; а т.к. сумма всех телесных углов с вершиной C равна 4\pi стерадиан, т.е. α1 + α2 + \ldots + αn = 4\pi, то
α1
α2
αn
αi
4\pi + 4\pi + \ldots + 4\pi = 1, поэтому pi = 4\pi .

4.3. Классическая вероятность
Классическая вероятность является частным случаем вероятности на конечном пространстве, когда вероятность подчинена принципу равной вероятности. Исторически классическая вероятность применялась в теории азартных игр и появилась раньше вероятности на конечном пространстве.
Принцип равной вероятности. Если на конечном пространстве \Omega вероятность наступления его элементарных исходов \Omega_1 , \Omega2 , \ldots , \Omegan одна и
та же,
p1 = p2 = \ldots = pn = p,
то говорят, что вероятность на конечном пространстве удовлетворяет
принципу равной вероятности (или равной возможности).
Выпадение орла и решки при подбрасывании симметричной монеты; выпадение граней при подбрасывании правильного многогранника (тетраэдра,
куба, октаэдра, додекаэдра или икосаэдра); появление к.-л. карты из полной
колоды карт удовлетворяют принципу равной возможности.
Классическая вероятность характеризуется только числом элементарных
исходов n в пространстве \Omega. Она имеет ряд распределения
\Omega
\Omega_1 \Omega2 \ldots \Omegan
,
P(\Omega) p p \ldots p
где np = 1, поэтому p = n1 .
Лемма 4.10. (Формула классической вероятности.) Если вероятность P
удовлетворяет принципу равной возможности, то вероятность наступ17

ления события A = {\Omegai1 , \Omegai2 , \ldots , \Omegaik } ⊂ \Omega определяется по формуле, называемой формулой классической вероятности,
P(A) =

k
.
n

Доказательство. P (A) = pi1 + pi2 + \ldots + pik = kp =

k
n

Если обозначить число k элементов множества A через \mu(A), а число n
элементов пространства \Omega через \mu(\Omega), то формулу классической вероятности
можно записать в виде
\mu(A)
P(A) =
.
\mu(\Omega)
Число \mu(A) = k называется числом исходов, благоприятствующих наступлению события A.
Замечание 4.11. 1) Вероятности элементарных исходов в экспериментах
с шариками, описанные в теоремах 1.4, 1.6 и 1.7, удовлетворяют принципу
равной возможности. Эти вероятности соответственно 1/Akn , 1/Cnk и 1/nk .
2) Вероятности элементарных исходов в теор. 1.9 (выбор с возвращением
и без учёта порядка) не удовлетворяют этом принципу. Например, при n = 2
и k = 2 вероятности элементарных событий имеют ряд распределения

\Omega
(1, 1) (1, 2) (2, 2)
.
P(\Omega) 1/4
1/2
1/4
3) Следует отметить, что при рассмотрении подобных вопросов ошибались даже такие великие математики, как, например, Д’Аламбер. Так, однажды у Даламбера спросили, с какой вероятностью монета, брошенная дважды, хотя бы один раз выпадет гербом. Ответ учёного был 23 , т.к. он считал, что есть 3 возможных исхода (герб-герб, герб-решка, решка-решка) и
среди них 2 благоприятствующих. Д’Аламбер пренебрегал тем, что эти три
возможных исхода не равновозможны. Правильным ответом является 34 , поскольку из четырёх равновозможных исходов (герб-герб, герб-решка, решкагерб, решка-решка) три благоприятствуют указанному событию. Точка зрения Д’Аламбера была даже опубликована во Французской энциклопедии в
1754 г. в статье "Герб и решётка"("Croix on pile").
18

4.4. Вероятность на счётном пространстве
Пусть теперь \Omega = {\Omega_1 , \Omega2 , \ldots , \Omegan , \ldots } – счётное пространство. Пусть p1 +p2 +
\ldots + pn + \ldots = 1 -- сходящийся (к единице) числовой ряд, удовлетворяющий
для всех i \in N условию 0 < pi < 1. Последнее условие позволяет трактовать
члены этого ряда как вероятности элементарных событий пространства \Omega.
Определение 4.12. Вероятность элементарных исходов, заданная в виде
таблицы
\Omega
\Omega_1 \Omega2 \ldots
P(\Omega) p1 p2 \ldots

\Omegai \ldots
,
pi \ldots

называется рядом распределения на счётном пространстве.
Потребуем теперь выполнение акс. P3.
Лемма 4.13. (Формула вероятности на счётном пространстве.) Если события из пространства \Omega подчиняются акс. P3, то вероятность события
A = {\Omegai1 , \Omegai2 , \ldots , \Omegaik , \ldots } ⊂ \Omega вычисляется по формуле
P (A) = pi1 + pi2 + \ldots + pik + \ldots .
(
Доказательство. P (A) = P (\Omegai1 , \Omegai2 , \ldots , \Omegaik , \ldots ) = P
P3

=

)
{\Omegaij }

P3

=

j=1

∞
∞
( ) ∑
∑
P \Omegaij = pij = pi1 + pi2 + \ldots + pik + \ldots.
j=1

∞
∪

j=1

Замечание 4.14. Каждому степенному ряду на той части его интервала
сходимости, на которой его члены положительны, можно поставить в соответствие параметрическое семейство распределений со счётным пространством.
Рассмотрим, например, экспоненту eλ . Её ряд МакЛорена
1+

λk
λ λ2
+
+ \cdot\cdot\cdot +
+ \ldots = eλ
1! 2!
k!

сходится при всех значениях −∞ < λ < ∞ и имеет положительные члены
при λ > 0. Умножим обе части этого тождества на e−λ , получим тождество
e−λ +

λ −λ λ2 −λ
λk
e + e + \ldots + e−λ + \ldots = 1 .
1!
2!
k!

Составим следующий ряд распределения
k
0
Pλ (k) e−λ

1
λ −λ
1! e

2
...
λ −λ
...
2! e
2

19

k
...
.
λ −λ
...
k! e
k

Определение 4.15. Распределение, реализуемое этим рядом, называется
распределением Пуассона с параметром λ.
На рис. 25 показаны функции Pλ (k) для для параметра λ = 0, 1; 1; 10, где
пунктиром показаны огибающие. В каждом случае сумма длин вертикальных
отрезков равна 1.
k −λ
Распределение Пуассона описывает, например, вероятность Pλ (k) = λ k!e
поступления на телефонную станцию k звонков за какой-нибудь фиксированный промежуток времени, где число звонков k = 0, 1, 2, \ldots .
Замечание 4.16. Другим источником построения распределений со счётным пространством являются сходящиеся числовые ряды с положительными
членами. Например, известно (Л. Эйлер), что
1
1
1
1
\pi2
+ + + \cdot\cdot\cdot + 2 + \cdot\cdot\cdot = .
12 22 32
k
6
2

Разделив обе части этого числового тождества на \pi6 , можно получить (безымянный) ряд распределения, определённым по формуле P(k) = k12 \cdot \pi62 = \pi26k2 ,
со счётным пространством \Omega = N.
Среди числовых рядов наиболее встречающимися в теории вероятностей
являются геометрические прогрессии с положительными членами.
Определение 4.17. Если члены ряда p1 + p2 + \ldots + pn + \ldots = 1 положительны и являются членами убывающей геометрической прогрессией с
первым членом p1 = p и с знаменателем q = 1 − p, то вероятность на счётном
пространстве называется геометрическим распределением.
Геометрическое распределение имеет ряд
τ1 \Omega_1 \Omega2 \ldots
P p qp \ldots

q

\Omegak
k−1

...
.
p ...

Пример 4.18. Рассмотрим схему Бернулли (ломаного гроша) с вероятностью "успеха (выпадения орла) = 1" равной p. Она имеет ряд распределения
ξ
0
1
.
P 1−p p
Пусть эксперимент состоит в том, что испытания по схеме Бернулли проводятся неограниченное число раз. С таким экспериментом связаны две случайные величины: τ1 -- номер первого выпавшего орла и τ0 -- число выпавших решек, появившихся до первого орла. Легко подсчитать, что случайные
величины τ0 и τ1 имеют ряды распределения
τ0 0 1 \ldots
P p qp \ldots

k ...
qk p \ldots

и
20

τ1 1 2 \ldots
P p qp \ldots

k
q

k−1

...
.
p ...

В строке вероятностей эти ряды содержат одну и ту же геометрическую
прогрессию; они называются соответственно τ0 - и τ1 -геометрическим распределениями. Эти случайные величины связаны очевидной формулой τ1 =
τ0 + 1.
Формула вероятность для τ0 -геометрического распределения определена
по формуле
P(τ0 = k) = q k p,
где 0 < p < 1 и q = p − 1.
Формула вероятность для τ1 -геометрического распределения:
P(τ1 = k) = q k−1 p,
где 0 < p < 1 и q = p − 1.

4.5. Геометрическая вероятность
Рассмотрим ограниченную измеримую область \Omega ⊂ Rn , состоящую из несчётного множества точек. Измеримость области означает: на прямой область
\Omega ⊂ R1 имеет конечную ненулевую длину, на плоскости область \Omega ⊂ R2
имеет конечную ненулевую площадь, в пространстве область \Omega ⊂ R3 имеет
конечный ненулевой объём и т.д. Пусть на \Omega определена σ-алгебра A. Для
любого события A \in A обозначим через \mu(A) его меру (длину, площадь, объём и т.д. соответственно). Пусть эксперимент состоит в том, что в область \Omega
бросают точку.
Принцип равномерности8 . Если для любого события A \in A его вероятность задаётся по формуле
P(A) = α\mu(A),
где α -- постоянное число, независящее от выбора события A (т.е. не зависящее от формы A и его расположения в \Omega), то говорят, что вероятность
P(A) удовлетворяет принципу равномерности.
Лемма 4.19. Если вероятность P(A) удовлетворяет принципу равномерности, то
1
α=
.
\mu(\Omega)
Доказательство. Подставим в формулу P(A) = α\mu(A) достоверное событие \Omega \in A, получим: 1 = α\mu(\Omega).
8

Вероятности, которые не подчиняются этому принципу, являются главным предметом изучения теории вероятностей. Они будут изучены в гл. 2. «Теория случайных величин».

21

Определение 4.20. Полученная формула
P(A) =

\mu(A)
\mu(\Omega)

называется формулой геометрической вероятности. (Не путать с геометрическим рядом распределения!)

Рис. 3: Задача Бюффона.

Рис. 4: Пространство элементарных событий \Omega в задаче Бюффона.
Пример: задача Бюффона 4.21. (1777 г.) На плоскости нарисовано
счётное множество параллельных прямых. Расстояние между соседними прямыми равно a. На плоскость брошена игла длины ℓ < a. Какова вероятность
того, что игла пересечёт одну из прямых?
Решение. Возможные положения иглы на плоскости полностью определяются двумя координатами: расстоянием x от середины иглы до ближайшей
прямой и острым углом φ между иглой и перпендикуляром к параллельным
прямым, см. рис. 3. Ясно, что x \in [0, a2 ] и φ \in [0, \pi2 ]. Поэтому множество
\Omega = [0, \pi2 ] × [0, a2 ] есть пространство элементарных исходов этого эксперимента, см. рис. 4, и \mu(\Omega) = \pia
4 .
Событие A = {игла пересечёт одну из прямых} эквивалентно неравенству
A = {x \leq 2ℓ cos φ}, поэтому множество благоприятных исходов располагается
22

в пространстве \Omega под графиком x = 2ℓ cos φ. Вычислим
\pi

∫2
\mu(A) =

ℓ
ℓ
cos φ dφ = sin φ
2
2

0

\pi
2

ℓ
= .
2
0

2ℓ
Отсюда получаем P(A) = \mu(A)
\mu(\Omega) = \pia .
"Парадокс" Бертрана9 4.22. (1888 г.) В круге наудачу выбирается хорда. Какова вероятность того, что её длина будет больше, чем длина стороны
вписанного в круг правильного треугольника?
Решение. Обозначим через A событие, состоящее в том, что длина хорды
будет больше, чем длина стороны вписанного в круг правильного треугольника. Существует по крайней мере три способа "выбрать наудачу" хорду в
круге.

Рис. 5: Парадокс Бертрана.
1-й способ. Зафиксируем один конец хорды O на окружности. Положение другого конца хорды M будем считать равномерно распределённым на
окружности, см. рис. 5.1. Пусть координата конца M хорды есть длина дуги
OM окружности, проходимой против часовой стрелки, тогда пространство
элементарных событий \Omega есть окружность, т.е. \mu(\Omega) = 2\piR. Благоприятным
исходом является положение конца хорды на дуге BC. Событие A всех благоприятных исходов есть дуга BC, которая составляет третью часть окруж\mu(A)
1
ности, т.е. \mu(A) = 2\pi
3 R. Поэтому P(A) = \mu(\Omega) = 3 .
2-й способ. Для каждой точки M внутри круга (кроме его центра10 ) существует единственная хорда, для которой точка M является её серединой,
см. рис. 5.2. Поэтому, бросая точку M в круг радиуса R, можно по ней однозначно восстановить хорду. Середину M хорды будем считать равномерно
9

Жозеф Луи Франсуа Бертран (Joseph Louis Francois Bertrand, 1822 -- 1900), французский математик.
Т.к. вероятность попадания точки в центр круга равна нулю, то наступление этого события не влияет
на вероятность какого-либо события.
10

23

распределённой в круге. Пространство элементарных событий \Omega есть круг
радиуса R, его площадь \mu(\Omega) = \piR2 . Благоприятными событию A являются
положения середины M хорды внутри окружности, вписанной в треугольник. Легко подсчитать, что радиус вписанной окружности равен R2 . Поэтому
2
1
\mu(A) = \piR4 и P(A) = \mu(A)
\mu(\Omega) = 4 .
3-й способ. Можно ограничиться рассмотрением только хорд, которые
перпендикулярны какому-нибудь диаметру, например BC (остальные положения могут быть получены поворотом), см. рис. 5.3. Середину хорды будем
считать равномерно распределённой на диаметре BC. Пространство элементарных событий \Omega есть диаметр BC, которому перпендикулярны хорды, его
длина \mu(\Omega) = 2R. Благоприятными событию A являются положения середины хорды на отрезке DE, лежащем на диаметре BC, так что центр отрезка DE совпадает с центром круга. Можно видеть, что длина отрезка DE
1
есть \mu(A) = R. Поэтому P(A) = \mu(A)
\mu(\Omega) = 2 .
Причина разных ответов заключается в том, что условие в круге наудачу выбирается хорда определяет эксперимент не однозначно. В решении мы
провели три разных эксперимента по выбору хорды, и поэтому каждом случае был получен правильной ответ.

§5. Независимые события
Определение 5.1. События A и B называются независимыми, если выполняется тождество
P(A \cap B) = P(A)P(B),
в противном случае они называются зависимыми.
Примеры. 1) Рассмотрим колоду карт в 52 листа. Пусть событие A означает вытянуть пику ♠, а B означает вытянуть даму Д, Тогда событие A \cap B
означает вытянуть пиковую даму Д♠. Легко подсчитать вероятности этих
событий P(A \cap B) = 1/52; P(A) = 1/4 и P(B) = 1/13. Подставив эти вероятности в равенство опред. 5.1, получим тождество 1/52 = 1/4 \cdot 1/13; т.е. по
опред. 5.1 события A и B независимы (в этой колоде).
2) Рассмотрим полную колоду карт в 54 листа (с двумя шутами). Пусть
события A и B -- те же как в предыдущем пункте. Легко подсчитать, что в
этой колоде P(A \cap B) = 1/54, P(A) = 13/54 и P(B) = 2/27. Таким образом
1/54 ̸= 13/54 \cdot 2/27, и по опред. 5.1 события A и B являются зависимыми в
полной колоде.
Получилось, что свойство быть или не быть независимыми зависит не от
самих событий, а от строения пространства \Omega (52 или 54).
24

Лемма 5.2. Если события A и B независимы, то пары событий A и B,
A и B, A и B тоже являются независимыми.
Доказательство.
Докажем, что события A и B независимы. Так как A =
∪
(A \cap B) (A \cap B), и события A \cap B и A \cap B несовместны, то P(A) = P(A \cap
B) + P(A \cap B). Поэтому P(A \cap B) = P(A) − P(A \cap B) = P(A) − P(A)P(B) =
P(A)(1 − P(B)) = P(A)P(B).
Независимость пар событий A и B, A и B доказывается аналогично. Доказать самостоятельно.
Определение 5.3. События A1 , \ldots , An называются независимыми в совокупности, если для 1 \leq i1 < \ldots < ik \leq n выполнено равенство
P(Ai1 \cap \ldots \cap Aik ) = P(Ai1 ) \cdot \ldots \cdot P(Aik ).
Замечание 5.4. Если события A1 , \ldots , An независимыми в совокупности,
то они попарно независимы. Чтобы это увидеть, достаточно в последнем равенстве положить k = 2. Обратное, как показывает следующий пример, не
верно.

Рис. 6: Тетраэдр Бернштейна.
Тетраэдр Бернштейна11 5.5. Рассмотрим правильный тетраэдр, три
грани которого окрашены в эти синий, зелёный, и красный цвет, см. рис.6,
а четвёртая грань разделена на три треугольника, и эти треугольники окрашены в те же три цвета. Обозначим через B, G и R события означающие
выпадение снизу грани, содержащей соответственно синий (blue), зелёный
(green), и красный (red) цвета.
Легко видеть, что каждый цвет нарисован на двух из четырёх граней
поэтому P(B) = P(G) = P(R) = 1/2. Также легко видеть, что появление
любой пары из них имеет вероятности P(B \capG) = P(G\capR) = P(B \capR) = 1/4.
Т.о., для каждой пары из этих событий формула опред. 5.1 выполнена, и
следовательно события попарно независимы.
11

Сергей Натанович Берншейн (1880 -- 1968), советский математик.

25

Теперь проверим независимость событий B, G и R в совокупности. Легко
видеть, что вероятность P(B \cap G \cap R) выпадения трёхцветной грани равна
1/4. Это левая часть равенства опред. 5.3. Правая часть равна P(B) \cdot P(G) \cdot
P(R) = 1/8. Т.е. равенство опред. 5.2 не выполнено, значит события B, G
и R зависимы в совокупности.

§6. Условная вероятность
Пример. Игральную кость подбрасывают один раз. Известно, что выпало
более трёх очков. Какова при этом вероятность того, что выпало чётное число
очков?
2
Решение. \Omega_1 = {4, 5, 6}, A = {4, 6}, и P(A) = \mu(A)
\mu(\Omega) = 3 .
Замечание 6.1. Пусть \Omega -- пространство элементарных событий и B ⊂ \Omega
-- событие, отличное от невозможного, т.е. B ̸= ∅. Пусть A ⊂ \Omega – другое
событие. Какова вероятность того, что произойдёт событие A, при условии,
что событие B произошло? Слова событие B произошло означают, что новым пространством элементарных событий становится событие \Omega_1 = B и его
мера равна \mu(\Omega_1 ) = \mu(B). Слова произойдёт событие A, если событие B
произошло означают ту часть события A, которая содержится в B, т.е. означают произойдёт событие A \cap B. Ясно, что A \cap B ⊂ \Omega и A \cap B ⊂ B = \Omega_1 .
Определение 6.2. Для того, чтобы подчеркнуть, что событие A \cap B есть
событие из нового пространства элементарных событий \Omega_1 = B его обозначают A|B и называют событие A при условии, что событие B произошло.
Очевидно, что P(A|B) = \mu(A|B)
\mu(B) . Вероятность P(A|B) называется условной
вероятностью.
Лемма 6.3. P(A|B) = P(A\capB)
P(B) .
Доказательство. P(A|B) =

\mu(A|B)
\mu(B)

=

\mu(A\capB)
\mu(B)

=

\mu(A\capB)
\mu(\Omega)
\mu(B)
\mu(\Omega)

=

P(A\capB)
P(B) .

Следующая формула непосредственно следует из леммы 6.3 и традиционно называется теоремой умножения.
Теорема 6.4. (Теорема умножения для двух событий.) Если P(B) > 0,
P(A) > 0, то
P(A \cap B) = P(B)P(A|B) = P(A)P(B|A).
Теорема 6.5. (Теорема умножения для n событий.)
P(A1 \capA2 \cap\ldots\capAn ) = P(A1 )P(A2 |A1 )P(A3 |A1 \capA2 )\cdot... \cdotP(An |A1 \capA2 \cap\ldots\capAn−1 ),
если все условные вероятности определены.
26

Доказательство. Доказать методом математической индукции.

§7. Формула полной вероятности и
формулы Байеса
Пример. Три завода производят одну и ту же машину Renault. При этом
1-й завод производит 20%, 2-й -- 30%, 3-й -- 50% автомобилей. Брак на 1-м
заводе составляет 5%, на 2-м -- 2%, на 3-м -- 4% автомобилей. Автомашины
случайным образом поступают в продажу. Найти
а) вероятность купить бракованную машину и
б) условную вероятность того, что машина изготовлена на 1-м заводе.
Решение. а) Т.к. сборка машин на заводах не зависима (опред. 6.1), и
сборка машин на них не совместна (аксиома P3), то вероятность купить бракованную машину равна доле бракованных машин во всей продукции, то есть
0, 05 \cdot 0, 2 + 0, 02 \cdot 0, 3 + 0, 04 \cdot 0, 5 = 0, 036.
б) Во этом случае условная вероятность покупки бракованной машины с
1-го завода равна доле брака 1-го завода среди всего количества бракованных
машин
0, 05 \cdot 0, 2
0, 01
=
= 0, 2(7).
0, 05 \cdot 0, 2 + 0, 02 \cdot 0, 3 + 0, 04 \cdot 0, 5 0, 036
Определение 7.1. Если события H1 , H2 , \ldots ⊂ \Omega
1) попарно несовместны (т.е. Hi \cap Hj = ∅ при i ̸= j),
2) их объединение составляет всё пространство элементарных событий, т.е.
∞
∪

Hi = \Omega,

i=1

3) P(Hi ) > 0 для всех i \in N,
то совокупность {H1 , H2 , \ldots } называется полной группой событий, а события H1 , H2 , \ldots называются гипотезами.
На рис.7 показана полная группа событий и некоторое событие A в проТеорема 7.2 (формула полной вероятности). Пусть H1 , H2 , \ldots -- полная
странстве \Omega.
группа событий. Тогда вероятность любого события A ⊂ \Omega вычисляется
по формуле
∞
∑
P(A) =
P(Hi ) P(A|Hi ).
i=1

27

Рис. 7: Полная группа событий и некоторое событие A в пространстве \Omega.
(∞ )
∞
∪
∪
Доказательство. Заметим, что A = A \cap \Omega = A \cap
Hi = A \cap Hi , где
i=1

i=1

события A \cap H1 , A \cap H2 , \ldots -- попарно несовместны. Используя сначала
аддитивность вероятности (аксиома P3), а затем теорему умножения 6.3,
∞
∞
∑
∑
получим требуемый результат P(A) = P(A \cap Hi ) = P(Hi ) P(A|Hi ).
i=1

i=1

Теорема 7.3 (формулы Байеса12 ). Пусть H1 , H2 , \ldots – полная группа
событий и A -- некоторое событие положительной вероятности. Тогда
условная вероятность события Hk при условии, что событие A произошло,
для любого k вычисляется по формуле
P(Hk )P(A|Hk )
P(Hk |A) = ∑
.
∞
P(Hi ) P(A|Hi )
i=1

Доказательство. По определению условной вероятности имеем
P(Hk |A) =

P(A \cap Hk )
P(Hk )P(A|Hk )
=∑
,
∞
P(A)
P(Hi ) P(A|Hi )
i=1

где последнее равенство следует из теоремы умножения и формулы полной
вероятности.

§8. Биномиальное распределение
Рассмотрим эксперимент, состоящим в n-кратном повторении схемы Бернулли (т.е. в подбрасывании ломаного гроша n раз). Вопрос: «Какова вероятность того, что в результате этих n испытаний «успех» (орёл) выпадет ровно
12

Томас Байес (Reverend Thomas Bayes, 1702 -- 1761), английский математик и пресветерианский священник.

28

k раз, а остальные n − k раз выпадет «неудача» (решка)?» Обозначим искомую вероятность (выпадения орла) через Pn (k). Ясно, что этот эксперимент
имеет конечное пространство элементарных событий \Omega = {0, 1, 2, \ldots , n} --
орёл выпал 0 раз, 1 раз, 2 раза, ... , n раз.
Теорема 8.1. Для любого k \in \Omega имеет место формула Бернулли
Pn (k) = Cnk pk (1 − p)n−k = Cnk pk q n−k .
Доказательство. Рассмотрим один из благоприятных элементарных исходов: (у, у, ... , у, н, н, ... , н). Здесь буквами «у» и «н» обозначены соответ| {z } | {z }
k раз

n−k раз

ственно «успех» и «неудача». Поскольку испытания независимы, вероятность
элементарного исхода (первые k испытаний завершились успехом, а остальные неудачей) по опред. 5.1 равна pk (1 − p)n−k .
Другие элементарные исходы, благоприятные событию A, отличаются от
рассмотренного (у, у, ... , у, н, н, ... , н) лишь перераспределением k успехов
| {z } | {z }
k раз

n−k раз

на n местах. По теор. 1.6 существует ровно Cnk способов расположить k успехов на n местах. Поэтому событие A состоит из Cnk элементарных исходов,
вероятность каждого из них равна pk (1 − p)n−k .
Определение 8.2. Эксперимент, имеющий ряд распределения
k
Pn (k)

0
Cn0 p0 q n =
= qn

1
Cn1 pq n−1 =
= npq n−1

2
Cn2 p2 q n−2 =
= n(n−1)
p2 q n−2
2

...
...
...

k
Cnk pk q n−k =
n!
= k!(n−k)!
p2 q n−2

...
...
...

n
Cnn pn =
= pn

называется биномиальным распределением.
Название этого распределения связан с тем, что сумма всех вероятностей
из второй строки ряда распределения может быть вычислены по формуле
бинома Ньютона, т.е.
n
∑

Cnk pk q n−k = (p + q)n = 1.

k=0

На рис. 8 показан график биномиального распределения P16 (k) =
k
= C16
\cdot 0, 65k \cdot 0, 3516−k . График является симметричным при p = q = 12 .
Если p > q, то максимум сдвигается вправо, и наоборот.
Возникает естественный вопрос. Какое число успехов при n испытаниях
наиболее вероятно? Другими словами, при каком k достигается максимум
функции Pn (k) = Cnk pk q n−k ? Другими словами, при каком (каких) k вероятность достигает максимума?
29

Рис. 8: График биномиального распределения при n = 16.
Теорема 8.3. Если в схеме Бернулли вероятность появления «успеха»
(орла) равна p, то в биномиальном распределении с n испытаниями наиболее вероятным числом «успехов» (орлов) является либо
а) единственное число [np + p], если число np + p не целое, либо
б) два числа np + p и np + p + 1, если число np + p целое.
Доказательство. Сравним отношение чисел Pn (k) и Pn (k − 1) с единицей.
Pn (k)
Cnk pk q n−k
(n − k + 1)p
np + p − k
= k−1 k−1 n−k+1 =
=1+
.
Pn (k − 1) Cn p q
kq
kq
Видно, что
1. Pn (k) > Pn (k − 1) при np + p − k > 0, т.е. при k < np + p;
2. Pn (k) < Pn (k − 1) при np + p − k < 0, т.е. при k > np + p;
3. Pn (k) = Pn (k − 1) при np + p − k = 0, что возможно лишь, если np + p
-- целое число.

§9. k-номиальное распределение
Полиномиальное распределение возникает в результате повторения n раз
схены Бернулли (см. §8). По аналогии k-номиальное распределение возникает в результате повторения n раз схемы независимых испытаний с k ≥ 3
исходами (см. пп. 4.5 и 4.9).
Пример. Асимметричный тетраэдр, грани которого обозначены \Omega_1 , \Omega2 ,
\Omega3 , \Omega4 подбрасывают 14 раз. Вероятности выпадения этих граней лицом вниз
1
соответственно равны 12 , 13 , 19 , 18
. Найти вероятность того, что грани \Omega_1 , \Omega2 ,
\Omega3 , \Omega4 выпадут соответственно
( 1 )5 ( 1 )3 ( 1 )45,( 13,)24, 2 раза.
14!
Ответ: 5! 3! 4! 2! 2
≃ 0, 00137.
3
9
18
30

Замечание 9.1. Известно, что биномом Ньютона называют формулу
n

(p + q) =

n
∑

Cnm pm q n−m ,

m=0
n!
где Cnm = m!(n−m)!
.
Обобщением бинома ньютона является следующая формула
∑
n!
mk
1 m2
(p1 + p2 + \ldots + pk )n =
pm
1 p2 \ldots p k ,
m ! m2 ! \ldots m k !
m +m + ... +m =n 1
1

2

k

где m1 , m2 , \ldots , mk ≥ 0. Эта формула может быть выведена из бинома Ньютона индукцией по k; по аналогии будем назвать её k-номом Ньютона.
Лемма 9.2. Сумма k-номиальных коэффициентов равна k n , т.е.
∑
n!
= kn.
m ! m2 ! \ldots m k !
m +m + ... +m =n 1
1

2

k

Доказательство. Подставим в k-ном Ньютона p1 = p2 = \ldots = pk = 1,
получим требуемый результат.
Лемма 9.3. Если p1 + p2 + \ldots + pk = 1, то сумма членов в правой части
k-нома Ньютона равна единице, т.е.
∑
n!
mk
1 m2
pm
1 p2 \ldots pk = 1.
m ! m2 ! \ldots m k !
m +m + ... +m =n 1
1

2

k

Доказательство. Подставим в k-ном Ньютона p1 +p2 +\ldots+pk = 1, получим
требуемый результат.
Определение 9.3. Пусть эксперимент состоит в том, что
1) проводят n независимых испытаний в одинаковых условиях,
2) в каждом испытании появляется одно из k несовместных событий
A1 , A2 , \ldots , Ak ,
3) эти события происходят с вероятностями p1 , p2 , \ldots , pk соответственно,
и 4) p1 + p2 + \ldots + pk = 1.
Тогда такой эксперимент называется схемой независимых испытаний.
Теорема 9.4. Для любой схемы n независимых испытаний и любых
m1 ≥ 0, m2 ≥ 0, \ldots , mk ≥ 0, таких что m1 + m2 + \ldots + mk = n, вероятность P(m1 , m2 , \ldots , mk ) того, что события A1 , A2 , \ldots , Ak произойдут
соответственно m1 , m2 , \ldots , mk раз, определяется по формуле
P(m1 , m2 , \ldots , mk ) =

n!
mk
1 m2
pm
1 p2 \ldots p k .
m1 ! m2 ! \ldots m k !
31

Доказательство. Рассмотрим один элементарный исход схемы n независимых испытаний:
(A1 , ..., A1 , A2 , ..., A2 , \ldots , Ak , ..., Ak ).
| {z } | {z }
| {z }
m1 раз

m2 раз

mk раз

Это один из благоприятных исходов: сначала событие A1 произошло m1 раз,
затем событие A2 произошло m2 раз, ..., и, наконец, событие Ak произошло mk
mk
1 m2
раз. Вероятность этого элементарного исхода равна pm
1 p2 \ldots p k .
Все остальные благоприятные исходы отличаются лишь расположением
событий из того же набора событий на n местах. Число таких исходов равно
числу способов расставить на n местах m1 событий A1 , потом m2 событий
A2 , ..., и, наконец, mk событий Ak . По теор. 1.3 и 1.6 это число равно
m2
m3
mk
Cnm1 \cdot Cn−m
\cdot Cn−m
\cdot ... \cdot Cn−m
= (проверьте это!) =
1
1 −m2
1 −m2 −\cdot\cdot\cdot−mk−1

n!
.
m1 ! m2 ! \ldots m k !

Теперь становится ясно, откуда взялся ответ задачи про асимметричный тетраэдр в начале этого параграфа.

§10. Гипергеометрическое распределение
Задача 10.1 Из урны, содержащей n1 белых и n − n1 чёрных шаров,
вынимают без возвращения k \leq n шаров. Найти вероятность события A,
состоящего в том, что будет вынуто ровно k1 белых и k−k1 чёрных шаров.
(Мы полагаем, что k1 \leq n1 и k − k1 \leq n − n1 .)
Решение. Результатом эксперимента является набор из k шаров. Оказывается, что искомая вероятность не зависит от того, будем ли мы
или не будем учитывать порядок следования шаров. Чтобы показать это,
подсчитаем её для обоих экспериментов.
1. Эксперимент без учёта порядка. В этом эксперименте общее число
\mu(\Omega) элементарных исходов равно числу k-элементных подмножеств множества, состоящего из n элементов. По теор. 1.6 оно равно \mu(\Omega) = Cnk .
Обозначим через A событие, состоящее в появлении набора, содержащего k1 белых шаров и k − k1 чёрных. По теор. 1.3 число его благоприятных исходов равно произведению числа способов выбрать k1 шаров из n1
белых шаров и числа способов выбрать k − k1 шаров из n − n1 чёрных, т.е
32

k−k1
\mu(A) = Cnk11 \cdot Cn−n
. Получаем, что вероятность появления события A в
1
этом эксперименте равна
k−k1
Cnk11 \cdot Cn−n
1
P(A) =
.
k
Cn

2. Эксперимент с учётом порядка. По теор. 1.4 общее число \mu(\Omega) элементарных исходов равно числу способов разместить n элементов на k
местах, т.е. \mu(\Omega) = Akn = n(n − 1) \ldots (n − k + 1).
В этом эксперименте при подсчёте числа благоприятных исходов \mu(A)
надо учесть как число способов выбрать нужное число k шаров, так и число способов расположить белые и чёрные шары среди выбранных k шаров.
Во-первых, мы подсчитываем число способов расположить k1 шаров на k
местах. Оно равно Ckk1 . Затем мы подсчитываем число способов расположить k1 белых шаров на n1 местах. Учитывая их порядок, получаем, что
это число равно Akn11 . И наконец, мы подсчитываем число способов разме1
стить k − k1 чёрных шаров на оставшихся n − n1 местах. Оно равно Ak−k
n−n1 .
Перемножая эти числа, по теор. 1.4 получим
1
\mu(A) = Ckk1 \cdot Akn11 \cdot Ak−k
n−n1 .

Подсчитывая искомую вероятность, получим
k−k1
1
Ckk1 \cdot Akn11 \cdot Ak−k
Cnk11 \cdot Cn−n
n−n1
1
P(A) =
=
.
k
k
An
Cn

Определение 10.2. Ряд распределения, определённый соответствием
k−k1
Cnk11 \cdot Cn−n
1
k1 \to
7 P(A) =
,
k
Cn

где 0 \leq k1 \leq min(k, n1 ) и k − k1 \leq n − n1 называется гипергеометрическим
распределением.

33

Глава 2. ТЕОРИЯ СЛУЧАЙНЫХ ВЕЛИЧИН
§11. Случайные величины
На практике элементарные случайные события являются либо числами, либо наборами чисел (случайными векторами). В §§ 11–13 мы изучим
одномерные случайные величины, у которых \Omega ⊂ R1 -- числовое множество. Начиная с §13 изучим случайные векторы, у которых \Omega ⊂ Rn , при
n ≥ 2.
Чтобы дать общее определение случайной величины пусть сначала (\Omega, A, P)
-- произвольное вероятностное пространство.
Определение 11.1. Функция ξ : \Omega \to R называется случайной величиной на σ-алгебре событий
A, если для любого числа x \in R прообраз луча

−1
ξ ((−∞, x]) = {\Omega \in \Omega  ξ(\Omega) \leq x} является событием из σ-алгебры A.
Замечание 11.2. 1) Самая простая функция ξ : \Omega \to R -- это постоянная функция, заданная для любого \Omega \in \Omega по формуле ξ(\Omega) = c. Она
принимает одно значение и является не случайной, а детерминированной.
Она рассматривается в теории вероятностей как частный тривиальный
случай.
2) Первая нетривиальная случайная величина (с \Omega ⊂ R1 ) задаётся
с помощью тождественной
функции ξ(\Omega) = \Omega. В этом случае событие

−1

ξ ((−∞, x]) = {\Omega \in \Omega ξ(\Omega) \leq x} обозначают короче: {ξ \leq x}.
3) Оказывается, что другие случайные величины (ξ(\Omega) ̸= \Omega) могут быть
описаны через случайную величину ξ(\Omega) = \Omega. Это будет показано в § 13.
Определение 11.3. Функцией распределения случайной величины ξ называется функция Fξ : R \to [0, 1], определённая по формуле
Fξ (x) = P(ξ \leq x).
Очевидно, что 0 \leq Fξ (x) \leq 1.

Рис. 9: Функция распределения детерминированной величины.
34

Примеры 11.3.1. 1) Детерминированная (вырожденная случайная) величина ξ : \Omega \to R имеет пространство элементарных событий, состоящее
из одного элементарного события, \Omega = {\Omega}. Она принимает только одно
значение ξ(\Omega) = c = const \in R с вероятностью равной 1, т.е. имеет ряд
ξ c
распределения
. Её функция распределения показана на рис. 9.
P 1
2) Случайная величина ξ, имеющая распределение Бернулли, и принимающая значения 1 (успех) и 0 (неудача) с вероятностями соответственно
ξ
0
1
p и 1 − p, имеет ряд распределения
и имеет график, покаP 1−p p
занный на рис. 10.

Рис. 10: Функция распределения Бернулли.
3) Случайная величина ξ -- номер грани при подбрасывании игральной
кости имеет функцию распределения, показанную на рис. 11.

Рис. 11: Функция распределения выпадения числа на игральной кости.
4) Случайная величина ξ -- номер появления успеха в геометрическом
ξ 1 2 ...
k
...
и имераспределения имеет ряд распределения
k−1
P p pq \ldots pq
...
ет функцию распределения, показанную на рис. 12.
В дальнейшем мы будем использовать следующие обозначения для пределов функций слева и справа соответственно:
def

lim h(x − ε) = h(x − 0)

ε\to0

и
35

def

lim h(x + ε) = h(x + 0),

ε\to0

Рис. 12: Функция геометрического распределения при p = 12 .
где всегда ε > 0.
Функция распределения Fξ (x) обладает следующими свойствами.
Теорема 11.4. 1) Fξ (x) -- неубывающая функция, другими словами,
если x1 < x2 , то Fξ (x1 ) \leq Fξ (x2 ).
2) Fξ (−∞) = lim Fξ (x) = 0 и Fξ (+∞) = lim Fξ (x) = 1.
x\to−∞

x\to∞

3) Fξ (x) непрерывна справа: для любой точки x0 \in R имеем Fξ (x0 + 0) =
Fξ (x0 ).
Доказательство. 1) По пп. 11.2, 3.3 и 3.1 имеем Fξ (x2 ) − Fξ (x1 ) =
P(ξ \leq x2 ) − P(ξ \leq x1 ) = P({ξ \leq x2 } r {ξ \leq x1 )}) = P(x1 < ξ \leq x2 ) ≥ 0.
2) Fξ (−∞) = lim Fξ (x) = lim P(ξ \leq x) = P(ξ \leq −∞) = 0 и
x\to−∞

x\to−∞

Fξ (+∞) = lim Fξ (x) = lim P(ξ \leq x) = P(ξ \leq ∞) = 1.
x\to∞

x\to∞

3) Fξ (x0 +0) = lim Fξ (x0 +ε) = lim P(ξ \leq x0 +ε) = P(ξ \leq x0 ) = Fξ (x0 ).
ε\to0

ε\to0

Теорема 11.5. Функция распределения имеет не более чем счётное множество скачков.
Доказательство. Разобьём множество H всех скачков на подмножества скачков по убыванию высоты h:
( ]
1) H1 – множество скачков высоты h \in 12 , 1 ,
( ]
2) H2 – множество скачков высоты h \in 14 , 12 ,
( ]
3) H3 – множество скачков высоты h \in 18 , 14 ,
..........................................................................
( 1 ,1 ]
n) Hn – множество скачков высоты h \in 2n , 2n−1 ,
................................................................................ .
36

Видно, что множества Hn для всех n \in Z попарно непересекающиеся, т.е.
∞
∪
Hi \cap Hj = ∅ при i ̸= j; и Hi = H. Функция распределения может иметь
i=1
( ]
во-первых, не более одного скачка высоты h \in( 12 , 1] , т.е. \mu(H1 ) \leq 1;
во-вторых, не более трёх скачков высоты h \in ( 14 , 21] , т.е. \mu(H2 ) \leq 3;
в-третьих, не более семи скачков высоты h \in 18 , 14 , т.е. \mu(H2 ) \leq 3;
............................................................................................................
;
(
]
1
1
в-n-ых, не более 2n − 1 скачков высоты h \in 2n , 2n−1 , т.е. \mu(Hn ) \leq 2n − 1;
....................................................................................................................... .
Можно занумеровать все скачки по убыванию их высоты, нумеруя при
этом скачки равной высоты, если такие повстречаются. Эта нумерация ставит
множество всех скачков во взаимно однозначное соответствие с множеством
Z натуральных чисел. Что и требовалось доказать.
Теорема 11.6. (О связи вероятности событий-интервалов с функцией
распределения.) Для любых точек x, a, b \in R, где a < b, имеем
1) P(ξ < x) = Fξ (x − 0),
2) P(ξ = x) = Fξ (x) − Fξ (x − 0),
3) если Fξ непрерывна в точке x, то P(ξ = x) = 0,
4) P(a < ξ \leq b) = Fξ (b) − Fξ (a),
5) P(a \leq ξ \leq b) = Fξ (b) − Fξ (a − 0),
6) P(a < ξ < b) = Fξ (b − 0) − Fξ (a),
7) P(a \leq ξ < b) = Fξ (b − 0) − Fξ (a − 0).
Доказательство. 1) P(ξ < x) = lim P(ξ \leq x − ε) = lim Fξ (x − ε) = Fξ (x − 0).
ε\to0

ε\to0

2) P(ξ = x) = P({ξ \leq x} r {ξ < x}) = P(ξ \leq x) − P(ξ < x) = Fξ (x) −
Fξ (x − 0).
3) P(ξ = x) = Fξ (x)−Fξ (x−0) = Fξ (x)−lim Fξ (x−ε) = Fξ (x)−Fξ (x) = 0.
ε\to0

4) P(a < ξ \leq b) = P ({ξ \leq b} r {ξ \leq a}) = P(ξ \leq b) − P(ξ \leq a) =
Fξ (b) − Fξ (a).
5) -- 7) доказать самостоятельно.
Следствие 11.7. Если функция распределения Fξ (x) непрерывна, то
P(a \leq ξ < b) = P(a < ξ < b) = P(a \leq ξ \leq b) = P(a < ξ \leq b) = Fξ (b) − Fξ (a).

§12. Абсолютно непрерывные случайные
величины
37

Определение 12.1. Случайная величина ξ называется абсолютно непрерывной, если существует такая неотрицательная функция fξ (x) (возможно обобщённая, см. §13), что для любого x \in R функция распределения Fξ (x)
представима в виде 13
∫x
Fξ (x) =
fξ (t)dt.
−∞

При этом функция fξ (x) называется плотностью вероятности случайной
величины ξ
Замечание 12.2. Если Fξ (x) -- дифференцируемая функция распределения, то название "плотность вероятности" имеет следующее объяснение. С одной стороны, используя формулу дифференцирования интеграла
dFξ (x)
по верхнему пределу, имеем dx
= fξ (t)|t=x = fξ (x). С другой стороны, по
определению производной имеем:
dFξ (x) Fξ (x + dx) − Fξ (x) P(ξ \leq x + dx) − P(ξ \leq x)
=
=
=
dx
dx
dx
=

P({ξ \leq x + dx} r {ξ \leq x}) P(x < ξ \leq x + dx)
=
.
dx
dx

Поэтому

P(x < ξ \leq x + dx)
dx
есть отношение вероятности попадания случайной величины ξ в интервал
(x, x+dx] к длине этого интервала dx, что физически означает плотность
вероятности ("массы") случайной величины ξ в точке x.
Теорема 12.3. Плотность обладает свойствами:
1) fξ (x) ≥ 0 для любого x;
∞
∫
2)
fξ (t)dt = 1.
fξ (x) =

−∞

Доказательство. 1) По теор. 11.4.1) функция распределения Fξ (x) -- неубыdFξ (x)
= fξ (x) ≥ 0.
вающая, поэтому dx
∞
∫
∫x
2)
fξ (t)dt = lim fξ (t)dt = lim Fξ (x) = 1 по свойству 11.4.2).
−∞

x\to∞−∞

x\to∞

Определение 12.4. Пусть область U ⊆ Rn имеет меру \mu(U ). Говорят,
что в области U функция h : U \to R удовлетворяет некоторому свойству
13

В дальнейшем мы рассматриваем только такие случайные величины, для которых все связанные с
ними несобственные интегралы и суммы бесконечных рядов сходятся абсолютно.

38

P почти всюду, если подмножество A ⊂ U , в котором свойство P не
выполняется, имеет меру 0, т.е. \mu(A) = 0.
Докажем свойства абсолютно непрерывных случайных величин.
Теорема 12.5. Если случайная величина ξ абсолютно непрерывна, то
1) её функция распределения Fξ (x) непрерывна в R и дифференцируема
d
почти всюду в R, т.е. равенство fξ (x) = dx
Fξ (x) справедливо почти всюду,
2) P(ξ = x) = 0 для любого x \in R,
∫b
3) P(a \leq ξ < b) = P(a < ξ < b) = P(a \leq ξ \leq b) = P(a < ξ \leq b) = fξ (t)dt.
a

Доказательство. 1) Во-первых, функция Fξ (x) =

∫x

fξ (t)dt непрерывна как

−∞

функция верхнего предела интеграла.
Во-вторых, по теор. 11.5 функция Fξ (x) имеет не более чем счётное множество скачков, поэтому она не дифференцируема не более чем в счётном
множестве точек. Любое счётное множество точек на прямой имеет нулевую
меру (длину). Поэтому Fξ (x) дифференцируема почти всюду в R.
2) Это следует из 11.6.3).
3) Из 11.6.4) имеем
∫b
∫a
∫b
P(a < ξ \leq b) = Fξ (b) − Fξ (a) =
fξ (t)dt − fξ (t)dt = fξ (t)dt.
−∞

−∞

a

Остальные равенства следуют из 11.7.
Примеры абсолютно непрерывных случайных величин
Определение 12.6. Случайная величина ξ имеет равномерное распределение на отрезке a, b, если


x<a
x<a
 0,
 0,
x−a
1
, a\leqx\leqb
, a\leqx\leqb.
Fξ (x) = P(ξ \leq x) =
и fξ (x) =
 b−a
 b−a
1,
x>b
0,
x>b
Графики функций Fξ (x) и fξ (x) показаны на рис. 13. Заметим, что в точках
a и b функция распределения Fξ (x) не дифференцируема, поэтому значение
плотности вероятности в этих точках можно задать как угодно: либо
1
fξ (a) = 0, либо fξ (a) = b−a
, а на другом конце тоже либо fξ (b) = 0, либо
1
.
fξ (b) = b−a
Определение 12.7. Случайная величина ξ имеет показательное распределение с параметром λ (рис. 14), если
{
0,
x<0
fξ (x) =
.
−λx
λe , x ≥ 0
39

Рис. 13: Равномерное распределение.

Рис. 14: Показательное распределение.
Определение 12.8. Если для любого x \in R случайная величина ξ имеет
плотность
2
1
− (x−a)
2
2σ
√
fξ (x) =
e
,
σ 2\pi
то говорят, что ξ имеет нормальное (или Гаусса14 ) распределение с математическим ожиданием a и дисперсией σ 2 , где a \in R и σ > 0. См. рис.
15.
1) Очевидно, что fξ (x) ≥ 0 для любого x;
∞
√
∫ − t2
2) Используем табличный интеграл (Пуассона)
e 2 dt = 2\pi.
−∞

∫∞

∫∞
fξ (x)dx =

−∞

−∞

(x−a)2
1
√ e− 2σ2 dx =
σ 2\pi

[

замена переменных
t = x−a
σ , dx = σdt

]

1
=√
2\pi

∫∞

2

− t2

e

dt = 1.

−∞

Свойство 12.9. Легко сосчитать, что расстояние между точками перегиба равно 2σ, поэтому параметр 2σ является характеристикой ширины
14

Карл Фридрих Гаусс (Johann Carl Friedrich Gauß, 1777 -- 1855), выдающийся немецкий математик,
астроном и физик, считается одним из величайших математиков всех времён.

40

Рис. 15: Нормальное распределение (Гаусса).
графика на уровне точек перегиба. Заметим, что вероятность попадания
нормальной случайной величины в интервал между точками перегиба

1
P(a − σ \leq ξ \leq a + σ) = √
σ 2\pi

a+σ
∫

2
− (x−a)
2σ 2

e
a−σ

1
dx = √
2\pi

∫1

t2

e− 2 dt = 2Φ(1) ≃ 0, 6827,

−1

где Φ(1) ≃ 0, 34134 приближённое значение функции Φ(x) =

√1
2\pi

∫x

t2

e− 2 dt

0

взято из таблицы.
Свойство 12.10 ("Правило трёх сигм"). Если ξ -- нормальная случайная величина, то P(|ξ − a| \leq 3σ) = 2Φ(3) ≃ 2 \cdot 0, 49865 ≃ 0, 997. Запоминать число 0,997 нет никакого смысла, а вот помнить, что почти вся
вероятность ("масса") нормального распределения сосредоточена в интервале [a − 3σ, a + 3σ], всегда полезно.

§13. Функции Хевисайда и Дирака
Определение 13.1. Функцией единичного скачка или короче функцией
41

Хевисайда15 называется функция u : R \to R, заданная по формуле (см. рис. 16)
{
0, x < 0
u(x) =
.
1, x ≥ 0

Рис. 16: Функция Хевисайда.
Примеры 13.2. Функция Хевисайда полезна для записи в строчку формул (многоэтажных) кусочно заданных функций.
1) Функция единичного импульса единичной длины см. рис. 17.


 0, x < 0

1, 0 < x < 1
U (x) =
= u(x) − u(x − 1).


0, x > 1

Рис. 17: U (x) = u(x) − u(x − 1)..
2) Функция распределения Бернулли, см. пример 11.3.1.2) и рис. 10.


0, x < c


1 − p, 0 \leq x < 1
Fξ (x) =
= (1 − p) u(x) + p u(x − 1).


p, 1 \leq x
15

Оливер Хевисайд (англ. Oliver Heaviside; 18 мая 1850 -- 3 февраля 1925) -- английский учёныйсамоучка, инженер, математик и физик. Впервые применил комплексные числа для изучения электрических цепей. Переписал уравнения Максвелла из их первоначальной формы, состоявшей из 20 уравнений
с 12 переменными, к современной форме, состоящей из 4 дифференциальным уравнениям, выраженной в
терминах современного векторного анализа. Предложил операционное исчисление (он ввёл обозначение D
для дифференциального оператора) и метод решения дифференциальных уравнений с помощью сведения
к обыкновенным алгебраическим уравнениям. Ввёл термины: «проводимость», «проницаемость», «индуктивность», «импеданс».

42

3) Функция равномерного распределения, см. опред. 12.6 и рис. 13.


 0, x < a
 x−a
x−a
x−a
, a\leqx<b
Fξ (x) =
=
u(x − a) −
u(x − b) + u(x − b).
b−a

 b−a
b−a
1, x ≥ b
4) Интеграл от функции Хевисайда.
∫x

∫x
f (t)u(t) dt =

−∞

в частности,

f (t) dt
0

∫x
u(t) dt = x u(x).
−∞

Лемма 13.3. Кусочная функция

g0 (x),




 g1 (x),
...,
g(x) =


gn (x),


 g (x),
n+1

x < x0
x0 \leq x < x1
...
xn−1 \leq x < xn
xn \leq x

представима в виде
g(x) = g0 (x)u(x0 − x) + g1 (x)[u(x − x0 ) − u(x − x1 )] + \ldots
+gn (x)[u(x − xn−1 ) − u(x − xn )] + gn+1 (x)u(x − xn ).
Доказательство. Функция g(x) является суммой следующих функций
{
}
g0 (x), x < x0
ge0 (x) =
= g0 (x)u(x0 − x),
0, x0 \leq x
{
}
0, x < x0 или x1 \leq x
ge1 (x) =
= g1 (x)u(x − x0 ) − g1 (x)u(x − x1 ),
g1 (x),
x0 \leq x < x 1
... ,
}
{
0, x < xn−1 или xn \leq x
= gn (x)u(x−xn−1 )−gn (x)u(x−xn ),
gen (x) =
gn (x),
xn−1 \leq x < xn
}
{
0, x < xn
= g0 (x)u(x − xn ).
gen+1 (x) =
g0 (x), xn \leq x
43

Определение 13.4. δ-функцией или функцией Дирака называется обобщённая функция δ : R \to R ∪ {∞}, заданная по формуле
{
0, x ̸= 0
δ(x) =
∞, x = 0
и любого ε > 0 подчинённая условию

∫ε

δ(x)dx = 1. См. рис. 18.

−ε

Рис. 18: Функция y = δ(x − a).
Свойства 13.5. 1) Для любого c \in R и любого ε > 0, имеет место
формула
c+ε
∫
δ(x − c)dx = 1.
c−ε

2) u(x) =

∫x

δ(t) dt.

−∞

3) u′ (x) = δ(x).
4) Для любой непрерывной функции f (x) любого a \in R имеет место
тождество
f (x)δ(x − a) = f (a)δ(x − a).
5) Для любой непрерывной функции f (x) любого a \in R имеет место
тождество
∫∞
f (x)δ(x − a)dx = f (a).
−∞

6) Для любой непрерывной функции f (x) любого a \in R имеет место
тождество
∫x
f (t)δ(t − a)dt = f (a)u(x − a),
−∞

44

в частности,

∫x
δ(t − a)dt = u(x − a).
−∞

7) Если функция f (x) непрерывна и все её нули (корни) x1 , x2 , \ldots , xk , \ldots
простые (т.е. имеют кратность 1), то
δ(f (x)) =

∑ δ(x − xk )
k

|f ′ (xk )|

.

8) Дельта-функция получается при вычислении преобразования Фурье
от константы:
∫∞
eixt dt = 2\piδ(x).
−∞

Примеры 13.6. 1) См. пример 13.2.3). Дано
Fξ (x) =

x−a
[u(x − a) − u(x − b)] + u(x − b).
b−a

Найти fξ (x).
Решение. fξ (x) = Fξ′ (x) =
(
=

x−a
b−a

)′

[u(x − a) − u(x − b)] +

x−a
[u(x − a) − u(x − b)]′ + u′ (x − b) =
b−a

x−a
1
[u(x − a) − u(x − b)] +
[δ(x − a) − δ(x − b)] + δ(x − b) =
b−a
b−a
1
x−a
x−a
=
[u(x − a) − u(x − b)] +
δ(x − a) −
δ(x − b) + δ(x − b) =
b−a
b−a
b−a
a−a
b−a
1
[u(x − a) − u(x − b)] +
δ(x − a) −
δ(x − b) + δ(x − b) =
=
b−a
b−a
b−a
1
=
[u(x − a) − u(x − b)].
b−a
2) Найти плотность вероятности по данной функции распределения
(см. рис. 19)


0,
x
<
0


1
1
(5x
+
8),
0
\leq
x
<
2
=
(5x + 8)[u(x) − u(x − 2)] + u(x − 2).
Fξ (x) =
 24
 24
1, x ≥ 2
=

45

Решение. fξ (x) = Fξ′ (x) =
=

5
1
[u(x) − u(x − 2)] + (5x + 8)[δ(x) − δ(x − 2)] + δ(x − 2) =
24
24
=

1
3
5
[u(x) − u(x − 2)] + δ(x) − δ(x − 2) + δ(x − 2) =
24
3
4
1
5
1
= δ(x) + [u(x) − u(x − 2)] + δ(x − 2).
3
24
4

См. рис. 20.

Рис. 19: Функция распределения с двумя скачками.

Рис. 20: Площадь под плотностью равна

1
3

+

5
24

\cdot2+

1
4

= 1.

Определение 13.6. Функции Хевисайда и Дирака и их композиции относятся к классу так называемых обобщённых функций.

§14. Функции одной случайной величины
Замечание 14.1. Пусть ξ : \Omega \to R -- абсолютно непрерывная случайная
величина, имеющая плотность fξ (x). Построим с помощью функции g :
R \to R новую случайную величину по формуле η = g(ξ). Требуется найти
46

функцию распределения и плотность случайной величины η. Мы решим эту
задачу сначала в предположении, что функция y = g(x) дифференцируема
и монотонна, т.е. когда во всех точках x \in R выполнено либо g ′ (x) > 0,
либо g ′ (x) < 0.
Теорема 14.2. Если ξ -- абсолютно непрерывная случайная величина,
имеющая функцию распределения Fξ (x) и плотность fξ (x), и если g : R \to R
-- дифференцируемая и монотонная функция, то случайная величина
η = g(ξ) имеет плотность вероятности
 [

 d g −1 (y)] 


fη (y) = fξ (g −1 (y)) \cdot 
.


dy
Доказательство. Заметим, что если g : R \to R -- монотонная функция, то
существует её
функция g −1 : R \to R, и выполнено
( −1обратная
)
тождество g g (y)
≡ y. Дифференцируя его, получим тождество
(
)
(
)
( )′
′
g ′ g −1 (y) \cdot g −1 (y) ≡ 1, которое означает, что производные g ′ и g −1 --
одного знака, т.е. функции g и g −1 либо обе возрастающие, либо обе убывающие.
( )′
1) Пусть сначала g -- возрастающая функция, т.е. g ′ > 0 и g −1 > 0. Это
означает, что неравенство g(ξ) \leq y можно записать в виде ξ \leq g −1 (y).
Fη (y) = Fg(ξ) (y) = P(g(ξ) \leq y) = P(ξ \leq g −1 (y)) = Fξ (g −1 (y)) =

g −1
∫ (y)

fξ (t)dt =
−∞

[
=

] ∫y
( −1 )′
( −1 )′ ( −1 )
замена: t = g (τ ), dt = g (τ ) dτ
=
g (τ ) fξ g (τ ) dτ.
−1
t = −∞ 7\to τ = −∞, t = g (y) 7\to τ = y
−1

−∞

( )′
2) Пусть теперь g -- убывающая функция, т.е. g ′ < 0 и g −1 < 0, тогда
неравенство g(ξ) \leq y можно записать в виде ξ ≥ g −1 (y).
Fη (y) = Fg(ξ) (y) = P(g(ξ) \leq y) = P(ξ ≥ g −1 (y)) =

∫∞
fξ (t)dt =
g −1 (y)

[
] −∞
∫
(
)′
( −1 )′ ( −1 )
замена: t = g −1 (τ ), dt = g −1 (τ ) dτ
=
=
g (τ ) fξ g (τ ) dτ =
t = ∞ 7\to τ = −∞, t = g −1 (y) 7\to τ = y
y

47

∫y 

( −1 )′  ( −1 )
=
 g (τ )  fξ g (τ ) dτ.
−∞

Объединяя оба случая в один, получим требуемую формулу.
Определение 14.3. Пусть A – подмножество на прямой R, т.е. A ⊂
R. Функция 1A : R \to {0, 1}, определённая по формуле
{
1, если x \in A
1A (x) =
,
0, если x \in
/A
называется выделяющей функцией множества A или индикатором A.
Если A = [0, ∞), то обозначение 1A (x) сокращают до 1(x). Заметим,
что 1(x) = u(x), т.е. совпадает с функцией Хевисайда.
Замечание 14.4. Пусть теперь g : R \to R, y = g(x), – дифференцируемая, кусочно монотонная функция, имеющая интервалы монотонности:
D = {D1 = (−∞, a1 ], D2 = (a1 , a2 ], \ldots , Dn = (an−1 , ∞)} .
Ясно, что все ограничения g

Di

: Di \to R, определённые по формулам g (x)
Di

= g(x) являются взаимно однозначными функциями и поэтому имеют об(
)−1
(y) = g −1 (y) с областями определения g(Di ) соответратные g
Di

Di

ственно.
Теорема 14.5. Если ξ -- абсолютно непрерывная случайная величина,
имеющая функцию распределения Fξ (x) и плотность fξ (x), и если g : R \to R
-- кусочно дифференцируемая и кусочно монотонная функция на интервалах D, то случайная величина η = g(ξ) имеет плотность вероятности
 [
] 

(
)  d g −1 (y) 
n
∑
Di


fη (y) =
fξ g −1 (y) \cdot 
 \cdot 1g(Di ) (y).


Di
dy
i=1




Без доказательства.

§15. Случайные векторы и их распределения
Пусть (\Omega, A, P) -- произвольное вероятностное пространство.
48

Определение 15.1. Вектор (ξ1 , \ldots , ξn ) называется случайным вектором, если ξ1 , \ldots , ξn являются случайными величинами, заданными на одном
и том же вероятностном пространстве \Omega.
Определение 15.2. Функцией совместного распределения случайных
величин ξ1 , \ldots , ξn (или случайного вектора (ξ1 , \ldots , ξn )) называется функция Fξ1 ,...,ξn : Rn \to [0, 1], определённая по формуле
Fξ1 ,...,ξn (x1 , \ldots , xn ) = P(ξ1 \leq x1 , \ldots , ξn \leq xn ).
Ясно, что 0 \leq Fξ1 ,...,ξn (x1 , \ldots , xn ) \leq 1.
Определение 15.3. Говорят, что случайные величины ξ1 , \ldots , ξn имеют абсолютно непрерывное совместное распределение, если существует
такая неотрицательная функция fξ1 ,...,ξn (x1 , \ldots , xn ), что для любой точки
(x1 , \ldots , xn ) \in Rn функция распределения Fξ1 ,...,ξn (x1 , \ldots , xn ) представима в
виде
∫x1
∫xn
Fξ1 ,...,ξn (x1 , \ldots , xn ) =
\ldots fξ1 ,...,ξn (t1 , \ldots , tn )dt1 \ldots dtn .
−∞

−∞

При этом функция fξ1 ,...,ξn (x1 , \ldots , xn ) называется плотностью вероятности совместного распределения случайных величин ξ1 , \ldots , ξn .
Лемма 15.4. Справедлива формула
∂ n Fξ1 ,...,ξn (x1 , \ldots , xn )
fξ1 ,...,ξn (x1 , \ldots , xn ) =
.
∂x1 \ldots ∂xn
Доказательство. Формула получается в результате последовательного дифференцирования формулы опред. 15.3 по верхним пределам.
Определение 15.5. Случайные величины ξ1 , \ldots , ξn называются независимыми, если для любого набора множеств A1 , \ldots , An ⊂ R, такого что
ξ1−1 (A1 ), \ldots , ξn−1 (An ) \in A, имеет место равенство
P(ξ1 \in A1 , \ldots , ξn \in An ) = P(ξ1 \in A1 ) \cdot \ldots \cdot P(ξn \in An ).
Лемма 15.6. 1) Случайные величины независимы, если для любых x1 ,
\ldots , xn \in R имеет место равенство
Fξ1 ,...,ξn (x1 , \ldots , xn ) = Fξ1 (x1 ) \cdot \ldots \cdot Fξn (xn ).
2) Случайные величины независимы, если для любых x1 , \ldots , xn \in R имеет место равенство
fξ1 ,...,ξn (x1 , \ldots , xn ) = fξ1 (x1 ) \cdot \ldots \cdot fξn (xn ).
49

Доказательство. 1) Fξ1 ,...,ξn (x1 , \ldots , xn ) = P(ξ1 \leq x1 , \ldots , ξn \leq xn ) =
= P(ξ1 \leq x1 ) \cdot \ldots \cdot P(ξn \leq xn ) = Fξ1 (x1 ) \cdot \ldots \cdot Fξn (xn ).
∂ n Fξ1 ,...,ξn (x1 ,...,xn )
∂ n [Fξ1 (x1 )\cdot\ldots\cdotFξn (xn )]
2) fξ1 ,...,ξn (x1 , \ldots , xn ) =
=
=
∂x1 ...∂xn
∂x1 ...∂xn
=

∂Fξ1 (x1 )
∂x1

\cdot ... \cdot

∂Fξn (xn )
∂xn

= fξ1 (x1 ) \cdot \ldots \cdot fξn (xn ).

В следующей теореме без потери общности и для простоты формулировки мы ограничимся двухмерным случаем, n = 2.
Функция распределения Fξ1 ,ξ2 (x1 , x2 ) обладает следующими свойствами.
Теорема 15.7. 1) Функция Fξ1 ,ξ2 (x1 , x2 ) является неубывающей по каждому аргументу x1 и x2 .
2) Существуют пределы Fξ1 ,ξ2 (−∞, x2 ) = lim Fξ1 ,ξ2 (x1 , x2 ) = 0 и
x1 \to−∞

Fξ1 ,ξ2 (x1 , −∞) = lim Fξ1 ,ξ2 (x1 , x2 ) = 0.
x2 \to−∞

3) Существуют пределы Fξ1 ,ξ2 (∞, x2 ) = lim Fξ1 ,ξ2 (x1 , x2 ) = Fξ2 (x2 ) и
x1 \to∞

Fξ1 ,ξ2 (x1 , ∞) = lim Fξ1 ,ξ2 (x1 , x2 ) = Fξ1 (x1 ).
x2 \to∞

4)

∫∞
fξ1 (x1 ) =

fξ1 ,ξ2 (x1 , x2 ) dx2 ,
−∞

∫∞
fξ2 (x2 ) =

fξ1 ,ξ2 (x1 , x2 ) dx1 .
−∞

5) Fξ,η (x, y) непрерывна справа по каждой координате x и y.
(Без доказательства.)
Примеры 15.8. 1) Пусть A ⊂ Rn -- множество, имеющее конечный
объём \mu(A), в пространстве с координатами x = (x1 , \ldots , xn ). Тогда функция
{ 1
, если x \in A
fξ1 ,...,ξn (x1 , \ldots , xn ) = \mu(A)
0, если x \in
/A
определяет плотность случайного вектора {ξ1 , \ldots , ξn } с равномерным распределением в A.
2) Функция fξ,η (x, y) =
{
[
]}
1
1
(x − a)2 2r(x − a)(y − b) (y − b)2
√
=
exp −
−
+
,
2(1 − r2 )
σ12
σ1 σ2
σ22
2\piσ1 σ2 1 − r2
где r -- коэффициент корреляции (см. §18), определяет двухмерную нормальную плотность вероятности случайного вектора (ξ, η), показанную
50

Рис. 21: Плотность вероятности двухмерного нормального распределения.
на рис. 21. Там же показан эллипс равных вероятностей
(x − a)2 2r(x − a)(y − b) (y − b)2
−
+
= const.
σ12
σ1 σ2
σ22

§16. Функции от двух случайных величин
Замечание 16.1. Пусть ξ1 , ξ2 -- случайные величины с совместной плотностью вероятности fξ1 ,ξ2 (x1 , x2 ). Построим с помощью функции g : R2 \to
R случайную величину η = g(ξ1 , ξ2 ). Требуется найти функцию распределения Fη (y) и плотность вероятности fη (y) случайной величины η.
Лемма 16.2. Пусть y \in R, и область Dy ⊆ R2 состоит из точек
(x1 , x2 ), удовлетворяющих неравенству g(x1 , x2 ) \leq y, т.е. Dy = {(x1 , x2 ) \in
R2 | g(x1 , x2 ) \leq y}. Тогда случайная величина η = g(ξ1 , ξ2 ) имеет функцию
распределения
∫∫
Fη (y) =
fξ1 ,ξ2 (x1 , x2 ) dx1 dx2 .
Dy

Доказательство.
∫∫
Fη (y) = P ( g(x1 , x2 ) \leq y ) = P( (x1 , x2 ) \in Dy ) =

fξ1 ,ξ2 (x1 , x2 ) dx1 dx2 ,
Dy

51

где последнее равенство следует их того, что вероятность попадания случайного вектора (x1 , x2 ) в область Dy равна объёму цилиндра, ограниченного
сверху графиком плотности вероятности, а снизу -- областью Dy .

Рис. 22: Случайные функции суммы, произведения и частного.
Лемма 16.3. (Распределение суммы.) Пусть η = ξ1 + ξ2 , тогда


∫ 1
∫∞ y−x

Fη (y) = P (η \leq y ) = P (x1 + x2 \leq y ) =
fξ1 ,ξ2 (x1 , x2 ) dx2  dx1 .
−∞

−∞

Доказательство. Воспользуемся леммой 16.2 для функции g(x1 , x2 ) =
= x1 + x2 . Заменим двойной интеграл по области Dy = {(x1 , x2 ) \in R2  x1 +
x2 \leq y} (см. рис. 22.1) на повторный, получим требуемый результат.
Лемма 16.4. (Распределение произведения.) Пусть η = ξ1 ξ2 , тогда


 y

∞
∫
∫∞ ∫x1



 fξ1 ,ξ2 (x1 , x2 ) dx2  dx1 + 
 fξ1 ,ξ2 (x1 , x2 ) dx2  dx1 .



∫0
Fη (y) = P (x1 x2 \leq y ) =
−∞

y
x1

0

−∞

Доказательство. Воспользуемся
леммой 16.2 для функции g(x1 , x2 ) = x1 x2 .

2
Область Dy = {(x1 , x2 ) \in R x1 x2 \leq y} показана на рис. 22.2. Переходя от
двойного интеграла к повторному, получим требуемый результат.
Лемма 16.5. (Распределение частного.) Пусть η =
(
Fη (y) = P

x2
\leqy
x1

)

∫∞
=
0

ξ2
ξ1 ,

тогда



∞
 yx
∫0
∫
∫1
 fξ1 ,ξ2 (x1 , x2 ) dx2  dx1 .
 fξ1 ,ξ2 (x1 , x2 ) dx2  dx1 +
−∞

−∞

yx1

Доказательство. Воспользуемся леммой 16.2 для функции g(x1 , x2 ) = xx21 .

Область Dy = {(x1 , x2 ) \in R2  xx21 \leq y} показана на рис. 22.3 Переходя от
двойного интеграла к повторному, получим требуемый результат.
52

Лемма 16.6. (О свёртке.) Если случайные величины ξ1 и ξ2 независимы
и имеют плотности вероятности соответственно fξ1 (x1 ) и fξ2 (x2 ), то
плотность вероятности суммы η = ξ1 + ξ2 равна свёртке плотностей fξ1
и fξ2 :
∫∞
fη (t) = fξ1 +ξ2 (t) =

∫∞
fξ1 (u)fξ2 (t − u) du =

−∞

fξ2 (u)fξ1 (t − u) du.
−∞

Доказательство. Воспользуемся леммой 16.3




∫∞ x−x
∫ 1
∫∞ x−x
∫ 1


Fη (x) =
fξ1 ,ξ2 (x1 , x2 ) dx2  dx1 =
fξ1 (x1 )fξ2 (x2 ) dx2  dx1 .
−∞

−∞

−∞

−∞

Сделаем в последнем интеграле замену переменной: x2 = t − x1 , dx2 = dt.
При этом x2 \in (−∞, x − x1 ) перейдёт в t \in (−∞, x). В последнем интеграле
меняем порядок интегрирования и получаем:


∞

∫∞ ∫x
∫x
∫
 fξ1 (x1 )fξ2 (t − x1 ) dt dx1 =
 fξ1 (x1 )fξ2 (t − x1 ) dx1  dt.
−∞

−∞

−∞

|

−∞

{z

}

fξ1 +ξ2 (t)

∫x

Итак, мы представили функцию распределения Fη (x) = Fξ1 +ξ2 (x) в виде
fξ1 +ξ2 (t) dt, где

−∞

∫∞
fξ1 +ξ2 (t) =

∫∞
fξ1 (x1 )fξ2 (t − x1 ) dx1 =

−∞

fξ1 (u)fξ2 (t − u) du
−∞

Второе равенство теоремы получается из первого, если всюду в доказательстве поменять местами индексы 1 и 2 .
Определение 16.7. Если две независимые случайные величины имеют
одно и то же распределение (возможно, с разными параметрами), и их
сумма имеет то же самое распределение, то распределение называется
устойчивым относительно суммирования.
Замечание 16.8. Следующие леммы могут быть доказаны непосредственно с помощью формулы свёртки, однако более короткие доказательства будут приведены в §25, используя характеристические функции.
53

Лемма 16.9. Пусть независимые случайные величины ξn и ξm имеют
биномиальное распределение (см. опред 12.8), с параметрами n и m и вероятностью "успеха" p, тогда случайная величина ξn + ξm имеет биномиальное распределение ξn+m . Другими словами, биномиальное распределение
является устойчивым относительно суммирования.
Лемма 16.10. Пусть независимые случайные величины ξ и η имеют
нормальное распределение (см. опред 12.8), и имеют соответственно математические ожидания a1 и a2 и дисперсии σ12 и σ22 , тогда случайная величина ξ + η имеет нормальное распределение с математическим ожиданием
a1 + a2 и дисперсией σ12 + σ22 . Другими словами, нормальное распределение
является устойчивым относительно суммирования.
Пример. Товарняк состоит из 100 вагонов. Масса (измеряемая в тоннах т) произвольного вагона -- случайная величина, распределенная по нормальному закону с средним значением 65 тонн и среднеквадратичным отклонением 9 тонн. Локомотив может везти состав массой не более 6600
тонн, в противном случае необходимо прицеплять второй локомотив. Найти вероятность того, что второй локомотив не потребуется.
Решение. По лемме 16.10 имеем a = a1 + \ldots + a100 = 65 \ldots 100 = 6500,
2
2
σ = σ12 +\ldots+σ100
= 81\cdot100 = 8100. Вероятность того, что второй (локомо)
тив не потребуется, составляет P (ξ \leq 6600) = Fξ (6600) = 12 + Φ x−a
=
σ
z
2
(
)
(
)
∫
1
6600−6500
1
− t2
√1
dt
= 12 + Φ 10
2 +Φ
90
9 ≃ 2 + Φ (1, 11) ≃ 0, 87, где Φ(z) = 2\pi e
0

-- табличный интеграл вероятности нормального распределения.

§17. Математическое ожидание
Определение 17.1. 1) Начальным моментом n-го порядка дискретной
случайной величины ξ называется число
∑
n
Mξ =
xnk pk ,
k

2) Начальным моментом n-го порядка абсолютно непрерывной случайной величины ξ называется число
∫∞
Mξ n =

xn fξ (x) dx.
−∞

Определение 17.2. 1) Математическим ожиданием или средним значением дискретной случайной величины ξ называется начальный момент
54

1-го порядка
Mξ =

∑

xk p k ,

k

2) Математическим ожиданием или средним значением абсолютно непрерывной случайной величины ξ называется начальный момент 1-го порядка
∫∞
Mξ =

x fξ (x) dx.
−∞

Замечание 17.3. Если ось x рассматривать как тонкую металличе∞
∫
скую проволоку с линейной плотностью массы fξ (x), то число Mξ =
x fξ (x) dx
−∞

есть координата центра тяжести оси x.
Примеры. 1) Пусть случайная величина ξ есть число очков, выпада6
∑
ющих при одном подбрасывании игральной кости. Тогда Mξ =
k \cdot 16 =
k=1

\cdot 21 = 3, 5. Т.е. в среднем выпадает 3,5 очка!
2) Пусть случайная величина ξ имеет равномерное распределение (см.
∫b
1
опред. 12.6). Тогда Mξ = x b−a
dx = a+b
2 . Т.е. центр массы, равномерно
1
6

a

распределённой на отрезке, находится посередине.
3) Пусть случайная величина ξ имеет нормальное распределение (см.
∞
∫
(x−a)2
(x−a)2
−
1
2
опред. 12.8) fξ (x) = σ√2\pi e 2σ . Тогда Mξ =
x σ√12\pi e− 2σ2 dx = a.
−∞

4) Если случайная величина ξ принимает конечное число значений x1 ,
x2 , \ldots , xk , классические вероятности которых соответственно равны p1 =
n1
n2
nk
n , p2 = n , \ldots , pk = n , где n1 + n2 + \ldots + nk = n, то математическое
ожидание
x 1 n 1 + \ldots + x k nk
Mξ =
n
совпадает со средним арифметическим величин (x1 , \ldots , x1 , \ldots , xk , \ldots , xk ).
| {z }
| {z }
n1 раз

nk раз

Математическое ожидание функции случайной величины доставляет
следующая теорема.
Теорема 17.4. 1) Для любой дискретной случайной величины ξ и произвольной функции g : R \to R, математическое ожидание случайной величины η = g(ξ) вычисляется по формуле
Mη = Mg(ξ) =

∑
k

55

g(xk )pk

Рис. 23: К доказательству теор. 17.4.

2) Для любого абсолютно непрерывного случайного вектора
ξ = (ξ1 , \ldots , ξn ) \in Rn и произвольной функции g : Rn \to R, математическое ожидание случайной величины η = g(ξ) вычисляется по формуле
∫∞
Mη = Mg(ξ) =

∫∞
...

−∞

g(t1 , \ldots , tn )fξ1 ,...,ξn (t1 , \ldots , tn )dt1 \ldots dtn .
−∞

Доказательство. Мы докажем эту теорему только для дискретного случая.
Пусть случайная величина ξ принимает значения x1 , x2 , \ldots , xk , \ldots соответственно с вероятностями p1 , p2 , \ldots , pk , \ldots . Тогда η = g(ξ) принимает
значения y1 , y2 , \ldots , ym , \ldots соответственно с вероятностями q1 , q2 , \ldots , qm ,
\ldots , при этом полный прообраз g −1 (ym ) может состоять из одного или более
чем из одного элемента. Поэтому
∑
qm = P(g(ξ) = ym ) = P(ξ \in g −1 (ym )) =
pk .
xk \ing −1 (ym )

Тогда
Mη = Mg(ξ) =
=

∑

∑

∑

y m qm =

m

∑
m

g(xk ) pk =

m xk \ing −1 (ym )

ym
∑
k

56

∑

pk =

xk \ing −1 (ym )

g(xk ) pk .

Последнее равенство справедливо потому, что суммирование по xk \in g −1 (ym )
означает суммирование вдоль горизонтального уровня y = ym (см. рис. 23),
суммирование по m означает суммирование сумм на горизонтальных уровнях. Поэтому двойное суммирование в левой части эквивалентно суммированию по k в правой части.
Теорема 17.5. Математическое ожидание имеет следующие свойства.
1) Если C = const, то MC = C.
2) Для любой случайной величины ξ имеем M(Mξ) = Mξ.
3) Если C = const, то M(Cξ) = CMξ.
4) Для любой случайной величины ξ имеем |Mξ| \leq M|ξ|.
5) Для любых случайных величин ξ1 и ξ2 имеем M(ξ1 + ξ2 ) = Mξ1 + Mξ2 .
6) Если случайные величины ξ1 и ξ2 независимы, то M(ξ1 ξ2 ) = Mξ1 Mξ2 .
Доказательство. 1) Константу C можно рассматривать как вырожденную
случайную величину ξ = C, сосредоточенную в точке x = C. Её плотность
∞
∫ n
есть fξ (x) = δ(x − C). Поэтому имеем Mξ n = MC n =
x δ(x − C) dx = C n
−∞

и, в частности, MC = C.
2) Т.к. Mξ = const, то по п. 1) M(Mξ) = Mξ.
∞
∞
∫
∫ n
n
n
n
3) M(Cξ) =
(Cx) fξ (x) dx = C
x fξ (x) dx = C n Mξ n и, в частно−∞

−∞

сти, M(Cξ) = CMξ.
∞
∞
∞
∫ n
∫ n
∫
n
4) |Mξ | = | x fξ (x) dx| \leq
|x |fξ (x) dx =
|x|n fξ (x) dx = M|ξ|n и, в
−∞

−∞

−∞

частности, |Mξ| \leq M|ξ|.
5) По теор. 17.4.2) и 15.7.4) имеем
∫∞ ∫∞
M(ξ1 + ξ2 ) =

(x1 + x2 )fξ1 ,ξ2 (x1 , x2 ) dx1 dx2 =
−∞−∞

∫∞
=
−∞

∞

∞

∫
∫∞
∫
x1  fξ1 ,ξ2 (x1 , x2 ) dx2  dx1 + x2  fξ1 ,ξ2 (x1 , x2 ) dx1  dx2 =
−∞

−∞

∫∞
=

−∞

∫∞
x1 fξ1 (x1 ) dx1 +

−∞

x2 fξ2 (x2 ) dx2 = Mξ1 + Mξ2 .
−∞

57

6) По теор. 17.4.2) и 15.7.4) имеем
∫∞ ∫∞
M(ξ1 ξ2 ) =

x1 x2 fξ1 (x1 )fξ2 (x2 ) dx1 dx2 =
−∞−∞

∫∞
=

∫∞
x1 fξ1 (x1 ) dx1

−∞

x2 fξ2 (x2 ) dx2 = Mξ1 Mξ2 .
−∞

Замечание 17.6. Обратное утверждение, к только что доказанному
свойству 6), неверно. Следующий пример показывает, что из равенства
M(ξ1 ξ2 ) = Mξ1 Mξ2 не следует независимость величин ξ1 и ξ2 .

Рис. 24: Равномерно распределённый угол.
Пример. 17.7. Пусть случайный угол φ равномерно распределён на окружности S 1 = {z = eiφ } ⊂ C, где φ \in [0, 2\pi]. Её плотность
{ 1
, если x \in [0, 2\pi]
fφ (x) = 2\pi
0, если x \in
/ [0, 2\pi].
показана на рис. 24. Случайные величины ξ1 = cos φ и ξ2 = sin φ являются
заведомо зависимыми. Ясно, что ξ12 +ξ22 = 1. Однако математическое ожидание их произведения равно произведению их математических ожиданий.
Действительно по теор. 17.4 имеем
Mξ1 =

2\pi
∫
0

1
dx = 0,
cos x 2\pi

M(ξ1 ξ2 ) =

2\pi
∫
0

Mξ2 =

2\pi
∫
0

1
sin x 2\pi
dx = 0,

1
cos x sin x 2\pi
dx = 0.

58

§18. Дисперсия
Определение 18.1. 1) Центральным моментом n-го порядка случайной
величины ξ называется число
∫∞
M(ξ − Mξ)n =

(x − Mξ)n fξ (x) dx.
−∞

2) Дисперсией случайной величины ξ называется центральный момент
2-го порядка, т.е. число
∫∞
Dξ = M(ξ − Mξ)2 =

(x − Mξ)2 fξ (x) dx.
−∞

Замечание 18.2. Для любой случайной величины ξ её центральный момент 1-го порядка равен нулю, M(ξ − Mξ) = Mξ − Mξ = 0.
Замечание 18.3. Если ось x рассматривать как тонкую металлическую проволоку с линейной плотностью массы fξ (x), то дисперсия Dξ есть
в точности момент инерции стержня относительно его центра тяжести Mξ.
Лемма 18.4. 1) Для любой случайной величины ξ имеем Dξ ≥ 0.
2) Если C = const, то DC = 0.
3) Если C = const, то для любой случайной величины ξ имеем D(Cξ) =
2
C Dξ.
Доказательство. 1) Т.к. (x − Mξ)2 fξ (x) ≥ 0, то интеграл в опред. 18.1.2) не
меньше нуля.
2) DC = M(C − MC)2 = 0.
3) D(Cξ) = M[Cξ −M(Cξ)]2 = M[C(ξ −Mξ)]2 = C 2 M(ξ −Mξ)2 = C 2 Dξ.
Замечание 18.5. Дисперсия (по прочтению формулы Dξ = M(ξ − Mξ)2 )
равна "среднему значению квадрата отклонения случайной величины от
её среднего". То есть, дисперсия характеризует отклонение (разброс, кучность) значений случайной величины вокруг её среднего значения Mξ.
В таком случае полезно следующее
√ определение.
Определение 18.6. Число σ = Dξ называется средне квадратическим
отклонением случайной величины ξ.
Теорема 18.7. Для любой случайной величины ξ справедлива формула
Dξ = Mξ 2 − (Mξ)2 .
59

Доказательство. Dξ = M(ξ − Mξ)2 = M[ξ 2 − 2ξMξ + (Mξ)2 ] = Mξ 2 −
2M(ξMξ) + M[(Mξ)2 ] = Mξ 2 − 2(Mξ)2 + (Mξ)2 = Mξ 2 − (Mξ)2 .
Теорема 18.8. Если случайные величины ξ1 и ξ2 независимы, то
D(ξ1 + ξ2 ) = Dξ1 + Dξ2 .
Доказательство. D(ξ1 + ξ2 ) = M(ξ1 + ξ2 )2 − (M(ξ1 + ξ2 ))2 =
= M(ξ12 + 2ξ1 ξ2 + ξ22 ) − (Mξ1 + Mξ2 )2

17.4.5)

=

= Mξ12 + 2M(ξ1 ξ2 ) + Mξ22 − (Mξ1 )2 − 2Mξ1 Mξ2 − (Mξ2 )2

17.4.6)

=

= Mξ12 − (Mξ1 )2 + Mξ22 − (Mξ2 )2 = Dξ1 + Dξ2 .
Примеры 18.9. 1) Пусть ξ -- подчиняется распределению Бернулли,
т.е. принимает два значения: 1 с вероятностью p и 0 с вероятностью
q = 1 − p, тогда
Mξ = 1 \cdot p + 0 \cdot q = p, Mξ 2 = 12 \cdot p + 02 \cdot q = p,
Dξ = Mξ 2 − (Mξ)2 = p − p2 = pq.
2) Вычислим математическое ожидание и дисперсию случайной величины ξ, имеющей биномиальное распределение, т.е. ξ принимает значения
0, 1, 2, \ldots , n соответственно с вероятностями P(ξn = k) = Cnk pk (1 − p)n−k .
Возьмем n независимых случайных величин ξ1 , \ldots , ξn имеющих одно и то
же распределение Бернулли, т.е. с Mξi = p и Dξi = pq . Тогда их сумма
ξ = ξ1 + \ldots + ξn имеет биномиальное распределение и
n
n
∑
∑
Mξ =
Mξi = nMξ1 = np, Dξ =
Dξi = nDξ1 = npq.
i=1

i=1

§19. Числовые характеристики зависимости
случайных величин
Замечание 19.1. Мы знаем, что для независимых случайных величин
дисперсия их суммы равна сумме их дисперсий
D(ξ1 + ξ2 ) = Dξ1 + Dξ2 .
Чему равна дисперсия суммы в общем случае?
D(ξ1 + ξ2 ) = M(ξ1 + ξ2 )2 − [M(ξ1 + ξ2 )]2 =
= M(ξ12 + 2ξ1 ξ2 + ξ22 ) − (Mξ1 )2 − (Mξ2 )2 − 2Mξ1 Mξ2 =
= Dξ1 + Dξ2 + 2[ M(ξ1 ξ2 ) − Mξ1 Mξ2 ].
60

Если случайные величины ξ1 и ξ2 независимы, то по теор. 17.5.6) величина M(ξ1 ξ2 ) − Mξ1 Mξ2 равна нулю. С другой стороны, из равенства её нулю
вовсе не следует их независимость (см. пример 19.7). Поэтому эту величину можно использовать как "индикатор степени зависимости" случайных
величин ξ1 и ξ2 .
Определение 19.2. Ковариацией cov(ξ1 , ξ2 ) случайных величин ξ1 и
ξ2 называется число
cov(ξ1 , ξ2 ) = M [(ξ1 − Mξ1 )(ξ2 − Mξ2 )] .
Лемма 19.3 (свойства ковариации).
1) cov(ξ1 , ξ2 ) = M(ξ1 ξ2 ) − Mξ1 Mξ2 ,
2) cov(ξ, ξ) = Dξ,
3) cov(ξ1 , ξ2 ) = cov(ξ2 , , ξ1 ),
4) cov(C ξ1 , ξ2 ) = C cov(ξ1 , ξ2 ).
Доказательство. 1) cov(ξ1 , ξ2 ) = M [(ξ1 − Mξ1 )(ξ2 − Mξ2 )] = M(ξ1 ξ2 −ξ1 Mξ2 −
ξ2 Mξ1 + Mξ1 Mξ2 ) = M(ξ1 ξ1 ) − Mξ1 Mξ2 ,
2) Следует из опред. 19.1.
3) Очевидно.
4) cov(C ξ1 , ξ2 ) = M(C ξ1 ξ2 ) − M(C ξ1 )Mξ2 = C[M(ξ1 ξ2 ) − Mξ1 Mξ2 ].
Пусть ξ1 , \ldots , ξn -- случайные величины. Для сокращения формул обозначим через σij ковариацию cov(ξi , ξj ), где i, j \in {1, \ldots , n}.
Лемма 19.4 (о дисперсии линейной комбинации.) Для любых случайных
величин ξ1 , \ldots , ξn и любых чисел c1 , \ldots , cn \in R
D(c1 ξ1 + \ldots + cn ξn ) =

n ∑
n
∑

σij ci cj .

i=1 j=1

Доказательство. Рассмотрим случайную величину η = c1 ξ1 + \ldots + cn ξn .
Нетрудно видеть, что
η − Mη =

n
∑

ci (ξi − Mξi ),

i=1

и что
(η − Mη) =
2

n ∑
n
∑

ci cj (ξi − Mξi )(ξj − Mξj ).

i=1 j=1

Вычисляя математическое ожидание от обеих частей последнего равенства,
получим требуемый результат.
61

Замечание 19.5. Т.к. Dη ≥ 0, то квадратичная форма
n
n ∑
∑

σij ci cj ,

i=1 j=1

где c1 , \ldots , cn \in R рассматриваются как переменные, является неотрицательной. Из теории квадратичных форм известно, что все главные миноры
матрицы неотрицательной квадратичной формы, в нашем случае матрицы


σ11 σ12 \ldots σ1n
 σ21 σ22 \ldots σ2n 

(σij ) = 
 ... ... ... ... ,
σn1 σn2 \ldots σnn
неотрицательны, и в частности, det σij ≥ 0. При n = 2 это неравенство
принимает вид

 

 σ11 σ12  

Dξ
cov(ξ
,
ξ
)
1
1
2 
2

=
 σ21 σ22   cov(ξ2 , ξ1 )
 = Dξ1 Dξ2 − cov (ξ1 , ξ2 ) ≥ 0.
Dξ2
Замечание 19.6. Обсудим достоинства и недостатки ковариации, как
величины, характеризующей зависимость двух случайных величин.
1) Если ковариация cov(ξ1 , ξ2 ) отлична от нуля, то величины ξ1 и ξ2
зависимы.
2) Если ковариация cov(ξ1 , ξ2 ) равна нулю, то зависимость случайных
величины ξ1 и ξ2 приходится исследовать с помощью пп. 17.5 и 17.6.
3) Самая сильная зависимость между случайными величинами -- функциональная, а из функциональных -- линейная зависимость, когда η =
aξ + b. Встречаются более слабые зависимости. Например, если по последовательности независимых случайных величин ξ1 , ξ2 , \ldots построить случайные величины ξ = ξ1 + \ldots + ξ32 + ξ33 и η = ξ33 + ξ34 \ldots + ξ101 , то эти
величины зависимы, но очень "слабо" и лишь через одно-единственное общее слагаемое ξ33 . (Представьте себе, сильно ли зависимы число появлений
орла в первых 33-х подбрасываниях монеты и число появлений орла в той
же серии, но в испытаниях с 33-го по 101-е.)
4) Ковариация не является "безразмерной". Если ξ -- объём газа в сосуде, а η -- давление этого газа, то ковариация cov(ξ1 , ξ2 ) измеряется в
m3 × \pia. При переходе к другой размерности, т.е. при умножении одной из
величин ξ, η на какое-нибудь число, ковариация тоже умножается на это
число. Но умножение на число не сказывается на "степени зависимости"
величин ξ и η. Поэтому с физической точки зрения имеет смысл сравнивать зависимость случайных величин, ковариации которых имеют одну и
ту же размерность.
62

Из сказанного следует, что нужно как-то нормировать ковариацию,
чтобы получить из неё безразмерную величину, абсолютное значение которой не менялось бы при умножении или сдвиге случайных величин на
число и свидетельствовало бы о "силе" зависимости случайных величин.
Такую величину доставляет следующее определение.
Определение 19.7. Коэффициентом корреляции ρ(ξ, η) случайных величин ξ и η называется число
cov(ξ, η)
ρ(ξ, η) = √ √ .
Dξ Dη
Замечание 19.8. Чтобы увидеть "устройство" коэффициента корреляции, распишем по определению величины, стоящие в числителе и знаменателе
M [(ξ − Mξ)(η − Mη)]
√
ρ(ξ, η) = √
.
M(ξ − Mξ)2 M(η − Mη)2
Для физиков уместно провести аналогию формулы косинуса угла между
векторами в евклидовом пространстве и формулой коэффициента корреляции.
Во-первых, так как для любых случайных величин ξ, η : \Omega \to R определена их сумма (ξ + η)(x) = ξ(x) + η(x) и умножение любой случайной величины на число (α \cdot ξ)(x) = α \cdot ξ(x), где α \in R, то эти операции превращают
множество {ξ : \Omega \to R} всех случайных величин в линейное (векторное)
пространство.
Во-вторых, в этом пространстве ковариация cov(ξ, η) является скалярным произведением двух "векторов" ξ и η и превращает его в евклидово.
И в-третьих, "длиной" случайной величины ξ является её среднеквадратичное отклонение, которая
равна корню
√
√ из скалярного произведения "вектора" ξ самого на себя cov(ξ, ξ) = Dξ. Поэтому коэффициент корреляции есть косинус угла между случайными величинами ξ и η в пространстве случайных величин. Надо только доказать, что −1 \leq ρ(ξ, η) \leq 1. Заметим, что т.к. пространство случайных величин бесконечномерное, то
рисовать в виде векторов можно только те случайные величины, которые
в фиксированном базисе представимы в виде конечных линейных комбинаций элементов этого базиса.
Определение 19.9. Случайные величины ξ и η называются некоррелированными, если ρ(ξ, η) = 0. (Некоррелированность является аналогом
ортогональности.)
Теорема 19.10 (свойства коэффициента корреляции.)
1) Если случайные величины ξ и η независимы, то ρ(ξ, η) = cov(ξ, η) =
0.
63

2) |ρ(ξ, η)| \leq 1.
3) |ρ(ξ, η)| = 1 тогда и только тогда, когда случайные величины ξ и η
линейно зависимы, т.е. существуют числа a, b \in R и a ̸= 0, такие что
ξ = aη + b.
Доказательство. 1) Косвенно мы уже это доказали, см. пп. 19.5.6) и 19.3.1).
2) Требуемое неравенство следует из неравенства Dξ1 Dξ2 −cov2 (ξ1 , ξ2 ) ≥ 0,
доказанного в п. 19.5.
3.1) Докажем сначала, что из |ρ(ξ, η)| = 1 следует, что ξ = aη + b.
Перепишем опред. 19.7 в виде
(
)
ξ − Mξ η − Mη
ρ(ξ, η) = M √
\cdot √
.
Dξ
Dη
Рассмотрим сначала случай ρ(ξ, η) = +1. Воспользуемся неравенством
αβ \leq 21 (α2 + β 2 )
[(
(
)
)2 (
)2 ]
η − Mη
ξ − Mξ η − Mη
ξ − Mξ
1
√
√
+
=
ρ(ξ, η) = M √
\cdot √
\leq M
2
Dξ
Dη
Dξ
Dη
(
)
1 M(ξ − Mξ)2 M(η − Mη)2
1
=
+
= \cdot 2 = 1.
2
Dξ
Dη
2
Т.к. ρ(ξ, η) = +1, то последнее неравенство переходит в равенство
[(
(
)
)2 (
)2 ]
ξ − Mξ η − Mη
η − Mη
1
ξ − Mξ
√
√
+
M √
\cdot √
= M
,
2
Dξ
Dη
Dξ
Dη
которое можно переписать в виде
(
)2
η − Mη ξ − Mξ
√
=0
M
− √
Dη
Dξ
или в виде

Обозначим a =

√
√
)2
Dξ
DξMη
= 0.
M ξ − √ η − Mξ + √
Dη
Dη
(

√
√Dξ
Dη

и b = Mξ −

√
DξMη
√
,
Dη

получим

M (ξ − aη − b)2 = 0.
По определению математического ожидания равенство нулю математического ожидания неотрицательной случайной величины означает, что эта
величина равна нулю, поэтому ξ = aη + b.
64

В случае ρ(ξ, η) = −1 воспользуемся неравенством αβ ≥ − 12 (α2 + β 2 ) и
по аналогии из неравенства
[(
)
)2 (
)2 ]
(
1
η − Mη
ξ − Mξ η − Mη
ξ − Mξ
√
√
ρ(ξ, η) = M √
\cdot √
≥− M
+
= −1
2
Dξ
Dη
Dξ
Dη
получим требуемый результат.
3.2) Докажем теперь, что из η = aξ + b следует, что |ρ(ξ, η)| = 1. Воспользуемся свойствами математического ожидания и дисперсии.
(
)
(
)
ξ − Mξ aξ + b − M(aξ + b)
ξ − Mξ aξ − M(aξ)
√
√
√
ρ(ξ, aξ+b) = M
\cdot
=M
\cdot √
=
Dξ
Dξ
D(aξ + b)
D(aξ)
(
= aM

(ξ − Mξ)2
√
DξD(aξ)

)

aM(ξ − Mξ)2
a
= √
=
=
|a|
a 2 D2 ξ

{

1, если a > 0
.
−1, если a < 0

Что и требовалось доказать.
Определение 19.11. Если ρ(ξ, η) < 0, то случайные величины ξ и η
называются отрицательно коррелированными; если ρ(ξ, η) > 0, то -- положительно коррелированными.
Замечание 19.12. Смысл знака коэффициента корреляции особенно ясен
в случае ρ(ξ, η) = ±1. В этом случае знак ρ совпадает со знаком a в равенстве η = aξ + b. Значение ρ(ξ, η) = 1 означает, что чем больше ξ, тем
больше и η. Напротив, ρ(ξ, η) = −1 означает, что чем больше ξ, тем меньше и η. Аналогично можно трактовать знак коэффициента корреляции и
в случае, когда |ρ(ξ, η)| < 1, помня при этом, что зависимость случайных
величин ξ и η не линейная и может быть даже не функциональная.
Задача 19.13. Найти коэффициент корреляции между числом выпадений единицы и числом выпадений шестёрки при n подбрасываниях игральной
кости.
Решение. Для i = 1, 2, 3, 4, 5, 6 обозначим через ξi случайную величину,
равную числу выпадений грани с i очками при n подбрасываниях кости. Посчитаем сначала ковариацию cov(ξ1 , ξ6 ) = M(ξ1 ξ6 ) − Mξ1 Mξ6 .
Каждая из случайных величин ξi имеет биномиальное распределение и
каждое из её значений может появиться в каждом из n подбрасываниях с
вероятностью p = 1/6, и по п. 19.9.2) Mξi = np = n/6 и Dξi = npq = 5n/36.
Т.к. при каждом подбрасывании выпадает какая-то грань, то ξ1 + \ldots +
ξ6 = n. Т.к. игральная кость симметрична, то при i ̸= j все математические ожидания M(ξi ξj ) одинаковы. Заметим, что из той же симмет65

рии следует, что M(ξi ξi ) то же одинаковы и равны Mξi2 = Dξi + (Mξi )2 =
5n/36 + n2 /36 = (n2 + 5n)/36.
Подсчитаем величину M[ξ1 (ξ1 + \ldots + ξ6 )] двумя способами. Во-первых,
она равна
M[ξ1 (ξ1 + \ldots + ξ6 )] = M(ξ1 \cdot n) = n2 /6,
а во-вторых,
M[ξ1 (ξ1 + \ldots + ξ6 )] = Mξ12 + 5M(ξ1 ξ6 ) = (n2 + 5n)/36 + 5M(ξ1 ξ6 ).
Отсюда 5M(ξ1 ξ6 ) = n2 /6 − (n2 + 5n)/36, т.е.
n2 − n
M(ξ1 ξ6 ) =
.
36
Следовательно, искомый коэффициент корреляции равен
M(ξ1 ξ6 ) − Mξ1 Mξ6
(n2 − n)/36 − n2 /36
1
cov(ξ1 , ξ6 )
√
√
√
=
=
=− .
ρ(ξ1 , ξ6 ) = √
5n/36
5
Dξ1 Dξ6
Dξ1 Dξ6
Естественно, что коэффициент корреляции не зависит от числа подбрасываний игральной кости.

66

Глава 3. ЗАКОНЫ БОЛЬШИХ ЧИСЕЛ
§20. Неравенство Бьенеме–Чебышёва и
неравенство Маркова
Напомним, что мы рассматриваем случайные величины, имеющие конечные начальные и центральные моменты до n-го порядка включительно.
Метод доказательства неравенств, изучаемых в этом параграфе, принадлежит Чебышёву16 .
Теорема 20.1 (неравенство Маркова17 , 1913 г.). Для любой случайной
величины ξ и для любого ε \in (0, ∞), имеет место неравенство
P ( |ξ| ≥ ε ) \leq

M|ξ|
.
ε

Доказательство. Если fξ (x) -- плотность случайной величины ξ, то
∫
P ( |ξ| ≥ ε ) =
fξ (t)dt.
|x| ≥ ε

Ясно, что для всех t \in { |x| ≥ ε } выполнено неравенство |t|ε ≥ 1. Поэтому
при замене fξ (t) на |t|ε fξ (t) подынтегральное выражение не уменьшится, т.е.
∫

∫

P ( |ξ| ≥ ε ) =

fξ (t)dt \leq
|x| ≥ ε

1
|t|
fξ (t) dt =
ε
ε

∫
|t| fξ (t) dt.
|x| ≥ ε

|x| ≥ ε

Если теперь мы увеличим область интегрирования с { |x| ≥ ε } до (−∞, ∞),
то интеграл справа тоже не уменьшится. Окончательно получаем
P ( |ξ| ≥ ε ) \leq

1
ε

∫
|t| fξ (t) dt \leq
|x| ≥ ε

16

1
ε

∫∞
|t| fξ (t) dt =
−∞

M|ξ|
.
ε

Чебышёв, Пафнутий Львович (распространено неправильное произношение его фамилии с ударением на первый слог) (1821 -- 1894), выдающийся русский математик и механик, внёсший большой вклад
в теорию вероятностей, теорию приближений, теорию интерполирования функций, интегральное исчисление и картографию. Работая на "оборонку," он улучшил дальнобойность и точность артиллерийской
стрельбы, чем оказал большое влияние на развитие русской артиллерии.
17
Марков, Андрей Андреевич (1856 -- 1922), выдающийся русский математик, внёсший большой вклад
в теорию вероятностей и математический анализ.

67

Следствие 20.2 (двойственное неравенство Маркова). Для любой случайной величины ξ и для любого ε \in (0, ∞) имеет место неравенство
P ( |ξ| < ε ) ≥ 1 −

M|ξ|
.
ε

Доказательство. По лемме 3.7 имеем P ( |ξ| < ε ) = 1 − P ( |ξ| ≥ ε ) . Подставим это выражение в неравенство Маркова, получим требуемый результат.
Теорема 20.3 (обобщённое неравенство Маркова). Для любой случайной величины ξ, для любого ε \in (0, ∞) и любой монотонно возрастающей
функции g : (0, ∞) \to (0, ∞) имеет место неравенство
P ( |ξ| ≥ ε ) \leq

Mg(|ξ|)
.
g(ε)

Доказательство. Поскольку функция g монотонно возрастает, то
P ( |ξ| ≥ ε ) = P ( g(|ξ|) ≥ g(ε) ). Оценивая последнюю вероятность согласно неравенству Маркова, получим требуемый результат:
(
)
Mg(|ξ|)
P g(|ξ|) ≥ g(ε) \leq
.
g(ε)

Следствие 20.4. Для любой случайной величины ξ, для любого ε \in
(0, ∞), и любой монотонно возрастающей функции g : (0, ∞) \to (0, ∞)
имеет место неравенство
(
)
Mg(|ξ|)
P g(|ξ|) < g(ε) > 1 −
g(ε)
(двойственное к обобщённому неравенству Маркова).
Доказательство аналогично доказательству след. 20.2.
В 1853 г. И.-Ж. Бьенеме18 и в 1866 г. независимо от него П.Л. Чебышёв
доказали следующее неравенство.
Теорема 20.5 (неравенство Бьенеме – Чебышёва). Для любой случайной
величины ξ и любого ε \in (0, ∞) имеет место неравенство
P ( |ξ − Mξ| ≥ ε ) \leq
18

Dξ
.
ε2

И.-Ж. Бьенеме (Irénée-Jules Biemaymé, 1796 -- 1878), французский математик, основные работы по
теории вероятностей и математической статистике.

68

Доказательство. Т.к. неравенство Маркова 20.1 справедливо для произвольной случайной величины, то перепишем его для случайной величины ξ − Mξ,
получим
M|ξ − Mξ|
.
P ( |ξ − Mξ| ≥ ε ) \leq
ε
Зададим функцию g : (0, ∞) \to (0, ∞) по формуле g(ε) = ε2 . Видно,
что она является монотонно возрастающей и поэтому удовлетворяет условиям теор. 20.3, и следовательно, для неё выполнено обобщённое неравенство
Маркова
M(ξ − Mξ)2
Dξ
P ( |ξ − Mξ| ≥ ε ) \leq
=
.
ε2
ε2
Что и требовалось доказать.
Следствие 20.6. Для любой случайной величины ξ и любого ε \in (0, ∞),
имеет место неравенство
P ( |ξ − Mξ| < ε ) ≥ 1 −

Dξ
ε2

(двойственное к неравенству Бьенеме – Чебышёва).
Мы будем называть двойственное неравенство тоже неравенством Бьенеме – Чебышёва.
Следствие 20.7. Для любой случайной величины ξ вероятность того,
что она примет значение, отличающееся от её среднего Mξ более чем на
три корня из её дисперсии, не превосходит 1/9, т.е.
(
)
√
1
P |ξ − Mξ| ≥ 3 Dξ \leq .
9
Доказательство. Из неравенства Бьенеме-Чебышёва имеем
(
)
√
Dξ
1
P |ξ − Mξ| ≥ 3 Dξ \leq √
=
.
9
(3 Dξ)2

§21. Последовательности случайных величин
Замечание 21.1. Напомним, что по опред. 11.1 случайная величина
есть функция ξ : \Omega \to R. Поэтому последовательность случайных величин
ξ1 , ξ2 , \ldots , ξn , \ldots = {ξn }∞
n=1 = {ξn }
короче

69

есть на самом деле последовательность функций {ξn : \Omega \to R}∞
n=1 , определённая на одном и том же пространстве элементарных событий \Omega.
В математическом анализе мы изучили следующие две сходимости последовательности функций.
Определение 21.2. Последовательность функций ξ1 , ξ2 , \ldots , ξn , \ldots сходится к функции ξ поточечно, если для любой точки \Omega \in \Omega последовательность чисел (значений) ξ1 (\Omega), ξ2 (\Omega), \ldots , ξn (\Omega), \ldots сходится к значению ξ(\Omega) функции ξ; или короче19 lim ξn (\Omega) = ξ(\Omega) для любой точки \Omega \in \Omega.
n\to∞
Определение 21.3. Последовательность функций ξ1 , ξ2 , \ldots , ξn , \ldots сходится к функции ξ поточечно почти всюду в \Omega, если подмножество A ⊂
\Omega, в которых поточечная сходимость не выполняется, имеет меру 0, т.е.
\mu(A) = 0.
В теории вероятностей объекты \Omega, A, \Omega являются событиями, а мерой
их наступления является вероятность, поэтому в теории вероятностей
сходимости "почти всюду"соответствует так называемая сходимость
"почти наверное."
Определение 21.4. Говорят, что последовательность случайных величин {ξn } сходится почти наверное к случайной величине ξ, если имеют
место эквивалентные друг другу равенства
{
}
{
}


P \Omega \in \Omega  lim ξn (\Omega) = ξ(\Omega) = 1 и P \Omega \in \Omega  lim ξn (\Omega) ̸= ξ(\Omega) = 0.
n\to∞

n\to∞

Замечание 21.5. Чтобы пользоваться на практике сходимостью "почти наверное" необходимо знать, как устроены отображения \Omega 7\to ξn (\Omega).
Как правило в задачах теории вероятностей известны не сами случайные
величины ξn , а их функции распределения, скажем P(ξn \leq x) = Fξn (x) =
∫x
fξn (t)dt. Можно ли в таком случае, обладая информацией только о функ−∞

циях распределения, каким-нибудь образом исследовать сходимость последовательности случайных величин {ξn }? Ответ: да, можно, если потребовать, чтобы вероятность тех элементарных исходов \Omega, для которых
значение ξn (\Omega) не попадает в "ε-окрестность" числа ξ(\Omega), сходилась к нулю при n \to ∞. В теории вероятностей эту идею реализуют с помощью
так называемой "сходимости по вероятности".
Определение 21.6. Говорят, что последовательность случайных величин {ξn } сходится по вероятности к случайной величине ξ, если для любого
ε \in (0, ∞) имеют место эквивалентные равенства
lim P ( |ξn − ξ| ≥ ε) = 0

и

n\to∞
19

lim P ( |ξn − ξ| < ε) = 1.

n\to∞

Используя определение сходимости числовой последовательности.

70

(♯)

Если {ξn } сходится по вероятности к ξ, то вместо пределов (♯) коротко
P
P
пишут "ξn \to ξ при n \to ∞," а т.к. n \to ∞ всегда, то ещё короче: ξn \to ξ.
Хотя на практике для проверки такой сходимости проверяют выполнение
одного из равенств (♯).
Пример. Рассмотрим последовательность случайных величин {ξn }∞
n=1 ,
в которой для каждого n случайная величина задана следующим рядом распределения
ξn
0
n3
.
P 1 − 1/n 1/n
Докажем, что эта последовательность сходится по вероятности к вырожденной случайной (детерминированной) величине ξ, имеющей ряд расξ 0
пределения
, а проще говоря, сходится по вероятности к нулю.
P 1
Действительно, зафиксируем произвольное ε > 0. Для всех n, начиная
с некоторого n0 такого, что n30 > ε, выполнено равенство ниже
(∗)

P ( |ξn − 0| ≥ ε) = P ( ξn ≥ ε) = P

(

) 1
ξn = n3 = .
n

Применяя теперь опред. 21.6 получаем
1
= 0,
n\to∞
n\to∞ n
т.е. последовательность случайных величин ξ1 , ξ2 , \ldots , ξn , \ldots сходится по
P
вероятности к ξ, т.е. ξn \to ξ.
В нашем примере случайные величины ξn с ростом n могут принимать
всё бóльшие и бóльшие значения, но с всё меньшей и меньшей вероятностью.
Замечание 21.7. Сходимость по вероятности может не сопровождаться сходимостью математических ожиданий (или других начальных и
P
центральных моментов): из ξn \to ξ не следует, что Mξn \to Mξ. Например,
lim P ( |ξn − 0| ≥ ε) = lim

P

в предыдущем примере ξn \to ξ, однако Mξn = n2 и Mξ = 0, и ясно, что
последовательность 1, 4, 9, ... не сходится к нулю.
Сходимость по вероятности обладает теми же свойствами, как и поточечная сходимость.
P
P
Теорема 21.8. Если ξn \to ξ и ηn \to η, то
P

1) ξn + ηn \to ξ + η,
71

P

2) ξn \cdot ηn \to ξ \cdot η.
P

3) Если g -- непрерывная функция, то g(ξn ) \to g(ξ).
P

P

4) Если ξn \to C и функция g непрерывна в точке C, то g(ξn ) \to g(C).
(Без доказательства.)
Другой тип сходимости случайных величин, который нам понадобится
в дальнейшем, определяется через поточечную сходимость функций распределений. Это так называемая "слабая сходимость." Пусть задана последовательность случайных величин {ξn }∞
n=1 с функциями распределения
∞
{Fξn (x)}n=1 , и задана случайная величина ξ с функцией распределения Fξ (x).
Определение 21.9. Говорят, что последовательность случайных величин {ξn }∞
n=1 слабо сходится к случайной величине ξ, если последовательность их функций распределения {Fξn (x)}∞
n=1 сходится поточечно к функции распределения Fξ (x), т.е. lim Fξn (x) = Fξ (x).
n\to∞

Если {ξn } слабо сходится к ξ, то коротко пишут ξn =⇒ ξ. На практике для проверки слабой сходимости проверяют выполнение равенства
lim Fξn (x) = Fξ (x) для любого x \in R.
n\to∞

P

Теорема 21.10. 1) Если ξn \to ξ, то ξn =⇒ ξ,
P

2) Если ξn =⇒ C = const, то ξn \to C.
P

3) Если ξn \to C и ηn =⇒ η, то ξn \cdot ηn =⇒ Cη.
P

4) Если ξn \to C и ηn =⇒ η, то ξn + ηn =⇒ C + η.
(Без доказательства.)

§22. Законы больших чисел
Одним из главных разделов теории вероятностей составляют так называемые "предельные теоремы". Они описывают условия возникновения
вероятностных закономерностей при наличии большого числа случайных
факторов. Предельные теоремы можно условно разделить на три типа:
1) закон больших чисел, 2) предельные теоремы биномиального распределения и 3) центральные предельные теоремы. Этот и следующие параграфы
посвящены изучению таких теорем.
Определение 22.1. Говорят, что последовательность случайных величин {ξn }∞
n=1 удовлетворяет закону больших чисел (ЗБЧ), если для любого
ε \in (0, ∞) (при некоторых дополнительных условиях) имеют место экви72

валентные друг другу равенства

( n
)
n
1 ∑

∑
1


lim P 
ξk −
Mξk  < ε = 1
n\to∞

n
n
k=1

(♭)

k=1

и

( n
)
n
1 ∑

∑
1


lim P 
ξk −
Mξk  ≥ ε = 0.
n\to∞
n

n
k=1

(♯)

k=1

Другими словами, среднее арифметическое первых n членов последовательности случайных величин сходится по вероятности к среднему арифметическому математических ожиданий её первых n членов при n \to ∞,
или в символической форме:
∑
1∑
P 1
ξk \to
Mξk при n \to ∞.
n
n
n

n

k=1

k=1

Замечание 22.2. Закон больших чисел в обобщённом смысле -- это совокупность теорем о том, что при некоторых условиях имеют место формулы типа (♭) и (♯) и их многочисленные обобщения. Т.к. каждая такая
теорема представляет собой конкретный закон больших чисел, то имеет
смысл говорить о законах больших чисел. Широкие условия применимости
ЗБЧ были найдены впервые Чебышёвым в 1867 г. Эти условия затем были
обобщены А.А. Марковым (старшим). Окончательное решение проблемы о
необходимых и достаточных условиях применимости ЗБЧ было найдено
А.Н. Колмогоровым в 1928 г. В этом параграфе мы изучим три наиболее
известных таких закона.
Теорема 22.3 (ЗБЧ в форме Чебышёва). Пусть ξ1 , ξ2 , \ldots , ξn , \ldots -- последовательность попарно независимых случайных величин, имеющих дисперсии, ограниченные одной и той же константой C, т.е.
Dξ1 \leq C,

Dξ2 \leq C,

... ,

Dξn \leq C,

Тогда для любого ε \in (0, ∞) при n \to ∞
∑
1∑
P 1
ξk \to
Mξk .
n
n
n

n

k=1

k=1

73

... .

Доказательство. По 18.4.3) и 18.8 имеем
(
)
n
n
n
∑
∑
1
1 ∑
1
1
C
D
ξk = 2
D ξk \leq 2 Cn =
ξk = 2 D
.
n
n
n
n
n
k=1

k=1

k=1

По след. 22.6

( n
)
D
n
1 ∑

∑
1


P 
ξk −
Mξk  < ε ≥ 1 −
n

n
k=1

(

k=1

1
n

n
∑
k=1
ε2

)
ξk
≥1−

C
.
nε2

Переходя к пределу при n \to ∞ получим неравенство

( n
)
n
1 ∑

∑
1


lim P 
ξk −
Mξk  < ε ≥ 1,
n\to∞
n

n
k=1

k=1

откуда по лемме 3.6 получаем требуемый результат.
Замечание 22.4. Из доказательства теор. 22.3 следует, что двойственное неравенство Бьенеме – Чебышёва можно записать в виде:
( n
)
∑
1

( n
)
D n
ξk
n
1 ∑

1∑


k=1
P 
ξk −
Mξk  ≥ ε \leq
.
(⋆)
n

n
ε2
k=1

k=1

Теорема 22.5 (ЗБЧ в форме Хинчина20 (1929)). Пусть ξ1 , ξ2 , \ldots , ξn , \ldots
-- последовательность попарно независимых и одинаково распределённых
случайных величин, то есть
Mξ1 = Mξ2 = \ldots = Mξn = \ldots
Тогда среднее арифметическое
гими словами

1
n

n
∑

1
n

n
∑

и

Dξ1 = Dξ2 = \ldots = Dξn = \ldots .

ξk сходится по вероятности к Mξ1 , дру-

k=1

P

ξk \to Mξ1 . При этом для любого ε \in (0, ∞) неравен-

k=1

ство Бьенеме – Чебышёва можно записать в виде:

( n
)
1 ∑

Dξ1


P 
ξk − Mξ1  ≥ ε \leq 2 .
n

nε
k=1

20

Александр Яковлевич Хинчин (1894 -- 1959), один из наиболее значимых математиков в советской
школе теории вероятностей. Им получены основополагающие результаты в теории функций действительного переменного, теории чисел, теории вероятностей и статистической физике.

74

n
∑
Доказательство. Для доказательства достаточно подставить n1
Mξk =
k=1
)
( n
∑
Mξ1 и D n1
ξk = n1 Dξ1 в ЗБЧ в форме Чебышёва и в неравенство (⋆).
k=1

Теорема 22.6 (ЗБЧ в форме Бернулли (1713)). Пусть A -- событие,
которое может произойти в любом из n независимых испытаний с одной и той же вероятностью p. Пусть n(A) -- число появлений события
A в этих n испытаниях. Тогда относительная частота n(A)
n сходится по
вероятности к вероятности p, т.е.

n(A)
n

P

\to Mξ1 . При этом для любого

ε \in (0, ∞) неравенство Бьенеме – Чебышёва можно записать в виде:

)
(
 n(A)

p(1 − p)
\leq
P 
− p ≥ ε
.
n
nε2
Доказательство. Видно, что ЗБЧ в форме Бернулли удовлетворяет условиn
∑
ям ЗБЧ в форме Хинчина. Среднее арифметическое n1
ξk нулей и единиц,
k=1

n(A)
n ,

т.е. относительной чавыпавших при n независимых испытаниях, равно
стоте появления события A (см. опред 4.2). В примере 18.9.1) мы нашли, что
Mξ1 = p и Dξ1 = p(1 − p). Подставляя эти величины в ЗБЧ в форме Хинчина,
получим ЗБЧ в форме Бернулли.
Пример 22.7. Монету подбрасывают 10 000 раз. Оценить вероятность
того, что относительная частота выпадения герба отличается от классической вероятности 1/2 не менее чем на 0,01.

(
)
 n(A) 1 
Решение. Другими словами, требуется оценить P  n − 2  ≥ 0, 01 ,
n
∑
где n = 104 , n(A) =
ξk -- число выпадений герба при условии, что ξk явk=1

ляются независимыми случайными величинами, имеющими распределение
Бернулли с p = 12 , и равные единице, если выпал герб, и нулю -- в противном
случае. Применим ЗБЧ в форме Бернулли. Поскольку Dξ1 = p(1 − p) = 41 ,
то искомая оценка сверху выглядит следующим образом:

(
)
 n(A) 1 
1
1
Dξ1
P 
−  ≥ 0, 01 \leq
=
=
,
n
2
n 0, 012
4 \cdot 104 \cdot 10−4
4
Другими словами, неравенство Бьенеме – Чебышёва позволяет заключить,
что в среднем не более чем в четверти случаев при 10 000 подбрасываниях
монеты частота выпадения герба будет отличаться от 1/2 более чем на
75

0,01. Мы увидим, что эта оценка достаточно грубая, когда изучим так
называемую "центральную предельную теорему."
В заключение параграфа приведём без доказательства ЗБЧ в форме Пуассона.
Теорема 22.8 (ЗБЧ в форме Пуассона21 (1837)). Пусть A -- событие,
которое может произойти в n независимых испытаниях с вероятностями
p1 , p2 , \ldots , pn . Пусть n(A) -- число появлений события A в этих n испытаниях. Тогда относительная частота n(A)
сходится по вероятности к
n
n
n(A) P 1 ∑
среднему арифметическому вероятностей pk , т.е. n \to n
pk .
k=1

§23. Предельные теоремы для
биномиального распределения
Теорема Пуассона
Замечание 23.1. По теор. 9.2 вероятность появления k успехов при n
испытаниях схемы Бернулли с вероятностью успеха равной p вычисляется
по формуле
P(ξn = k) = Cnk pk (1 − p)n−k = Cnk pk q n−k .
Если числа k и n большие и при этом одна из вероятностей p или q мала,
то подсчёт по этой формуле становится очень трудным. Мы рассмотрим
три случая, когда для упрощения вычислений применимы приближённые
формулы.
Определение 23.2. Дискретная случайная величина ξ со счётным пространством \Omega = {0, 1, 2, \ldots , k, \ldots , }, подчиняется распределению Пуассона с параметром λ > 0, если её ряд распределения определена соответствиk
ем k 7\to Pλ (k) = λk! e−λ . (Ср. с опред 4.11.)
Нетрудно подсчитать, что для распределения Пуассона Mξ = λ и Dξ =
λ. На рис. 25 показаны функции Pλ (k) для λ = 0, 1; 1; 10, где пунктиром
показаны огибающие. В каждом случае сумма длин вертикальных отрезков равна 1. Сравните график на рис. 25.3 с графиком биномиального распределения, показанным на рис. 8: обе случайные величины имеют близкие
математические ожидания и похожие графики, только биномиальный график -- без "хвоста". Эта внешняя схожесть наводит на мысль, что биномиальное распределение может быть аппроксимировано распределением
Пуассона.
21

Симеон-Дени Пуассон (Siméon-Denis Poisson, 1781 -- 1840), знаменитый французский физик и математик. Его труды относятся к разным областям чистой математики, математической физики, теоретической
и небесной механики.

76

Рис. 25: Распределение Пуассона.
Рассмотрим бесконечную таблицу событий:
A11
A21
A31
...
An1
...

A22
A32
...
An2
...

A33
,
... ...
An3 \ldots , Ann
... ... ...

где 1) в n-ой строке, n = 1, 2, \ldots , стоят n событий An1 , An2 , An3 , \ldots , Ann ;
2) в каждой строке события попарно независимы;
3) каждое событие в n-ой строке происходит с одной и той же вероятностью pn , зависящей только от номера строки.
Обозначим через ξn случайную величину, равную числу событий Ani ,
произошедших в n-ой строке. Ясно, что случайная величина ξn принимает значения k = 0, 1, 2, \ldots , n и имеет биномиальное распределение k 7\to
Cnk pkn (1 − pn )n−k .
Определение 23.3. Говорят, что последовательность p1 , p2 , \ldots ,
pn , \ldots удовлетворяет закону малых чисел, если lim pn = 0 и существуn\to∞

77

ет предел
lim npn = λ,

n\to∞

0 < λ < ∞.

где

Теорема 23.4 (Пуассона). Если последовательность {pn }∞
n=1 удовлетворяет закону малых чисел, то для любого k ≥ 0 имеет место равенство
lim

n\to∞

Cnk

pkn (1

− pn )

n−k

λk −λ
= e .
k!

Доказательство. Обозначим λn = n \cdot pn . Тогда
n!
pkn (1 − pn )n−k =
k!(n − k)!
( )k (
)n−k
n(n − 1) \ldots (n − k + 1) λn
λn
=
1−
=
k!
n
n
(
)n (
)−k
λn
λn
λkn n(n − 1) \ldots (n − k + 1)
=
\cdot
1−
1−
=
k!
nk
n
n
(
)(
) (
)(
)n (
)−k
λkn
1
2
k−1
λn
λn
=
.
1−
1−
... 1 −
1−
1−
k!
n
n
n
n
n
Отсюда переходя к пределу при n \to ∞ получим требуемый результат.
P(ξn = k) = Cnk pkn (1 − pn )n−k =

Замечание 23.5. Теорема Пуассона доставляет приближённую формулу
(np)k −np
e .
k!
Заметим, что в примере 23.9.2) мы вычислили математическое ожидание и дисперсию для биномиального распределения Mξ = np и Dξ = npq.
Поэтому имеем
(Mξ)k −Mξ
e
.
P(ξn = k) ≃
k!
Параметр λ = np является математическим ожиданием для распределения Пуассона. Таким образом, биномиальное распределение аппроксимируется распределением Пуассона так, что оба распределения имеют одно и то
же математическое ожидание. На самом деле оба распределения имеют и
достаточно близкие дисперсии. В области применения приближённой формулы вероятность p должна быть мала, а значит q = 1 − p ≃ 1, поэтому
Dξ = npq ≃ np = λ.
P(ξn = k) = Cnk pk (1 − p)n−k ≃

78

Пример. Вероятность попадания в цель при каждом выстреле равна
0,001. Найти вероятность попадания в цель двумя и более пулями, если
число выстрелов равно 5 000.
Решение. Этот эксперимент реализует схему Бернулли, и использование точной формулы даёт значение искомой вероятности равное
P(ξn ≥ 2) =

5000
∑

P(ξ5000 = k) =

k=2

= 1 − P(ξ5000 = 0) − P(ξ5000 = 1) =
= 1 − 0, 9995000 − 5000 \cdot 0, 001 \cdot 0, 9994999 .

(⋆)
k

−np
Воспользуемся теоремой Пуассона P(ξn = k) ≃ (np)
. Вычислим: λ =
k! e
−5
np = 5000 \cdot 0, 001 = 5, P(ξ5000 = 0) ≃ e , P(ξ5000 = 1) ≃ 5e−5 . Поэтому

Pn (ξ ≥ 2) = 1 − P(ξ5000 = 0) − P(ξ5000 = 1) ≃ 1 − 6e−5 ≃ 0, 9596.
Вычисление по точной формуле (⋆) с точностью до четвёртого знака
даёт ответ Pn (ξ ≥ 2) = 0, 9575. Нетрудно подсчитать, что ошибка от
применения приближённой формулы составляет меньше 0,25%.
Теорема Муавра
Эта предельная теорема обеспечивает приближённое вычисление вероятностей биномиального распределения,
P(ξn = k) = Cnk \cdot pk \cdot q n−k ,
в случае, когда при n \to ∞ обе величины k \to ∞ и n − k \to ∞ так,
√
что величина xk = k−np
npq ограничена, т.е. существует N > 0, такое что
|xk | < N для k = 0, 1, 2, \ldots .
Теорема 23.6 (локальная теорема Муавра22 ). Если вероятность 0 <
√
p < 1 постоянна, и величина xk = k−np
npq ограничена, то справедлива формула
[
( 2 )]
1
x
lim Cnk pk q n−k − √
exp − k
= 0.
n\to∞
2
2\pinpq
(Без доказательства.)
22

Абрахам де Муавр (Abraham de Moivre, 1667 -- 1754), английский математик французского происхождения. Основные труды по теории рядов, теории вероятностей, теории комплексных чисел.

79

Замечание 23.7. Локальная теорема Муавра доставляет приближённую формулу
( 2)
1
x
P(ξn = k) = Cnk pk q n−k ≃ √
exp − k .
2
2\pinpq
Напомним, что в примере 18.9.2) мы вычислили математическое ожидание и дисперсию для биномиального распределения Mξ = np и Dξ = npq.
Поэтому имеем
k − np k − Mξ
k − Mξ
xk = √
= √
=
npq
σ
Dξ

и

)
(
1
(k − Mξ)2
P(ξn = k) ≃ √ exp −
.
2σ 2
σ 2\pi
Последняя формула означает, что биномиальное распределение аппроксимировано нормальным, причём оба распределения имеют одинаковые математические ожидания и дисперсии.
Пример. Пусть надо вычислить P(ξn = k) при n = 10 000, k = 40,
p = 0, 005. Сделаем подготовительные вычисления:
√
√
√
npq = 10 000 \cdot 0, 005 \cdot 0, 995 = 49, 75 ≃ 7, 05,
k − np
≃ −1, 42.
√
npq
По теореме Муавра имеем
(
)
1, 422
1
√ exp −
P(ξn = k) ≃
.
2
7, 05 2\pi
Функция
x2
1
φ(x) = √ e− 2
2\pi
табулирована (см., например, Таблицу 23.8.8 в [6]), по таблице находим

P(ξn = k) ≃

0, 1456
= 0, 00206.
7, 05

Заметим, что точное значение с точностью до третьего знака P(ξn =
k) ≃ 0, 00197. Полученная ошибка составляет 4,6%.
Теорема Муавра-Лапласа
80

Теорема 23.8 (интегральная теорема Муавра(1730)-Лапласа23 (1812)).
Если случайная величина ξ имеет биномиальное распределение P(ξn = k) =
Cnk pk q n−k , тогда для любых вещественных k1 и k2 имеет место равенство
∫y
lim P(k1 \leq ξn \leq k2 ) =

n\to∞

x

t2
1
√ e− 2 dt,
2\pi

k2 −np
√
где x = k√1 −np
npq и y =
npq .
Теорему Муавра-Лапласа мы докажем в §25 как частный случай центральной предельной теоремы.

§24. Характеристические функции
Замечание 24.1. Решение многих задач теории вероятностей, особенно тех, которые связаны с суммированием независимых случайных величин, удаётся получить с помощью т.н. характеристических функций.
Связь между преобразованием Фурье и характеристической функцией можно описать следующим образом. Если обозначить преобразование Фурье через Φ, то формулы прямого и обратного преобразования можно записать
следующим образом
1
φ(t) = Φ[f ] = √
2\pi

∫∞

e−ixt f (x) dx,

−∞

1
f (x) = Φ−1 [φ] = √
2\pi

∫∞
eitx φ(t) dt.
−∞

Если ξ -- случайная величина, имеющая плотность fξ (x), то в терминах
преобразования Фурье её характеристическая функция есть
θξ (t) =

√

2\pi Φ−1 [fξ ] =

∫∞
eitx fξ (x) dx.
−∞

23

Пьер-Симон Лаплас (Pierre-Simon Laplace, 1749 -- 1827), французский математик, астроном, физик
и философ; известен работами по небесной механике, дифференциальным уравнениям, является одним
из создателей теории вероятностей. Заслуги Лапласа в чистой и прикладной математике и астрономии
громадны: он усовершенствовал почти все разделы этих наук.

81

Определение 24.2. Пусть fξ (x) -- плотность случайной величины ξ,
тогда функция
∫∞
θξ (t) = Meitξ =
eixt fξ (x) dx
−∞

называется характеристической функцией случайной величины ξ.
Замечание 24.3. 1) Пусть ξ и η -- вещесвенные случайные величины. Составим комплексную случайную величину ξ + iη. Мы распространяем действие знака математического ожидания M на любую комплексную
случайную величину по свойству линейности:
M(ξ + iη) = Mξ + i Mη.
2) Зная характеристическую функцию θξ (t), можно однозначно восстановить функцию распределения, а также плотность вероятности или ряд
распределения случайной величины ξ. Например, если модуль характеристической функции θξ (t) интегрируем на всей прямой, то плотность fξ (x)
случайной величины ξ находится по формуле
1
fξ (x) =
2\pi

∫∞

e−ixt θξ (t) dt.

−∞

Свойства характеристических функций
Теорема 24.4. Характеристическая функция θξ (t) любой случайной величины ξ равномерно непрерывна. (Без доказательства.)
Лемма 24.5. 1) θξ (0) = 1,
2) |θξ (t)| \leq 1 для −∞ < t < ∞.
Доказательство. 1) θξ (0) = Me0 = 1.
2) |θξ (t)| = |Meitξ | \leq M|eitξ | = M 1 = 1.
Лемма 24.6. Если η = aξ + b, где a и b -- постоянные, то
θη (t) = θξ (at) eibt .
Доказательство. θη (t) = Meitη = Meit(aξ+b) = eibt Meiatξ = eibt θξ (at).
Лемма 24.7. Если ξ1 и ξ2 -- независимые случайные величины, то
θ ξ1 +ξ2 (t) = θξ1 (t) \cdot θξ2 (t).
82

Доказательство. Т.к. ξ1 и ξ2 -- независимые величины, то eitξ1 и eitξ2 тоже
независимы. Тогда
(
) 16.5.6)
θ ξ1 +ξ2 (t) = M eit(ξ1 +ξ2 ) = M eitξ1 \cdot eitξ2
= M eitξ1 \cdot M eitξ2 = θξ1 (t) \cdot θξ2 (t).

Следствие 24.8. Если ξ1 , \ldots , ξn -- независимые случайные величины,
то
θ ξ1 + ... +ξ2 (t) = θξ1 (t) \cdot ... \cdot θξn (t).
Лемма 24.9. θ ξ (−t) = θ ξ (t), где черта означает комплексное сопряжение.
Доказательство. θ ξ (−t) = M e−itξ = M eitξ = Meitξ = θ ξ (t).
Лемма 24.10. Если ξ -- дискретная случайная величина, заданная ряξ x1 x 2 \ldots x k \ldots
дом распределения (конечным или бесконечным)
,
P p1 p2 \ldots pk \ldots
∑
то θξ (t) = eitxk pk .
k

Доказательство. Это утверждение непосредственно следует из теор. 17.4.1).
Лемма 24.11. Пусть существует начальный момент n-го порядка,
n = 1, 2, ..., случайной величины ξ, т.е. M|ξ|n < ∞. Тогда её характеристическая функция θξ (t) является n раз непрерывно дифференцируемой, и
её n-я производная в нуле равна
(n)

θξ (0) = in M ξ n .
Доказательство. Заметим сначала, что т.к. существует начальный момент
Mξ n , то существуют все моменты Mξ k при k < n.
По лемме 24.5.2) имеем |θξ (t)| \leq 1, поэтому интеграл в правой части
∫∞
eitx fξ (x)dx

θξ (t) =
−∞

равномерно сходится по параметру t и следовательно его можно дифференцировать по t:
∫∞
θξ′ (t) = i xeitx fξ (x)dx,
−∞

83

θξ′′ (t) = i2

∫∞
x2 eitx fξ (x)dx,
−∞

.....................
∫∞
(n)
θξ (t) = in xn eitx fξ (x)dx.
−∞

Подставляя в эти равенства t = 0, получим требуемый результат: θξ′ (0) =
i M ξ, θξ′′ (0) = i2 M ξ 2 ,

(n)

... , θξ (0) = in M ξ n .

Лемма 24.12. Если существуют начальные моменты M ξ, M ξ 2 , \ldots ,
M ξ n случайной величины ξ, т.е. M |ξ|n < ∞, тогда в окрестности нуля её
характеристическая функция θξ (t) разлагается в ряд Тейлора24
θξ (t) = 1 +

iMξ
i2 M ξ 2 2
in M ξ n n
t+
t + ...+
t + o(tn ).
1!
2!
n!

Доказательство. В стандартное разложение функции θξ (t) в ряд Тейлора
θξ (0) n
θξ′ (0)
θξ′′ (0) 2
θξ (t) = 1 +
t+
t + ...+
t + o(tn )
1!
2!
n!
(n)

подставим выражения для θξ′ (0), θξ′ (0), \ldots , θξ (0), доставляемые теор.
24.11, получим требуемый результат.
(n)

В заключение параграфа сформулируем без доказательства теорему Леви, которая устанавливает "непрерывное" соответствие между слабо сходящимися последовательностями случайных величин и поточечно сходящимися последовательностями характеристических функций. "Непрерывность" этого соответствия состоит в том, что пределу при слабой сходимости соответствует предел при поточечной сходимости и наоборот.
Теорема 24.13. (Леви25 о непрерывном соответствии). Последовательность случайных величин {ξn }∞
n=1 слабо сходится к случайной величине ξ
тогда и только тогда, когда последовательность их характеристических
функций {θξn (t)}∞
n=1 поточечно сходится к характеристической функции θξ (t).
24

Брук Тэйлор (Brook Taylor, 1685 -- 1731), английский математик, именем которого назван ряд (опубликованный им в 1715--1717 гг.), однако этот ряд был известен и применялся ещё в XVII веке Грегори и
Ньютоном.
25
Поль Пьер Леви (Paul Pierre Lévy, 1886 -- 1971), выдающийся французский математик, основные
труды по теории вероятностей, функциональному анализу, теории функций и механике.

84

§25. Вычисление характеристических
функций
Пример 25.1. Пусть случайная величина ξ имеет распределение Берξ
0
1
нулли
. По лемме 25.10 её характеристическая функция равна
P 1−p p
θξ (t) = M eitξ = eit\cdot0 (1 − p) + eit\cdot1 p = 1 − p + peit .
Пример 25.2. Пусть случайная величина ξ имеет биномиальное распределение (см. опред. 9.3) k 7\to P(ξn = k) = Cnk pk (1 − p)n−k , где k =
0, 1, 2, \ldots , n. Её характеристическая функция равна
itξ

θξ (t) = M e

=

n
∑

it\cdotk

e

Cnk pk (1−p)n−k

=

k=0

n
∑

Cnk (peit )k (1−p)n−k = (1−p+peit )n ,

k=0

где последнее равенство есть бином Ньютона.
Пример 25.3. Пусть случайная величина ξ имеет распределение Пуасk
сона (см. опред. 23.2) k 7\to Pλ (k) = λk! e−λ , где k = 0, 1, 2, \ldots . По лемме 24.10
её характеристическая функция равна
itξ

θξ (t) = M e

=

∞
∑

it\cdotk λ

e

k=0

k

k!

−λ

e

=e

−λ

∞
∑
(λeit )k
k=0

k!

= e−λ eλe = eλ(e
it

it

−1)

.

Пример 25.4. Пусть случайная величина
ξ имеет показательное рас{
0,
x<0
пределение (см. опред. 12.7), fξ (x) =
. По лемме 25.10 её
−λx
λe , x ≥ 0
характеристическая функция равна
∫∞
θξ (t) = M eitξ =

∫∞
eit\cdotx λe−λx dx = λ e−(λ−it)x dx =

0

0

λ
λ ( −(λ−it)x ∞ )
−e
=
,
0
λ − it
λ − it
поскольку при x \to ∞ модуль величины e−(λ−it)x = e−λx eitx стремится к
нулю: |e−(λ−it)x | = e−λx \to 0.
Пример 25.5. Пусть
{ случайная
} величина ξ имеет нормальное распреде2
(x−a)
ление fξ (x) = σ√12\pi exp − 2σ2
(см. опред. 12.8). Её характеристическая
85

функция равна
θξ (t) = M eitξ

1
=√
2\pi

= e−t

2

∫∞

eitx e−x

2

−∞

/2 1
√
2\pi

∫∞

1
/2
dx = √
2\pi

e−(x−it)

2

/2

∫∞

e−t

2

/2 −(x−it)2 /2

e

dx =

−∞

d(x − it) = e−t

2

/2

,

−∞

где в показателе экспоненты мы выделили полный квадрат и получили ин2
теграл от функции √12\pi e−u /2 .
Напомним
Определение 16.7. Если две независимые случайные величины имеют
одно и то же распределение (возможно, с разными параметрами), и их
сумма имеет то же самое распределение, то распределение называется
устойчивым относительно суммирования.
Лемма 16.9. Биномиальное распределение является устойчивым относительно суммирования.
Доказательство. θξn +ξm (t) = θξn (t)θξm (t) = (1 − p + peit )n (1 − p + peit )m =
k
(1 − p + peit )n+m , следовательно P(ξn+m = k) = Cn+m
pk (1 − p)n+m−k , где
k = 0, 1, 2, \ldots , n + m.
Лемма 16.10. Нормальное распределение является устойчивым относительно суммирования.
{
}
{
}
t2 σ12
t2 σ22
Доказательство. θξ+η (t) = θξ (t)θη (t) = exp ita1 − 2 exp ita2 − 2
=
{
}
2 2
2
k
exp it(a1 + a2 ) − t (σ12+σ2 ) , следовательно P(ξn+m = k) = Cn+m
pk (1−p)n+m−k ,
где k = 0, 1, 2, \ldots , n + m.

§26. Центральная предельная теорема
Замечание 26.1. Центральные предельные теоремы (ЦПТ) в теории
вероятностей -- это класс теорем, утверждающих, что сумма большого
количества независимых случайных величин имеет распределение близкое
к нормальному. Так как многие случайные явления в природе и социальном обществе являются суммами большого числа случайных факторов, то
центральные предельные теоремы обосновывают фундаментальность нормального закона распределения. История получения ЦПТ растянулась на
86

два века -- от первых работ Муавра 1730 г. до необходимых и достаточных
условий, полученных в 30-х гг. XX века. Самый общий классический случай ЦПТ для неодинаково распределённых последовательностей случайных
величин принадлежит А.М. Ляпунову26 (1901). Мы докажем ЦПТ в классической форме (теор. 26.3), а чтобы иметь представление о ЦПТ в форме
Ляпунова (теор. 26.5) мы приведём её без доказательства.
Замечание 26.2. Вернёмся ещё раз к ЗБЧ в форме Хинчина. Пусть
ξ1 , ξ2 , \ldots , ξn , \ldots -- последовательность попарно независимых одинаково распределённых случайных величин, т.е. все имеющие математическое
n
∑
ожидание Mξ1 и дисперсию Dξ1 . Обозначим Sn =
ξk . Тогда по ЗБЧ в форk=1

среднее арифметическое Snn
1
же самое, величина Sn −nMξ
n

ме Хинчина
сходится по вероятности к Mξ1 ,
или, что то
сходится по вероятности к нулю.
Запишем это утверждение с помощью неравенства Бьенеме – Чебышёва:

(
)
 Sn − nMξ1 
 < ε ≥ 1 − Dξ1 .
P 

n
nε2
Т.к. вероятность не превосходит 1, то это неравенство можно переписать в виде

(
)
 Sn − nMξ1 
Dξ1
<ε
1 − 2 \leq P 
\leq 1.

nε
n
Если теперь перейти к пределу при n \to ∞, то левая часть этого сквозного неравенства стремится к единице, и вероятность, стоящая в средней
части, "намертво" впечатывается в единицу. В этом и состоит высший
смысл Закона Больших Чисел:
при стремлении n к бесконечности и для

 Sn −nMξ1 
любого ε > 0 неравенство  n  < ε становится достоверным событием. Поэтому ЗБЧ есть строгое математическое выражение свойства
статистической устойчивости (см. опред 4.4). Заметим, что Mξ1 и Dξ1
являются константами, а ε > 0 хотя и любое, но тоже постоянное число.
Идея как-то оторвать упомянутую вероятность от единицы заключается в следующем: а не слишком ли на большу́ю степень числа n мы поде1
лили в выражении Sn −nMξ
. Нельзя ли поделить на что-нибудь, растущее к
n
бесконечности

{
}медленнее чем n так, чтобы последовательность событий
 Sn −nMξ1 
 nα  < ε при некотором 0 < α < 1 перестала бы сходиться к достоверному (и, само собой разумеется, не сходилась бы к невозможному
26

Александр Михайлович Ляпунов (1857 -- 1918), выдающийся русский математик, основные труды
по устойчивости динамических систем, теории потенциала и механике. Занятие теорией вероятностей
было кратким эпизодом в его научной работе, тем не менее в этой области он добился фундаментальных
результатов. Он доказал ЦПТ при весьма широких условиях методом, который и сейчас является одним
из основных в теории вероятностей.

87

событию)? Оказывается, если выбрать α = 1/2, то при n \to ∞ последо1
√
вательность случайных величин ηn = Sn −nMξ
слабо сходится к случайной
n
величине η, имеющей нормальное (!) распределение.
Теорема 26.3 (ЦПТ в классической форме). Если случайные величины
ξ1 , ξ2 , \ldots , ξn , \ldots независимы, одинаково распределены и имеют конечные
математическое ожидание Mξi = a < ∞ и дисперсию Dξi = σ 2 < ∞ и
σ ̸= 0, тогда последовательность случайных величин
ηn =

ξ1 + \ldots + ξn − na
√
σ n

слабо сходится к случайной величине, имеющей стандартное нормальное
распределение, т.е.
(
lim P

n\to∞

ξ1 + \ldots + ξn − na
√
\leqx
σ n

или кратко
1
lim P ( ηn \leq x ) = √
n\to∞
2\pi

)

1
=√
2\pi

∫x

e−u

2

/2

∫x

e−u

2

/2

du,

−∞

du.

−∞

Доказательство. Для упрощения выкладок вместо ξ1 , ξ2 , \ldots , ξn , \ldots
введём стандартные случайные величины ξ 1 , ξ 2 , \ldots , ξ n , \ldots по формулам
ξi =

ξi − a
.
σ

Легко видеть, что случайные величины ξ i являются независимыми, одинаково распределёнными, имеют нулевое математическое ожидание и единичную дисперсию и следовательно имеют одинаковые характеристические
функции. Обозначим их характеристические функции тем же символом как
и для первой случайной величины θ ξ i (t) = θ ξ 1 (t). Используя теор. 24.12, разложим её в ряд Тейлора, содержащий три первых члена плюс остаточный
член:
1
θ ξ 1 (t) = 1 − t2 + o(t2 ),
2
2

где мы учли, что Mξ 1 = 0 и Mξ 1 = Dξ 1 + (Mξ 1 )2 = 1.
Случайная величина ηn может быть записана в виде
ηn =

ξ1 + \ldots + ξn
ξ
ξ
√
= √1 + \ldots + √n .
n
n
n
88

Запишем и преобразуем её характеристическую функцию, получим
24.8

24.6

θηn (t) = θ √ξ1 + \ldots + √ξn (t) = θ √ξ1 (t) \cdot \ldots \cdot θ √ξn (t) =
n

(
= θ ξ1

t
√
n

)

n

(
\cdot \ldots \cdot θ ξn

t
√
n

n

n

)

[
= θ ξ1

(

t
√
n

)]n

[
( 2 )]n
t2
t
= 1−
+o
.
2n
n

Т.к. по второму замечательному пределу имеем
[
( 2 )]n
t2
t
2
lim 1 −
+o
= e−t /2 ,
n\to∞
2n
n
то это означает, что последовательность характеристических функций
−t2 /2
{θηn (t)}∞
.
n=1 поточечно сходится к характеристической функции θη (t) = e
По пункту 25.5 эта функция является характеристической функцией стандартного нормального распределения с плотностью вероятности
2
fη (x) = √12\pi e−x /2 . По теор. 24.13 (Леви о непрерывном соответствии), последовательность случайных величин {ηn }∞
n=1 слабо сходится к случайной
величине η, а по опред. 21.9 слабой сходимости имеем
1
11.3
21.9
12.1
lim P ( ηn \leq x ) = lim Fηn (x) = Fη (x) = √
n\to∞
n\to∞
2\pi

∫x

e−u

2

/2

du.

−∞

Что и требовалось доказать.
Следствие 26.4. Если случайные величины ξ1 , ξ2 , \ldots , ξn , \ldots независимы, одинаково распределены и имеют конечную ненулевую дисперсию и
n −na
ηn = ξ1 + . .σ.√+ξ
, то следующие утверждения эквивалентны ЦПТ в класn
сической форме.
1) Для любых x < y имеет место равенство:
1
lim P ( x < ηn < y ) = √
n\to∞
2\pi

∫y

e−u

2

/2

du.

/2

du.

x

2) Для любых x < y имеет место равенство:
1
lim P ( x \leq ηn \leq y ) = √
n\to∞
2\pi
89

∫y
x

e−u

2

Теорема 26.5. (ЦПТ в форме Ляпунова). Пусть случайные величины
ξ1 , ξ2 , \ldots , ξn , \ldots независимы и имеют конечные абсолютные начальные
моменты 3-го порядка (M|ξn |3 < ∞). Введём следующие обозначения
An =

n
∑

Mξk ,

k=1

Bn2

=

n
∑

Cn3

Dξk ,

=

k=1

n
∑

M|ξk − Mξk |3 .

k=1

Если

Cn
= 0,
n\to∞ Bn
тогда последовательность случайных величин
lim

ξ1 + \ldots + ξn − An
Bn
слабо сходится к случайной величине, имеющей стандартное нормальное
распределение, т.е.
(

ξ1 + \ldots + ξn − An
\leqx
Bn

lim P

n\to∞

)

1
=√
2\pi

∫x

e−u

2

/2

du.

−∞

Доказательство теоремы Муавра-Лапласа 26.8
В качестве следствия из ЦПТ докажем предельную теорему МуавраЛапласа. Подобно ЗБЧ в форме Бернулли предельная теорема Муавра-Лапласа
является утверждением только для схемы Бернулли. Напомним её формулировку.
Теорема 26.8 (интегральная теорема Муавра-Лапласа). Если случайная величина ηn имеет биномиальное распределение P(ηn = k) = Cnk pk q n−k ,
тогда для любых вещественных k1 и k2 имеет место равенство
∫y
lim P(k1 \leq ηn \leq k2 ) =

n\to∞

x

где x =

k1 −np
√
npq

иy=

1
2
√ e−t /2 dt,
2\pi

k2 −np
√
npq .

Доказательство. Приведём обозначения теоремы Муавра-Лапласа в соответствие с обозначениями ЦПТ. Случайная величина ξ есть число появлений события A в результате n испытаний в схеме Бернулли с вероятностью
P(A) = p. Если обозначить через ξi число (равное 0 или 1) появлений события A в результате i-го испытания, где i = 1, \ldots , n, то случайную величину
90

ηn можно представить в виде суммы ηn = ξ1 + \ldots + ξn независимых, одинаково распределённых случайных величин, имеющих одинаковые конечные
математические ожидания Mξi = p и дисперсии Dξi = p(1 − p) = pq. Тогда
по пункту 18.9.2) имеем Mηn = np и Dηn = npq. Заметим, что неравенство
ηn −np
k2 −np
√
√
k1 \leq ηn \leq k2 эквивалентно неравенству k√1 −np
npq \leq
npq \leq
npq . По след.
26.4.2) получим требуемый результат.
Пример 26.6. (Ср. пример 26.7.) Монету подбрасывают 10 000 раз.
Найти вероятность того, что относительная частота выпадения герба
отличается от классической вероятности 1/2 не менее
(  чем на 0,01.
)
 n(A) 1 
Решение. Другими словами, требуется найти P  n − 2  ≥ 0, 01 ,
n
∑
где n = 104 , n(A) =
ξk -- число выпадений герба, а ξk являются незаk=1

висимыми случайными величинами, имеющие одно и то же распределение
Бернулли с p = 12 , и равные единице, если выпал герб, и нулю -- в противном
вероятности на
√ случае. Умножим обе части неравенства√под знаком
√
n = 100 и разделим на корень из дисперсии Dξ1 = pq = 21 .


(
)
(
)

 n(A)
 n(A) − np 
 < 0, 01 =
− p ≥ 0, 01 = 1 − P 
P 

n
n

( √ 
√ )
n  n(A) − np 
n
=
=1−P √
< 0, 01 √


n
Dξ1
Dξ1

(
)
∫2
 n(A) − np 
1
−u2 /2
<2 =1− √
= 1 − P  √
e
du =
npq 
2\pi
−2

1 − 2Φ(2) ≃ 1 − 2 \cdot 0, 47725 = 0, 0455,
где значение Φ(2) интеграла вероятности взято из таблицы. Заметим,
что применение ЦПТ и предельной теоремы Муавра-Лапласа доставляет
лучшую оценку чем ЗБЧ в форме Бернулли (см. ответ в примере 21.7.).

§27. Сферическое, χ2-распределение
и распределение Стьюдента
Сферическое распределение
Определение 27.1. Пусть случайные величины ξ1 , \ldots , ξn независимы
и одинаково распределены по нормальному закону распределения
1
2
2
fξi (xi ) = √
e−xi /2σ ,
2\pi σ
91

то есть ai = 0 и σi = σ для всех i = 1, \ldots , n. Тогда распределение случайного вектора ξ = (ξ1 , \ldots , ξn ) называется нормальным сферическим
распределением или проще сферическим распределением.
Лемма 27.2. Плотность вероятности сферического распределения есть
fξ (x1 , \ldots , xn ) =

1
− 2σ12 (x21 + \ldots +x2n )
e
.
(2\pi)n/2 σ n

Доказательство. Это утверждение очевидно следует из 27.1 и 15.6.2).
Замечание 27.3. Так как поверхности равной вероятности, то есть
fξ (x1 , \ldots , xn ) = const, являются концентрическими (n − 1)-мерными сферами x21 + \ldots + x2n = R2 с центром в начале координат, то сферическое
распределение инвариантно относительно любого ортогонального преобразования A : Rn \to Rn . То есть, если η = A \cdot ξ, то fη (x1 , \ldots , xn ) =
fξ (x1 , \ldots , xn ),
где через A обозначена ортогональная матрица.
Положим в сферическом распределении σ = 1, получим плотность вероятности
1
− 12 (x21 + \ldots +x2n )
fξ (x1 , \ldots , xn ) =
e
(2\pi)n/2
и назовём её плотностью вероятности стандартного сферического распределения.
χ- и χ2 -распределения
Определение 27.4. Пусть случайные величины ξ1 , \ldots , ξn независимы
и одинаково распределены по стандартному нормальному закону распределения. Случайные величины
√
χ = ξ12 + \ldots + ξn2
и
χ2 = ξ12 + \ldots + ξn2
называются соответственно χ- и χ2 -распределениями с n степенями свободы.
Наша ближайшая задача найти их плотности вероятности fχ (x) и
fχ2 (x).
92

Рис. 26: К вычислению плотности χ-распределения.
Теорема 27.5. Плотность вероятности χ-распределения задаётся по
формуле
1 2
xn−1
fχ (x) = n −1 ( n ) e− 2 x ,
x ≥ 0,
22 Γ 2
где Γ (x)-- гамма-функция.
Доказательство. Вероятность события {x < χ < x + dx} можно вычислить,
интегрируя плотность вероятности fξ (x1 , \ldots , xn ) стандартного сферического распределения по n-мерному сферическому слою радиуса x и толщины dx
(см. рис. 26).
∫
P(x < χ < x + dx) =
x<

∫
fξ (x1 , \ldots , xn ) dx1 \ldots dxn .

...

√

x21 + \ldots +x2n < x+dx

Откуда получаем
P(x < χ < x + dx)
fχ (x) =
=
dx
√
1
=
(2\pi)n/2 √

∫

∫

∫
...

fξ (x1 , \ldots , xn ) dx1 \ldots dxn =

x21 + \ldots +x2n = x

∫

e− 2 (x1 + \ldots +xn ) dx1 \ldots dxn =
1

...

2

2

x21 + \ldots +x2n = x

1
− 12 x2
=
e
(2\pi)n/2
√

∫

∫

dx1 \ldots dxn = Cxn−1 e− 2 x ,
1 2

...

x21 + \ldots +x2n = x

93

где последнее равенство справедливо потому, что площадь (n − 1)-мерной
сферы радиуса x пропорциональна xn−1 . Чтобы найти константу C, восполь∞
∫
зуемся свойством плотности fχ (x) dx = 1, откуда получаем
0

∫∞
C

x

n−1 − 12 x2

e

dx = 2

n
2 −1

Γ

(n)
2

C = 1,

0

откуда следует требуемый результат.
Теорема 27.6. Плотность fχ2 (x) случайной величины χ2 есть
x
x 2 −1
fχ2 (x) = n ( n ) e− 2 ,
22 Γ 2
n

x ≥ 0.

Доказательство. Ясно, что случайные величины χ и χ2 связаны функцией
g(x) = x2 . Поэтому по теор. 14.2, находим, что
n
(

2 −1
√
x
x
1
 −1 )′ 
−1
fχ2 (x) =  g (x)  \cdot fχ (g (x)) = √ fχ ( x) = n ( n ) e− 2 ,
x ≥ 0.
2 x
22 Γ 2
Замечание 27.7. Заметим, что χ2 -распределение с двумя степенями
свободы (n = 2) является показательным распределением 12.7 с параметx
ром λ = 1/2 и с плотностью вероятности 12 e− 2 , x ≥ 0. А χ-распределение
с тремя степенями свободы (n = 3) называется распределением Максвелла
и описывает в кинетической теории газов распределение модуля скорости
частиц в состоянии термодинамического равновесия.
О распределении Стьюдента
Замечание 27.8. Этот пункт имеет информативный характер. Распределение Стьюдента27 часто возникает в прикладных задачах математической статистики. Пусть случайные величины ξ0 , ξ1 , \ldots , ξn независимы и одинаково распределены по стандартному нормальному закону
27

Стьюдент -- псевдоним английского химика и статистика Вильяма Госсета (William Sealy Gosset, 1876
-- 1937). По окончании университета был (с 1899) младшим управляющим пивоваренной компании Arthur
Guinness & Son в Дублине. В то время в совете директоров компании уже понимали важность методов
теории вероятностей и статистики для массового производства и направили Госсета на стажировку в
Лондонский университет для изучения статистики. Вскоре Госсет получил теоретические результаты в
статистике, которые оказались важными для пивоварения и которые он хотел опубликовать. В компании
не возражали против его публикаций, однако совет директоров хотел, чтобы конкуренты как можно
дольше не знали о применении статистики на пивоварне Arthur Guinness & Son. Это объясняет появления
псевдонима Стьюдент.

94

распределения
1
2
fξi (xi ) = √ e−xi /2 ,
2\pi
для всех i = 0, 1, \ldots , n. Тогда случайная величина
τn = √

ξ0
1 2
n (ξ1

+ \ldots + ξn2 )

называется отношением Стьюдента, её распределение называется распределением Стьюдента с n степенями свободы. Формула плотности вероятности τn имеет вид
( ) (
) n+1
2 − 2
Γ n+1
x
2( )
fτn (x) = √
1+
,
n
n\pi Γ n2

−∞ < x < ∞.

Замечание 27.9. Легко проверить, что последовательность отношений Стьюдента {τn }∞
n=1 слабо сходится к стандартному нормальному распределению, то есть
1 − x2
lim fτ (x) = √ e 2 .
n\to∞ n
2\pi

§28. Цепи Маркова
Непосредственным обобщением схемы независимых испытаний (см. опред.
10.3) является схема цепей Маркова.
Определение 28.1. Пусть эксперимент состоит в том, что
1) проводят последовательность испытаний с номерами s = 1, 2, \ldots ;
2) в каждом испытании появляется одно из k несовместных событий
A1 , A2 , \ldots , Ak , при этом то, что в s-ом испытании произошло событие
Ai , будем обозначать Asi ;
3) вероятность появления события As+1
(то есть j-го события в (s+1)j
ом испытании) зависит только от того, какое событие произошло в предыдущем s-ом испытании и не зависит от того, какие события произошли в
испытаниях с номерами s − 1, s − 2, \ldots .
Тогда такая последовательность событий называется (простой) цепью
Маркова.
Пример. Согласно предложенной Н. Бором28 модели атома водорода
28

Нильс Хенрик Давид Бор (Niels Henrik David Bohr, 1865 -- 1962), датский физик, один из создателей
квантовой физики. Создал первую квантовую модель атома, участвовал в разработке основ квантовой
механики, теории атомного ядра, ядерных реакций и взаимодействия элементарных частиц со средой.

95

электрон может находится только на одной из допустимых орбит. Обозначим через Ai событие, состоящее в том, что электрон находится на
i-ой орбите. Эти события Бор назвал стационарными состояниями атома. Вероятность перехода электрона с i-ой на j-ю орбиту зависит только
от i и j, потому что разность j − i зависит от количества испускаемой
или поглощаемой атомом энергии и не зависит от того, на каких орбитах
находился электрон в прошлом. Этот пример доставляет цепь Маркова
теоретически с бесконечным числом состояний атома.
Теория цепей Маркова довольно обширна, поэтому мы ограничимся изучением так называемых однородных цепей( Маркова.
 s)
 A , т.е. вероятность поРассмотрим условную вероятность P As+1
i
j
s+1
явления события Aj при условии, что событие Asi произошло.
Определение 28.2.
 s )Маркова называется однородной, если услов( s+1Цепь
ная вероятность
P Aj  Ai не зависит от номера s, при этом вероят( s+1  s )
ность P Aj  Ai называется вероятностью перехода от события Asi к
событию As+1
и обозначается
j
 s)
(
 Ai .
pij = P As+1
j
Замечание 28.3. Ясно, что
1) 0 \leq pij \leq 1 и
2) pi1 + pi2 + \ldots + pik = 1 для всех i = 1, 2, \ldots , k.
Определение 28.4. Полная информация о вероятностях перехода в цепи Маркова содержится в таблице


p11 p12 \ldots p1k
 p21 p22 \ldots p2k 

\pi1 = 
 ... ... ... ... ,
pk1 pk2 \ldots pkk
которая называется матрицей перехода.
Замечание 28.5. Главной задачей теории цепей Маркова является нахождение вероятности перехода от события Asi к событию As+n
j , произошедшему через n испытаний. Обозначим эту вероятность
 s)
(
 Ai ,
pij (n) = P As+n
j
а искомую матрицу перехода через n испытаний через


p11 (n) p12 (n) \ldots p1k (n)
 p21 (n) p22 (n) \ldots p2k (n) 
.
\pin = 
 ...
...
...
... 
pk1 (n) pk2 (n) \ldots pkk (n)
96

Теорема 28.6. Если 0 < m < n, то \pin = \pim \cdot \pin−m .
Доказательство. Рассмотрим какое-нибудь промежуточное испытание с номером s + m, то есть s < s + m < s + n. Пусть в этом испытании появится
какое-то событие As+m
, где 1 \leq r \leq k. В наших обозначениях вероятность
r
s
перехода от события Ai к событию As+m
равна
r
 s)
(
 Ai = pir (m),
P As+m
r
к событию As+n
равна
а вероятность перехода от события As+m
r
j
 s+m )
(
 Ar
P As+n
= prj (n − m).
j
По формуле полной вероятности 7.2 имеем
pij (n) =

k
∑

pir (m) \cdot prj (n − m).

r=1

Последняя формула в точности совпадает с формулой произведения матриц, поэтому получаем \pin = \pim \cdot \pin−m .
Теорема 28.7. Для любого n ≥ 1, имеет место формула \pin = \pi1n .
Доказательство. Доказательство проведём методом математической индукции.
1) Проверяем тождество при n = 1: \pi1 = \pi11 = \pi1 .
2) Пусть при n = q выполнено тождество \piq = \pi1q .
3) По теор. 28.6 имеем \piq+1 = \pi1 \cdot \piq = \pi1 \cdot \pi1q = \pi1q+1 .
Что и требовалось доказать.

97

98

Литература
[1] Гнеденко Б.В. Курс теории вероятностей. –М.:Наука, 1988.
[2] Чистяков В.П. Курс теории вероятностей. –М.:Наука, 1996.
[3] Боровков А.А. Теория вероятностей. – М.:Эдиториал УРСС, 1999.
[4] Севастьянов Б.А. Курс теории вероятностей и математической статистики. –М.:Наука, 1982.
[5] Двайт Г.Б. Таблицы интегралов и другие математические формулы.
Изд.9. –СПб.:Лань, 2005.
[6] Корн Г., Корн Т. Справочник по математике для научных работников
и инженеров. М.: Наука, 1968.
[7] Задачи по теории вероятностей (Сост. А.А. Дубков, А.Т. Гаврилин)
Метод. разработка для студентов РФ ф-та ННГУ. –Н.Новгород: ННГУ, 1999. Диск I://students/libr/probabilitytheory/met-99/.pdf
[8] Сборник задач по теории вероятностей, математической статистике и теории случайных функций (под редакцией А.А. Свешникова). М.:
Наука, 1970.
[9] Коваленко И.Н., Филиппова А.А. Теории вероятностей и математической статистики. –М.: Высшая школа, 1992.
[10] Вентцель Е.С. Теория Вероятностей. –М.: Высшая школа, 1998.
[11] Гихман И.И., Скороход А.В., Ядренко М.И. Теории вероятностей и математической статистики. –Киев: Высшая школа, 1988.
[12] Агапов Г.И. Задачник по теории вероятностей –М.: Высшая школа,
1996.
[13] Чернова Н.И. Теория вероятностей: Учеб. пособие/Новосиб. гос ун-т.
Новосибирск, 2007. 160 с.
99

