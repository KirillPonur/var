%!TEX root = ../var.tex

\textbf{Пример}. Три завода производят одну и ту же машину Renault. При этом
1-й завод производит 20\%, 2-й — 30\%, 3-й — 50\% автомобилей. Брак на 1-м
заводе составляет 5\%, на 2-м — 2\%, на 3-м — 4\% автомобилей. Автомашины
случайным образом поступают в продажу. Найти

а) вероятность купить бракованную машину и

б) условную вероятность того, что машина изготовлена на 1-м заводе.
Решение. а) Т.к. сборка машин на заводах не зависима (замеч. \ref{zam:6.1}), и

сборка машин на них не совместна (аксиома $\mathcal{P}3$), то вероятность купить бра-
кованную машину равна доле бракованных машин во всей продукции, то есть
0, 05 · 0, 2 + 0, 02 · 0, 3 + 0, 04 · 0, 5 = 0, 036.

б) Во этом случае условная вероятность покупки бракованной машины с
1-го завода равна доле брака 1-го завода среди всего количества бракованных
машин
\begin{equation*}
	\frac{0,05\cdot 0,2}{0,05\cdot 0,2+0,02\cdot0,3+0,04\cdot0,5}=\frac{0,01}{0,036}=0,2(7).
\end{equation*}

\begin{definition}
	Если события $H_1,H_2,\dots\subset\Omega$
	
	1) попарно несовместны (т.е. $H_i ∩ H_j = \O$ при $i \neq j$),

	2) их объединение составляет всё пространство элементарных событий, т.е.
	\begin{equation*}
		\bigcup^{\infty}_{i=1}H_i=\Omega,
	\end{equation*}

	3)$P(H_i)>0$ для всех $i\in\mathbb{N}$,

	то совокупность $\{H_1,H_2,\dots\}$ называется \textit{полной группой событий}, а события $H_1,H_2,\dots$ называются \textit{гипотезами}.
\end{definition}
На \ref{pic:7} показана полная группа событий и некоторое событие А в пространстве $\Omega$.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.5\textwidth]{pic/pic7.pdf}
	\caption{Полная группа событий и некоторое событие А в пространстве $\Omega$}
	\label{pic:7}
\end{figure}


\begin{proof}
	Заметим, что $A=A\cap\Omega=A\cap\left(\bigcup\limits^{\infty}_{i=1}H_i\right)=\bigcup\limits_{i=1}^{\infty}\cap H_i$, где события $A\cap H_1,A\cap H_2,\dots$-- попарно несовместны. Используя аддитивность вероятности (аксиома $\mathcal{P}3$), а затем теорему умножения 6.3, получим требуемый результат
	\begin{equation*}
		P(A)=\sum\limits_{i=1}^{\infty}P(A\cap H_i)=
		\sum\limits_{i=1}^{\infty}P(H_i)P(A|H_i).
	\end{equation*}
\end{proof}

\begin{theorem}[формулы Байеса\footnote{Томас Байес (Reverend Thomas Bayes, 1702 — 1761), английский математик и пресветерианский священник.}]
Пусть $H_1,H_2,\dots$ – полная группа
событий и $A $— некоторое событие положительной вероятности. Тогда
условная вероятность события $H_k$ при условии, что событие $A$ произошло,
для любого $k$ вычисляется по формуле
\begin{equation*}
	P(H_k|A)=\frac{P(H_k)P(A|H_k)}{\sum\limits_{i=1}^{\infty}P(H_i)P(A|H_i)}.
\end{equation*}
\end{theorem}

\begin{proof}
	По определению условной вероятности имеем
	\begin{equation*}
		P(H_k|A)=\frac{P(A\cap H_k)}{P(A)}=\frac{P(H_k)P(A|H_k)}
		{\sum\limits_{i=1}^{\infty}P(H_i)P(A|H_i)}.
	\end{equation*}
где последнее равенство следует из теоремы умножения и формулы полной
вероятности
\end{proof}