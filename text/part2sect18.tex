%!TEX root = ../var.tex
\begin{definition}
1) Центральным моментом $n$-го порядка случайной
величины $\xi$ называется число
\begin{equation*}
\M(\xi − \M\xi)^n = \int_{-\infty}^{\infty}(x-\M\xi)^n f_{\xi}(x)dx
\end{equation*}

2) Дисперсией случайной величины $\xi$ называется центральный момент 2-го порядка, т.е. число
\begin{equation*}
\D\xi = \M(\xi − \M\xi)^2 = \int_{-\infty}^{\infty}(x-\M\xi)^2 f_{\xi}(x)dx.
\end{equation*}
\end{definition}

\begin{zam}
Для любой случайной величины $\xi$ её центральный момент 1-го порядка равен нулю, $\M(\xi − \M\xi) = \M\xi − \M\xi = 0$.
\end{zam}

\begin{zam}
Если ось $x$ рассматривать как тонкую металлическую проволоку с линейной плотностью массы $f_{\xi}(x)$, то дисперсия $\D\xi$ есть в точности момент инерции стержня относительно его центра тяжести $\M\xi$.
\end{zam}

\begin{lemma}
1) Для любой случайной величины $\xi$ имеем $\D\xi \geq 0$.

2) Если $C = const$, то $\D C = 0$.

3) Если $C = const$, то для любой случайной величины $\xi$ имеем $\D(C\xi) = C^2\D\xi.$
\end{lemma}
 
\begin{proof}

1) Т.к. $(x − \M\xi)^2 f_{\xi}(x) (x) \geq 0$, то интеграл в опред. 18.1.2) не меньше нуля.

2) $\D C = \M(C − \M C)^2 = 0$.

3) $\D(C\xi) = \M[C\xi −\M(C\xi)]^2 = \M[C(\xi −\M\xi)]^2 = C^2\M(\xi − \M\xi)^2 = C^2\D\xi.$

\end{proof}

\begin{zam}
Дисперсия (по прочтению формулы $\D\xi = \M(\xi − \M\xi)^2$)
равна <<среднему значению квадрата отклонения случайной величины от её среднего>>. То есть, дисперсия характеризует отклонение (разброс, кучность) значений случайной величины вокруг её среднего значения $\M\xi$.
В таком случае полезно следующее определение.	
\end{zam}

\begin{definition}
Число $\sigma = \sqrt{\D\xi}$ называется средне квадратическим отклонением случайной величины $\xi$.	
\end{definition}

\begin{theorem}
	Для любой случайной величины $\xi$ справедлива формула

\begin{equation*}
	\D\xi = \M\xi^2 − (\M\xi)^2 .
\end{equation*}

\end{theorem}

\begin{proof}

	\begin{gather*}
		\D\xi = \M(\xi − \M\xi)^2 = \M[\xi^2 − 2\xi \M\xi + (\M\xi)^2] =\\= \M\xi^2 − 2M(\xi \M\xi) + \M[(\M\xi)^2 ] =\\= \M\xi^2 − 2(\M\xi)^2 + (\M\xi)^2 = \M\xi^2 − (\M\xi)^2 .
	\end{gather*}

\end{proof}

\begin{theorem}
 Если случайные величины $\xi_1$ и $\xi_2$ независимы, то
$$\D(\xi_1 + \xi_2 ) = \D\xi_1 + \D\xi_2 .$$
 \end{theorem} 

\begin{proof}
 	\begin{gather*}
 		\D(\xi_1 + \xi_2 ) = \M(\xi_1 + \xi_2 )^2 − (\M(\xi_1 + \xi_2 ))^2 =\\= \M(\xi_1^2 + 2\xi_1 \xi_2 + \xi_2^2 ) - (\M\xi_1 + \M\xi_2 )^2 \stackrel{17.4.5)}{=}\\= \M\xi_1^2 + 2\M(\xi_1 \xi_2 ) + \M\xi_2^2 − (\M\xi_1)^2 − 2\M\xi_1 \M\xi_2 − (\M\xi_2 )^2  \stackrel{17.4.6)}{=}\\= \M\xi_1^2 − (\M\xi_1 )^2 + \M\xi_2^2 − (\M\xi_2 )^2 = \D\xi_1 + \D\xi_2 .
 	\end{gather*}
 \end{proof} 
 
\begin{example}
1) Пусть $\xi$ — подчиняется распределению Бернулли,
т.е. принимает два значения: 1 с вероятностью $p$ и 0 с вероятностью $q = 1 − p$, тогда 

\begin{gather*}
\M\xi = 1 \cdot p + 0 \cdot q = p,\quad
\M\xi^2 = 1^2 \cdot p + 0^2 \cdot q = p,\\
\D\xi = \M\xi^2 − (\M\xi)^2 = p − p^2 = pq.	
\end{gather*}

2) Вычислим математическое ожидание и дисперсию случайной величины $\xi$, имеющей биномиальное распределение, т.е. $\xi$ принимает значения $0, 1, 2, \ldots, n$ соответственно с вероятностями $\P(\xi_n = k) = C_n^k p^k (1 − p)^{n−k}$.
Возьмем $n$ независимых случайных величин $\xi_1 , \ldots, \xi_n$ имеющих одно и то же распределение Бернулли, т.е. с $\M\xi_i = p$ и $\D\xi_i = pq$ . Тогда их сумма $\xi = \xi_1 + \ldots + \xi_n$ имеет биномиальное распределение и

\begin{equation*}
\M\xi = \sum_{i=1}^{n}\M\xi_i = n\M\xi_1 = np, \quad
\D\xi = \D\xi_i = n\D\xi_1 = npq.		
\end{equation*}
\end{example}

